{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import scipy\n",
    "from scipy.integrate import simps\n",
    "import os\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRFClassifier\n",
    "from sklearn import metrics\n",
    "from tqdm import tqdm, trange\n",
    "import datetime\n",
    "import xgboost as xgb\n",
    "import multiprocessing\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedKFold, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pickle\n",
    "from joblib import dump, load\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"xtick.labelsize\": 14,\n",
    "    \"ytick.labelsize\": 14,\n",
    "    'font.size': 18,\n",
    "    'axes.labelweight': 'bold',\n",
    "    'figure.dpi': 150.0,\n",
    "    'axes.linewidth':2.0,\n",
    "})\n",
    "\n",
    "# Important lists\n",
    "features = ['A-A', 'B-B', 'A-B', 'A-A/B-B', 'A-B/(A-A + B-B)']\n",
    "features_merged = ['A-A_n', 'B-B_n', 'A-B_n', 'A-A_n/B-B_n', 'A-B_n/(A-A_n + B-B_n)',\n",
    "                   'A-A_l', 'B-B_l', 'A-B_l', 'A-A_l/B-B_l',\n",
    "                   'A-B_l/(A-A_l + B-B_l)']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DES and non-DES hbond lifetimes\n",
    "Creation and cleaning up of dataframes. These cells take in a path to GROMACS outputs from hydrogen bond calculations, and stores the \n",
    "A-A, B-B, and B-B lifetimes in a pandas dataframe. The dataframe can be stored as a csv for later use.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DES\n",
    "''' This function takes in a path to GROMACS outputs from hydrogen bond calculations, and stores the \n",
    "A-A, B-B, and B-B lifetimes in a pandas dataframe. The dataframe can be stored as a csv for later use.\n",
    "'''\n",
    "\n",
    "pathway = Path()\n",
    "\n",
    "hlife_dict = {}\n",
    "\n",
    "for folderz in pathway.glob('./h*-avg-files/des/*'):\n",
    "    # print(folderz.stem)\n",
    "    dict_key = folderz.stem[6:]\n",
    "    hlife_list = []\n",
    "    for file in pathway.glob(f\"{folderz}/hlife-*\"):\n",
    "        # print(file)\n",
    "        if len(os.listdir(file)) == 0:\n",
    "            hlife_list.append(0)\n",
    "            continue\n",
    "\n",
    "        for txt in pathway.glob(f\"{file}/hlife*.txt\"):\n",
    "            # print(txt)\n",
    "            txtfile = txt.name\n",
    "            data = pd.read_csv('{}'.format(txt), sep='\\s+',\n",
    "                               header=None, skiprows=[0, 1])\n",
    "            data = pd.DataFrame(data)\n",
    "            x = data[0]/1000\n",
    "            y = data[2]\n",
    "            area = 0\n",
    "            # Change dx to 1 for files prior to 7 Sep 2020\n",
    "            area = simps(y, dx=0.01)\n",
    "            hlife_list.append(area)\n",
    "            # print(\"The area of {thing} is {val}\".format(thing= txt.stem, val=area))\n",
    "            # print(\"\\n\")\n",
    "\n",
    "    hlife_dict[f\"{dict_key}\"] = hlife_list\n",
    "    # print(hlife_dict)\n",
    "    # print(\"\\n\")\n",
    "\n",
    "DES = []\n",
    "AA = []\n",
    "AB = []\n",
    "BB = []\n",
    "\n",
    "for i in list(hlife_dict.items()):\n",
    "    # print(i)\n",
    "    DES.append(i[0])\n",
    "    AA.append(i[1][0])\n",
    "    AB.append(i[1][1])\n",
    "    BB.append(i[1][2])\n",
    "\n",
    "des_dict = {\n",
    "    \"DES\": DES,\n",
    "    \"A-A\": AA,\n",
    "    \"A-B\": AB,\n",
    "    \"B-B\": BB\n",
    "}\n",
    "des_hlife_frame = pd.DataFrame(des_dict, columns=[\"DES\", \"A-A\", \"B-B\", \"A-B\"])\n",
    "aa_dlife = des_hlife_frame['A-A']\n",
    "ab_dlife = des_hlife_frame['A-B']\n",
    "bb_dlife = des_hlife_frame['B-B']\n",
    "des_hlife_frame['A-A/B-B'] = aa_dlife/bb_dlife\n",
    "# des_hlife_frame['BB/AA'] = bb_dlife/aa_dlife\n",
    "des_hlife_frame['A-B/(A-A + B-B)'] = ab_dlife/(aa_dlife + bb_dlife)\n",
    "des_hlife_frame.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' This cell deletes the A-A, B-B, and B-B lifetimes with 0.00 values in a pandas dataframe. The dataframe can be stored as a csv for later use.\n",
    "'''\n",
    "des_hlife = des_hlife_frame[(des_hlife_frame['B-B'] > 0.0)]\n",
    "des_hlife.reset_index(drop=True, inplace=True)\n",
    "# des_hlife"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# des_hlife.describe().to_csv('./des_hlife_summary_01-18-2023.csv')\n",
    "# des_hlife.to_excel('./des_hlife_01-23-2023.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DES non-overlapping histogram\n",
    "xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "des_fig = plt.figure()\n",
    "des_fig.set_size_inches(12, 10, forward=True)\n",
    "des_ax = des_fig.add_subplot(1,1,1)\n",
    "des_ax.set_xlabel(\"Hydrogen bond lifetime (ns)\", fontsize=28, weight='bold')\n",
    "des_ax.set_ylabel(\"Number of systems\", fontsize=28, weight='bold')\n",
    "ytick = np.arange(0,24, 2)\n",
    "xtick = np.arange(0,5.5, 0.5)\n",
    "plt.yticks(ytick,fontsize=26, weight='bold')\n",
    "plt.xticks(xtick,fontsize=26, weight='bold')\n",
    "# plt.title('DES', fontsize=26, weight='bold')\n",
    "plt.ylim([0,24])\n",
    "# des_hist = des_slice[['A-A', 'B-B', 'A-B']]\n",
    "# des_hist.plot.hist(bins=20, alpha=0.5, ylim=[0,16], ax=des_ax)\n",
    "# binss = np.linspace(0.09871825, 4.54204605, 10)\n",
    "# binss = np.linspace(0.0, 4.0, 10)\n",
    "plt.hist([des_hlife['A-A'], des_hlife['B-B'], des_hlife['A-B']], bins=10, label=['A-A', 'B-B', 'A-B'])\n",
    "# plt.hist([des_slice['A-A'], des_slice['B-B'], des_slice['A-B']], bins=binss, label=['A-A', 'B-B', 'A-B'])\n",
    "plt.legend(loc='upper left')\n",
    "des_fig.savefig(f'plots/distributions/des_hlife_nonoverlap_{xdate}.tiff', dpi=350,facecolor='white', bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non-DES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NON-DES\n",
    "''' This function takes in a path to GROMACS outputs from hydrogen bond calculations, and stores the \n",
    "A-A, B-B, and B-B lifetimes in a pandas dataframe. The dataframe can be stored as a csv for later use.\n",
    "'''\n",
    "\n",
    "pathway = Path()\n",
    "\n",
    "hlife_dict = {}\n",
    "\n",
    "for folderz in pathway.glob('./h*-avg-files/nondes/*'):\n",
    "    # print(folderz.stem)\n",
    "    dict_key = folderz.stem[6:]\n",
    "    hlife_list = []\n",
    "    for file in pathway.glob(f\"{folderz}/hlife-*-?-?\"):\n",
    "        # print(file)\n",
    "        if len(os.listdir(file)) == 0 or len(os.listdir(file)) < 3:\n",
    "            hlife_list.append(0)\n",
    "            continue\n",
    "\n",
    "        for txt in pathway.glob(f\"{file}/hlife*.txt\"):\n",
    "            # print(txt)\n",
    "            txtfile = txt.name\n",
    "            data = pd.read_csv('{}'.format(txt), sep='\\s+',\n",
    "                               header=None, skiprows=[0, 1])\n",
    "            data = pd.DataFrame(data)\n",
    "            x = data[0]/1000\n",
    "            y = data[2]\n",
    "            area = 0\n",
    "            # Change dx to 1 for files prior to 7 Sep 2020\n",
    "            area = simps(y, dx=0.01)\n",
    "            hlife_list.append(area)\n",
    "            # print(\"The area of {thing} is {val}\".format(thing= txt.stem, val=area))\n",
    "            # print(\"\\n\")\n",
    "\n",
    "    hlife_dict[f\"{dict_key}\"] = hlife_list\n",
    "    # print(hlife_dict)\n",
    "    # print(\"\\n\")\n",
    "\n",
    "# print(hlife_dict)\n",
    "NONDES = []\n",
    "AA_ = []\n",
    "AB_ = []\n",
    "BB_ = []\n",
    "\n",
    "for i in list(hlife_dict.items()):\n",
    "    # print(i)\n",
    "    NONDES.append(i[0])\n",
    "    AA_.append(i[1][0])\n",
    "    AB_.append(i[1][1])\n",
    "    BB_.append(i[1][2])\n",
    "\n",
    "nondes_dict = {\n",
    "    \"Non-DES\": NONDES,\n",
    "    \"A-A\": AA_,\n",
    "    \"A-B\": AB_,\n",
    "    \"B-B\": BB_\n",
    "}\n",
    "nondes_hlife_frame = pd.DataFrame(\n",
    "    nondes_dict, columns=[\"Non-DES\", \"A-A\", \"B-B\", \"A-B\"])\n",
    "aa_nlife = nondes_hlife_frame['A-A']\n",
    "ab_nlife = nondes_hlife_frame['A-B']\n",
    "bb_nlife = nondes_hlife_frame['B-B']\n",
    "nondes_hlife_frame['A-A/B-B'] = aa_nlife/bb_nlife\n",
    "# nondes_hlife_frame['BB/AA'] = bb_nlife/aa_nlife\n",
    "nondes_hlife_frame['A-B/(A-A + B-B)'] = ab_nlife/(aa_nlife + bb_nlife)\n",
    "# nondes_hlife_frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' This cell deletes the A-A, B-B, and B-B lifetimes with 0.00 values in a pandas dataframe. The dataframe can be stored as a csv for later use.\n",
    "'''\n",
    "nondes_hlife = nondes_hlife_frame[(nondes_hlife_frame['B-B'] > 0.0)]\n",
    "nondes_hlife.reset_index(drop=True, inplace=True)\n",
    "# nondes_hlife"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nondes_hlife.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nondes_hlife.to_excel('./nondes_hlife_01-23-2023.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NON-DES non-overlapping histo \n",
    "xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "non_des_fig = plt.figure()\n",
    "non_des_fig.set_size_inches(12, 10, forward=True)\n",
    "non_des_ax = non_des_fig.add_subplot(1,1,1)\n",
    "non_des_ax.set_xlabel(\"Hydrogen bond lifetime (ns)\", fontsize=28, weight='bold')\n",
    "non_des_ax.set_ylabel(\"Number of systems\", fontsize=28, weight='bold')\n",
    "ytick = np.arange(0,24, 2)\n",
    "xtick = np.arange(0,10, 0.5)\n",
    "plt.yticks(ytick,fontsize=26, weight='bold')\n",
    "plt.xticks(xtick,fontsize=26, weight='bold')\n",
    "# plt.title('Non-DES', fontsize=26, weight='bold')\n",
    "# non_des_hist = nondes_slice[['A-A', 'B-B', 'A-B']]\n",
    "# non_des_hist.plot.hist(bins=20, alpha=0.5, ylim=[0,16], ax =non_des_ax) \n",
    "# binss = np.linspace(0.09871825, 4.54204605, 10)\n",
    "# plt.hist([nondes_slice['A-A'], nondes_slice['B-B'], nondes_slice['A-B']], bins=binss, label=['A-A', 'B-B', 'A-B'])\n",
    "plt.hist([nondes_hlife['A-A'], nondes_hlife['B-B'], nondes_hlife['A-B']], bins=10, label=['A-A', 'B-B', 'A-B'])\n",
    "plt.legend(loc='upper left')\n",
    "non_des_fig.savefig(f'plots/distributions/nondes-hlife_nonoverlap_{xdate}.tiff', dpi=350,facecolor='white', bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lignin DES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DES\n",
    "''' This function takes in a path to GROMACS outputs from hydrogen bond calculations, and stores the \n",
    "A-A, B-B, and B-B lifetimes in a pandas dataframe. The dataframe can be stored as a csv for later use.\n",
    "'''\n",
    "\n",
    "pathway = Path()\n",
    "\n",
    "hlife_dict_lignin = {}\n",
    "\n",
    "for folderz in pathway.glob('./desfiles-irc/des/*'):\n",
    "    # print(folderz.stem)\n",
    "    dict_key = folderz.stem  #[6:]\n",
    "    hlife_list = []\n",
    "    for file in pathway.glob(f\"{folderz}/hbond-*\"):\n",
    "        # print(file)\n",
    "        if len(os.listdir(file)) < 5:\n",
    "            hlife_list.append(0)\n",
    "            continue\n",
    "\n",
    "        for txt in pathway.glob(f\"{file}/hlife*.txt\"):\n",
    "            # print(txt)\n",
    "            txtfile = txt.name\n",
    "            data = pd.read_csv('{}'.format(txt), sep='\\s+',\n",
    "                               header=None, skiprows=[0, 1])\n",
    "            data = pd.DataFrame(data)\n",
    "            x = data[0]/1000\n",
    "            y = data[2]\n",
    "            area = 0\n",
    "            # Change dx to 1 for files prior to 7 Sep 2020\n",
    "            area = simps(y, dx=0.01)\n",
    "            hlife_list.append(area)\n",
    "            # print(\"The area of {thing} is {val}\".format(thing= txt.stem, val=area))\n",
    "            # print(\"\\n\")\n",
    "\n",
    "    hlife_dict_lignin[f\"{dict_key}\"] = hlife_list\n",
    "    # print(hlife_dict_lignin)\n",
    "    # print(\"\\n\")\n",
    "\n",
    "DES = []\n",
    "AA = []\n",
    "AB = []\n",
    "BB = []\n",
    "\n",
    "for i in list(hlife_dict_lignin.items()):\n",
    "    # print(i)\n",
    "    DES.append(i[0])\n",
    "    AA.append(i[1][0])\n",
    "    AB.append(i[1][1])\n",
    "    BB.append(i[1][2])\n",
    "\n",
    "des_dict = {\n",
    "    \"DES\": DES,\n",
    "    \"A-A\": AA,\n",
    "    \"A-B\": AB,\n",
    "    \"B-B\": BB\n",
    "}\n",
    "des_hlife_frame_lignin = pd.DataFrame(des_dict, columns=[\"DES\", \"A-A\", \"B-B\", \"A-B\"])\n",
    "aa_dlife_lignin = des_hlife_frame_lignin['A-A']\n",
    "ab_dlife_lignin = des_hlife_frame_lignin['A-B']\n",
    "bb_dlife_lignin = des_hlife_frame_lignin['B-B']\n",
    "des_hlife_frame_lignin['A-A/B-B'] = aa_dlife_lignin/bb_dlife_lignin\n",
    "# des_hlife_frame_lignin['BB/AA'] = bb_dlife_lignin/aa_dlife_lignin\n",
    "des_hlife_frame_lignin['A-B/(A-A + B-B)'] = ab_dlife_lignin/(aa_dlife_lignin + bb_dlife_lignin)\n",
    "des_hlife_frame_lignin.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' This cell deletes the A-A, B-B, and B-B lifetimes with 0.00 values in a pandas dataframe. The dataframe can be stored as a csv for later use.\n",
    "'''\n",
    "des_hlife_lignin = des_hlife_frame_lignin[(des_hlife_frame_lignin['B-B'] > 0.0)]\n",
    "des_hlife_lignin.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DES non-overlapping histogram\n",
    "xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "des_fig_lignin = plt.figure()\n",
    "des_fig_lignin.set_size_inches(12, 10, forward=True)\n",
    "des_ax_lignin = des_fig_lignin.add_subplot(1,1,1)\n",
    "des_ax_lignin.set_xlabel(\"Hydrogen bond lifetime (ns)\", fontsize=24, weight='bold')\n",
    "des_ax_lignin.set_ylabel(\"Number of systems\", fontsize=24, weight='bold')\n",
    "ytick = np.arange(0,24, 2)\n",
    "xtick = np.arange(0,5.5, 0.5)\n",
    "plt.yticks(ytick,fontsize=22, weight='bold')\n",
    "plt.xticks(xtick,fontsize=22, weight='bold')\n",
    "plt.title('DES', fontsize=22, weight='bold')\n",
    "plt.ylim([0,12])\n",
    "# des_hist = des_slice[['A-A', 'B-B', 'A-B']]\n",
    "# des_hist.plot.hist(bins=20, alpha=0.5, ylim=[0,16], ax=des_ax_lignin)\n",
    "# binss = np.linspace(0.09871825, 4.54204605, 10)\n",
    "# binss = np.linspace(0.0, 4.0, 10)\n",
    "plt.hist([des_hlife_frame_lignin['A-A'], des_hlife_frame_lignin['B-B'], des_hlife_frame_lignin['A-B']], bins=10, label=['A-A', 'B-B', 'A-B'])\n",
    "# plt.hist([des_slice['A-A'], des_slice['B-B'], des_slice['A-B']], bins=binss, label=['A-A', 'B-B', 'A-B'])\n",
    "plt.legend(loc='upper left')\n",
    "# des_fig_lignin.savefig(f'plots/des_hlife_frame_lignin_nonoverlap_{xdate}.png', dpi=350,facecolor='white', bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lignin non-DES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NON-DES\n",
    "''' This function takes in a path to GROMACS outputs from hydrogen bond calculations, and stores the \n",
    "A-A, B-B, and B-B lifetimes in a pandas dataframe. The dataframe can be stored as a csv for later use.\n",
    "'''\n",
    "\n",
    "pathway = Path()\n",
    "\n",
    "hlife_dict_nondes = {}\n",
    "\n",
    "for folderz in pathway.glob('./desfiles-irc/nondes/*'):\n",
    "    # print(folderz.stem)\n",
    "    dict_key = folderz.stem\n",
    "    hlife_list = []\n",
    "    for file in pathway.glob(f\"{folderz}/hbond-*-?-?\"):\n",
    "        # print(file)\n",
    "        if len(os.listdir(file)) < 5:\n",
    "            hlife_list.append(0)\n",
    "            continue\n",
    "\n",
    "        for txt in pathway.glob(f\"{file}/hlife*.txt\"):\n",
    "            # print(txt)\n",
    "            txtfile = txt.name\n",
    "            data = pd.read_csv('{}'.format(txt), sep='\\s+',\n",
    "                               header=None, skiprows=[0, 1])\n",
    "            data = pd.DataFrame(data)\n",
    "            x = data[0]/1000\n",
    "            y = data[2]\n",
    "            area = 0\n",
    "            # Change dx to 1 for files prior to 7 Sep 2020\n",
    "            area = simps(y, dx=0.01)\n",
    "            hlife_list.append(area)\n",
    "            # print(\"The area of {thing} is {val}\".format(thing= txt.stem, val=area))\n",
    "            # print(\"\\n\")\n",
    "\n",
    "    hlife_dict_nondes[f\"{dict_key}\"] = hlife_list\n",
    "    # print(hlife_dict_nondes)\n",
    "    # print(\"\\n\")\n",
    "\n",
    "# print(hlife_dict_nondes)\n",
    "NONDES = []\n",
    "AA_ = []\n",
    "AB_ = []\n",
    "BB_ = []\n",
    "\n",
    "for i in list(hlife_dict_nondes.items()):\n",
    "    # print(i)\n",
    "    NONDES.append(i[0])\n",
    "    AA_.append(i[1][0])\n",
    "    AB_.append(i[1][1])\n",
    "    BB_.append(i[1][2])\n",
    "\n",
    "nondes_dict_lignin = {\n",
    "    \"Non-DES\": NONDES,\n",
    "    \"A-A\": AA_,\n",
    "    \"A-B\": AB_,\n",
    "    \"B-B\": BB_\n",
    "}\n",
    "nondes_hlife_frame_lignin = pd.DataFrame(\n",
    "    nondes_dict_lignin, columns=[\"Non-DES\", \"A-A\", \"B-B\", \"A-B\"])\n",
    "aa_nlife_lignin = nondes_hlife_frame_lignin['A-A']\n",
    "ab_nlife_lignin = nondes_hlife_frame_lignin['A-B']\n",
    "bb_nlife_lignin = nondes_hlife_frame_lignin['B-B']\n",
    "nondes_hlife_frame_lignin['A-A/B-B'] = aa_nlife_lignin/bb_nlife_lignin\n",
    "# nondes_hlife_frame_lignin['BB/AA'] = bb_nlife_lignin/aa_nlife_lignin\n",
    "nondes_hlife_frame_lignin['A-B/(A-A + B-B)'] = ab_nlife_lignin/(aa_nlife_lignin + bb_nlife_lignin)\n",
    "# nondes_hlife_frame_lignin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' This cell deletes the A-A, B-B, and B-B lifetimes with 0.00 values in a pandas dataframe. The dataframe can be stored as a csv for later use.\n",
    "'''\n",
    "nondes_hlife_lignin = nondes_hlife_frame_lignin[(nondes_hlife_frame_lignin['B-B'] > 0.0)]\n",
    "nondes_hlife_lignin.reset_index(drop=True, inplace=True)\n",
    "# nondes_hlife_lignin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nondes_hlife_frame.to_excel('./nondes_hlife_01-23-2023.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NON-DES non-overlapping histo \n",
    "xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "non_des_fig_lignin = plt.figure()\n",
    "non_des_fig_lignin.set_size_inches(12, 10, forward=True)\n",
    "non_des_ax_lignin = non_des_fig_lignin.add_subplot(1,1,1)\n",
    "non_des_ax_lignin.set_xlabel(\"Hydrogen bond lifetime (ns)\", fontsize=24, weight='bold')\n",
    "non_des_ax_lignin.set_ylabel(\"Number of systems\", fontsize=24, weight='bold')\n",
    "ytick = np.arange(0,24, 2)\n",
    "xtick = np.arange(0,10, 0.5)\n",
    "plt.yticks(ytick,fontsize=22, weight='bold')\n",
    "plt.xticks(xtick,fontsize=22, weight='bold')\n",
    "plt.title('Non-DES', fontsize=22, weight='bold')\n",
    "plt.ylim([0,12])\n",
    "# non_des_hist = nondes_slice[['A-A', 'B-B', 'A-B']]\n",
    "# non_des_hist.plot.hist(bins=20, alpha=0.5, ylim=[0,16], ax =non_des_ax_lignin) \n",
    "# binss = np.linspace(0.09871825, 4.54204605, 10)\n",
    "# plt.hist([nondes_slice['A-A'], nondes_slice['B-B'], nondes_slice['A-B']], bins=binss, label=['A-A', 'B-B', 'A-B'])\n",
    "plt.hist([nondes_hlife_lignin['A-A'], nondes_hlife_lignin['B-B'], nondes_hlife_lignin['A-B']], bins=10, label=['A-A', 'B-B', 'A-B'])\n",
    "plt.legend(loc='upper left')\n",
    "# non_des_fig_lignin.savefig(f'plots/distributions/nondes-ligninhlife_nonoverlap_{xdate}.png', dpi=350,facecolor='white', bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DES and non-DES hbond numbers\n",
    "Creation and cleaning up of dataframes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' This function takes in a path to GROMACS outputs from hydrogen bond calculations, and stores the \n",
    "A-A, B-B, and B-B numtimes in a pandas dataframe. The dataframe can be stored as a csv for later use.\n",
    "'''\n",
    "\n",
    "pathway = Path()\n",
    "\n",
    "hnum_dict = {}\n",
    "\n",
    "for folderz in pathway.glob('./h*-avg-files/des/*'):\n",
    "    # print(folderz.stem)\n",
    "    dict_key = folderz.stem[6:]\n",
    "    hnum_list = []\n",
    "    for file in pathway.glob(f\"{folderz}/hlife-*\"):\n",
    "        # print(file)\n",
    "        if len(os.listdir(file)) == 0:\n",
    "            hnum_list.append(0)\n",
    "            continue\n",
    "\n",
    "        for txt in pathway.glob(f\"{file}/hnum*.txt\"):\n",
    "            # print(txt)\n",
    "            txtfile = txt.name\n",
    "            data = pd.read_csv('{}'.format(txt), sep='\\s+',\n",
    "                               header=None, skiprows=[0, 1])\n",
    "            data = pd.DataFrame(data)\n",
    "            y = data[1]\n",
    "            avg = 0\n",
    "            avg = np.average(y)  # Change dx to 1 for files prior to 7 Sep 2020\n",
    "            hnum_list.append(avg)\n",
    "            # print(\"The avg of {thing} is {val}\".format(thing= txt.stem, val=avg))\n",
    "            # print(\"\\n\")\n",
    "\n",
    "    hnum_dict[f\"{dict_key}\"] = hnum_list\n",
    "    # print(hnum_dict)\n",
    "    # print(\"\\n\")\n",
    "\n",
    "DES = []\n",
    "AA = []\n",
    "AB = []\n",
    "BB = []\n",
    "\n",
    "for i in list(hnum_dict.items()):\n",
    "    # print(i)\n",
    "    DES.append(i[0])\n",
    "    AA.append(i[1][0])\n",
    "    AB.append(i[1][1])\n",
    "    BB.append(i[1][2])\n",
    "\n",
    "des_dict = {\n",
    "    \"DES\": DES,\n",
    "    \"A-A\": AA,\n",
    "    \"A-B\": AB,\n",
    "    \"B-B\": BB\n",
    "}\n",
    "des_hnum_frame = pd.DataFrame(des_dict, columns=[\"DES\", \"A-A\", \"B-B\", \"A-B\"])\n",
    "# des_hnum_frame\n",
    "aa_dnum = des_hnum_frame['A-A']\n",
    "ab_dnum = des_hnum_frame['A-B']\n",
    "bb_dnum = des_hnum_frame['B-B']\n",
    "des_hnum_frame['A-A/B-B'] = aa_dnum/bb_dnum\n",
    "# des_hnum_frame['BB/AA'] = bb_dnum/aa_dnum\n",
    "des_hnum_frame['A-B/(A-A + B-B)'] = ab_dnum/(aa_dnum + bb_dnum)\n",
    "des_hnum_frame.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "des_hnum_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' This cell deletes the A-A, B-B, and B-B lifetimes with 0.00 values in a pandas dataframe. The dataframe can be stored as a csv for later use.\n",
    "'''\n",
    "des_hnum = des_hnum_frame[(des_hnum_frame['B-B'] > 0.0)]\n",
    "des_hnum.reset_index(drop=True, inplace=True)\n",
    "# des_hnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "des_hnum.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# des_hnum.describe().to_excel('./des_hnum_new_summary.xlsx')\n",
    "# des_hnum.to_excel('./des_hnum_01-23-2023.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-overlapping histo DES\n",
    "xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "des_fig = plt.figure()\n",
    "des_fig.set_size_inches(12, 10, forward=True)\n",
    "des_ax = des_fig.add_subplot(1,1,1)\n",
    "des_ax.set_xlabel(\"Hydrogen bond number\", fontsize=28, weight='bold')\n",
    "des_ax.set_ylabel(\"Number of systems\", fontsize=28, weight='bold')\n",
    "ytick = np.arange(0,40, 4)\n",
    "xtick = np.arange(0,140, 10)\n",
    "plt.yticks(ytick,fontsize=26, weight='bold')\n",
    "plt.xticks(xtick,fontsize=26, weight='bold')\n",
    "# plt.title('DES', fontsize=22, weight='bold')\n",
    "plt.ylim([0,40])\n",
    "# des = des[['AA', 'BB', 'AB']]\n",
    "# des.plot.hist(bins=20, alpha=0.5, ylim=[0,22], ax=des_ax)\n",
    "plt.hist([des_hnum['A-A'], des_hnum['B-B'], des_hnum['A-B']], bins=10, label=['A-A', 'B-B', 'A-B'])\n",
    "# plt.hist([des['A-A'], des['B-B'], des['A-B']], bins=binss, label=['A-A', 'B-B', 'A-B'])\n",
    "plt.legend(loc='upper right', prop={'weight':'bold'})\n",
    "des_fig.savefig(f'./plots/distributions/des_hnum_nonoverlap_{xdate}.tiff', dpi=350,facecolor='white', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lignin DES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' This function takes in a path to GROMACS outputs from hydrogen bond calculations, and stores the \n",
    "A-A, B-B, and B-B numtimes in a pandas dataframe. The dataframe can be stored as a csv for later use.\n",
    "'''\n",
    "\n",
    "pathway = Path()\n",
    "\n",
    "hnum_dict_lignin = {}\n",
    "\n",
    "for folderz in pathway.glob('./desfiles-irc/des/*'):\n",
    "    # print(folderz.stem)\n",
    "    dict_key = folderz.stem\n",
    "    hnum_list = []\n",
    "    for file in pathway.glob(f\"{folderz}/hbond-*\"):\n",
    "        # print(file)\n",
    "        if len(os.listdir(file)) < 5:\n",
    "            hnum_list.append(0)\n",
    "            continue\n",
    "\n",
    "        for txt in pathway.glob(f\"{file}/hnum*.txt\"):\n",
    "            # print(txt)\n",
    "            txtfile = txt.name\n",
    "            data = pd.read_csv('{}'.format(txt), sep='\\s+',\n",
    "                               header=None, skiprows=[0, 1])\n",
    "            data = pd.DataFrame(data)\n",
    "            y = data[1]\n",
    "            avg = 0\n",
    "            avg = np.average(y)  # Change dx to 1 for files prior to 7 Sep 2020\n",
    "            hnum_list.append(avg)\n",
    "            # print(\"The avg of {thing} is {val}\".format(thing= txt.stem, val=avg))\n",
    "            # print(\"\\n\")\n",
    "\n",
    "    hnum_dict_lignin[f\"{dict_key}\"] = hnum_list\n",
    "    # print(hnum_dict_lignin)\n",
    "    # print(\"\\n\")\n",
    "\n",
    "DES = []\n",
    "AA = []\n",
    "AB = []\n",
    "BB = []\n",
    "\n",
    "for i in list(hnum_dict_lignin.items()):\n",
    "    # print(i)\n",
    "    DES.append(i[0])\n",
    "    AA.append(i[1][0])\n",
    "    AB.append(i[1][1])\n",
    "    BB.append(i[1][2])\n",
    "\n",
    "des_dict = {\n",
    "    \"DES\": DES,\n",
    "    \"A-A\": AA,\n",
    "    \"A-B\": AB,\n",
    "    \"B-B\": BB\n",
    "}\n",
    "des_hnum_frame_lignin = pd.DataFrame(des_dict, columns=[\"DES\", \"A-A\", \"B-B\", \"A-B\"])\n",
    "# des_hnum_frame_lignin\n",
    "aa_dnum_lignin = des_hnum_frame_lignin['A-A']\n",
    "ab_dnum_lignin = des_hnum_frame_lignin['A-B']\n",
    "bb_dnum_lignin = des_hnum_frame_lignin['B-B']\n",
    "des_hnum_frame_lignin['A-A/B-B'] = aa_dnum_lignin/bb_dnum_lignin\n",
    "# des_hnum_frame_lignin['BB/AA'] = bb_dnum_lignin/aa_dnum_lignin\n",
    "des_hnum_frame_lignin['A-B/(A-A + B-B)'] = ab_dnum_lignin/(aa_dnum_lignin + bb_dnum_lignin)\n",
    "des_hnum_frame_lignin.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "des_hnum_frame_lignin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' This cell deletes the A-A, B-B, and B-B lifetimes with 0.00 values in a pandas dataframe. The dataframe can be stored as a csv for later use.\n",
    "'''\n",
    "des_hnum_lignin = des_hnum_frame_lignin[(des_hnum_frame_lignin['B-B'] > 0.0)]\n",
    "des_hnum_lignin.reset_index(drop=True, inplace=True)\n",
    "# des_hnum_lignin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "des_hnum_lignin.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# des_hnum_lignin.describe().to_excel('./des_lignin_hnum_summary.xlsx')\n",
    "# des_hnum_lignin.to_excel('./des_lignin_hnum.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-overlapping histo DES\n",
    "xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "des_fig_lignin = plt.figure()\n",
    "des_fig_lignin.set_size_inches(12, 8, forward=True)\n",
    "des_ax_lignin = des_fig_lignin.add_subplot(1,1,1)\n",
    "des_ax_lignin.set_xlabel(\"Hydrogen bond number\", fontsize=24, weight='bold')\n",
    "des_ax_lignin.set_ylabel(\"Number of systems\", fontsize=24, weight='bold')\n",
    "ytick = np.arange(0,40, 2)\n",
    "xtick = np.arange(0,140, 10)\n",
    "plt.yticks(ytick,fontsize=22, weight='bold')\n",
    "plt.xticks(xtick,fontsize=22, weight='bold')\n",
    "plt.title('DES', fontsize=22, weight='bold')\n",
    "plt.ylim([0,12])\n",
    "# des = des[['AA', 'BB', 'AB']]\n",
    "# des.plot.hist(bins=20, alpha=0.5, ylim=[0,22], ax=des_ax_lignin)\n",
    "plt.hist([des_hnum_lignin['A-A'], des_hnum_lignin['B-B'], des_hnum_lignin['A-B']], bins=10, label=['A-A', 'B-B', 'A-B'])\n",
    "# plt.hist([des['A-A'], des['B-B'], des['A-B']], bins=binss, label=['A-A', 'B-B', 'A-B'])\n",
    "plt.legend(loc='upper right', prop={'weight':'bold'})\n",
    "des_fig_lignin.savefig(f'des_hnum_lignin_nonoverlap_{xdate}.png', dpi=350,facecolor='white', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### non-DES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' This function takes in a path to GROMACS outputs from hydrogen bond calculations, and stores the \n",
    "A-A, B-B, and B-B numtimes in a pandas dataframe. The dataframe can be stored as a csv for later use.\n",
    "'''\n",
    "\n",
    "pathway = Path()\n",
    "\n",
    "hnum_dict_nondes = {}\n",
    "\n",
    "for folderz in pathway.glob('./h*-avg-files/nondes/*'):\n",
    "    # print(folderz.stem)\n",
    "    dict_key = folderz.stem[6:]\n",
    "    hnum_list_nondes = []\n",
    "    for file in pathway.glob(f\"{folderz}/hlife-???-*\"):\n",
    "        # print(file)\n",
    "        if len(os.listdir(file)) < 5:\n",
    "            hnum_list_nondes.append(0)\n",
    "            continue\n",
    "\n",
    "        for txt in pathway.glob(f\"{file}/hnum*.txt\"):\n",
    "            # print(txt)\n",
    "            txtfile = txt.name\n",
    "            data = pd.read_csv('{}'.format(txt), sep='\\s+',\n",
    "                               header=None, skiprows=[0, 1])\n",
    "            data = pd.DataFrame(data)\n",
    "            y = data[1]\n",
    "            avg = 0\n",
    "            avg = np.average(y)  # Change dx to 1 for files prior to 7 Sep 2020\n",
    "            hnum_list_nondes.append(avg)\n",
    "            # print(\"The avg of {thing} is {val}\".format(thing= txt.stem, val=avg))\n",
    "            # print(\"\\n\")\n",
    "\n",
    "    hnum_dict_nondes[f\"{dict_key}\"] = hnum_list_nondes\n",
    "    # print(hnum_dict_nondes)\n",
    "    # print(\"\\n\")\n",
    "\n",
    "NONDES = []\n",
    "AA = []\n",
    "AB = []\n",
    "BB = []\n",
    "\n",
    "for i in list(hnum_dict_nondes.items()):\n",
    "    # print(i)\n",
    "    NONDES.append(i[0])\n",
    "    AA.append(i[1][0])\n",
    "    AB.append(i[1][1])\n",
    "    BB.append(i[1][2])\n",
    "    # try:\n",
    "    #     BB.append(i[1][2])\n",
    "    # except:\n",
    "    #     BB.append(0)\n",
    "\n",
    "nondes_dict = {\n",
    "    \"DES\": NONDES,\n",
    "    \"A-A\": AA,\n",
    "    \"A-B\": AB,\n",
    "    \"B-B\": BB\n",
    "}\n",
    "nondes_hnum_frame = pd.DataFrame(nondes_dict, columns=[\"DES\", \"A-A\", \"B-B\", \"A-B\"])\n",
    "# nondes_hnum_frame\n",
    "aa_nnum = nondes_hnum_frame['A-A']\n",
    "ab_nnum = nondes_hnum_frame['A-B']\n",
    "bb_nnum = nondes_hnum_frame['B-B']\n",
    "nondes_hnum_frame['A-A/B-B'] = aa_nnum/bb_nnum\n",
    "# nondes_hnum_frame['BB/AA'] = bb_nnum/aa_nnum\n",
    "nondes_hnum_frame['A-B/(A-A + B-B)'] = ab_nnum/(aa_nnum + bb_nnum)\n",
    "nondes_hnum_frame.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nondes_hnum_frame.to_csv('./nondes_investigation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' This cell deletes the A-A, B-B, and B-B lifetimes with 0.00 values in a pandas dataframe. The dataframe can be stored as a csv for later use.\n",
    "'''\n",
    "nondes_hnum = nondes_hnum_frame[(nondes_hnum_frame['B-B'] > 0.0)]\n",
    "nondes_hnum.reset_index(drop=True, inplace=True)\n",
    "# nondes_hnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nondes_hnum.describe().to_excel('./nondes_hnum_new_summary.xlsx')\n",
    "# nondes_hnum.to_excel('./nondes_hnum_01-23-2023.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-overlapping histo NON-DES\n",
    "xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "non_des_fig = plt.figure()\n",
    "non_des_fig.set_size_inches(12, 10, forward=True)\n",
    "non_des_ax = non_des_fig.add_subplot(1,1,1)\n",
    "non_des_ax.set_xlabel(\"Hydrogen bond number\", fontsize=28, weight='bold')\n",
    "non_des_ax.set_ylabel(\"Number of systems\", fontsize=28, weight='bold')\n",
    "ytick = np.arange(0,40, 4)\n",
    "xtick = np.arange(0,90, 10)\n",
    "plt.yticks(ytick,fontsize=26, weight='bold')\n",
    "plt.xticks(xtick,fontsize=26, weight='bold')\n",
    "# plt.title('Non-DES', fontsize=22, weight='bold')\n",
    "plt.ylim([0,40])\n",
    "# non_des_hist = non_des[['AA', 'BB', 'AB']]\n",
    "# non_des_hist.plot.hist(bins=20, alpha=0.5, ylim=[0,22], ax =non_des_ax) # ylim=[0,22], \n",
    "plt.hist([nondes_hnum['A-A'], nondes_hnum['B-B'], nondes_hnum['A-B']], bins=10, label=['A-A', 'B-B', 'A-B'])\n",
    "plt.legend(loc='upper right', prop={'weight':'bold'})\n",
    "non_des_fig.savefig(f'./plots/distributions/nondes_hnum_nonoverlap_{xdate}.tiff', dpi=350,facecolor='white', bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lignin non-DES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' This function takes in a path to GROMACS outputs from hydrogen bond calculations, and stores the \n",
    "A-A, B-B, and B-B numtimes in a pandas dataframe. The dataframe can be stored as a csv for later use.\n",
    "'''\n",
    "\n",
    "pathway = Path()\n",
    "\n",
    "hnum_dict_nondes_lignin = {}\n",
    "\n",
    "for folderz in pathway.glob('./desfiles-irc/nondes/*'):\n",
    "    # print(folderz.stem)\n",
    "    dict_key = folderz.stem\n",
    "    hnum_list_nondes = []\n",
    "    for file in pathway.glob(f\"{folderz}/hbond-???-*\"):\n",
    "        # print(file)\n",
    "        if len(os.listdir(file)) < 3:\n",
    "            hnum_list_nondes.append(0)\n",
    "            continue\n",
    "\n",
    "        for txt in pathway.glob(f\"{file}/hnum*.txt\"):\n",
    "            # print(txt)\n",
    "            txtfile = txt.name\n",
    "            data = pd.read_csv('{}'.format(txt), sep='\\s+',\n",
    "                               header=None, skiprows=[0, 1])\n",
    "            data = pd.DataFrame(data)\n",
    "            y = data[1]\n",
    "            avg = 0\n",
    "            avg = np.average(y)  # Change dx to 1 for files prior to 7 Sep 2020\n",
    "            hnum_list_nondes.append(avg)\n",
    "            # print(\"The avg of {thing} is {val}\".format(thing= txt.stem, val=avg))\n",
    "            # print(\"\\n\")\n",
    "\n",
    "    hnum_dict_nondes_lignin[f\"{dict_key}\"] = hnum_list_nondes\n",
    "    # print(hnum_dict_nondes_lignin)\n",
    "    # print(\"\\n\")\n",
    "\n",
    "NONDES = []\n",
    "AA = []\n",
    "AB = []\n",
    "BB = []\n",
    "\n",
    "for i in list(hnum_dict_nondes_lignin.items()):\n",
    "    # print(i)\n",
    "    NONDES.append(i[0])\n",
    "    AA.append(i[1][0])\n",
    "    AB.append(i[1][1])\n",
    "    BB.append(i[1][2])\n",
    "    # try:\n",
    "    #     BB.append(i[1][2])\n",
    "    # except:\n",
    "    #     BB.append(0)\n",
    "\n",
    "nondes_dict_lignin = {\n",
    "    \"DES\": NONDES,\n",
    "    \"A-A\": AA,\n",
    "    \"A-B\": AB,\n",
    "    \"B-B\": BB\n",
    "}\n",
    "nondes_hnum_frame_lignin = pd.DataFrame(nondes_dict_lignin, columns=[\"DES\", \"A-A\", \"B-B\", \"A-B\"])\n",
    "# nondes_hnum_frame_lignin\n",
    "aa_nnum_lignin = nondes_hnum_frame_lignin['A-A']\n",
    "ab_nnum_lignin = nondes_hnum_frame_lignin['A-B']\n",
    "bb_nnum_lignin = nondes_hnum_frame_lignin['B-B']\n",
    "nondes_hnum_frame_lignin['A-A/B-B'] = aa_nnum_lignin/bb_nnum_lignin\n",
    "# nondes_hnum_frame_lignin['BB/AA'] = bb_nnum_lignin/aa_nnum_lignin\n",
    "nondes_hnum_frame_lignin['A-B/(A-A + B-B)'] = ab_nnum_lignin/(aa_nnum_lignin + bb_nnum_lignin)\n",
    "nondes_hnum_frame_lignin.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nondes_hnum_frame_lignin.to_excel('./nondes_lignin_hnum.xlsx')\n",
    "# nondes_hnum_frame_lignin.describe().to_excel('./nondes_lignin_hnum_summary.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' This cell deletes the A-A, B-B, and B-B lifetimes with 0.00 values in a pandas dataframe. The dataframe can be stored as a csv for later use.\n",
    "'''\n",
    "nondes_hnum_lignin = nondes_hnum_frame_lignin[(nondes_hnum_frame_lignin['B-B'] > 0.0)]\n",
    "nondes_hnum_lignin.reset_index(drop=True, inplace=True)\n",
    "# nondes_hnum_lignin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-overlapping histo NON-DES\n",
    "xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "non_des_fig_lignin = plt.figure()\n",
    "non_des_fig_lignin.set_size_inches(12, 8, forward=True)\n",
    "non_des_ax_lignin = non_des_fig_lignin.add_subplot(1,1,1)\n",
    "non_des_ax_lignin.set_xlabel(\"Hydrogen bond number\", fontsize=24, weight='bold')\n",
    "non_des_ax_lignin.set_ylabel(\"Number of systems\", fontsize=24, weight='bold')\n",
    "ytick = np.arange(0,40, 2)\n",
    "xtick = np.arange(0,90, 10)\n",
    "plt.yticks(ytick,fontsize=22, weight='bold')\n",
    "plt.xticks(xtick,fontsize=22, weight='bold')\n",
    "plt.title('Non-DES', fontsize=22, weight='bold')\n",
    "plt.ylim([0,12])\n",
    "# non_des_hist = non_des[['AA', 'BB', 'AB']]\n",
    "# non_des_hist.plot.hist(bins=20, alpha=0.5, ylim=[0,22], ax =non_des_ax_lignin) # ylim=[0,22], \n",
    "plt.hist([nondes_hnum_lignin['A-A'], nondes_hnum_lignin['B-B'], nondes_hnum_lignin['A-B']], bins=10, label=['A-A', 'B-B', 'A-B'])\n",
    "plt.legend(loc='upper right', prop={'weight':'bold'})\n",
    "non_des_fig_lignin.savefig(f'nondes_hnum_lignin_nonoverlap_{xdate}.png', dpi=350,facecolor='white', bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dirmaker(path):\n",
    "    '''\n",
    "    path is the folder path you want to make if it exists\n",
    "    '''\n",
    "    if os.path.isdir(path):\n",
    "        pass\n",
    "    else:\n",
    "        os.mkdir(path)\n",
    "        pass\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### data generation for hnum or hlife\n",
    "This generates random data samples of training and testing set for hnum or hlife scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(des, nondes, test_sample_size=8, nondes_batch_size=38, random_state=1):\n",
    "    '''\n",
    "    This generates batches of equally sized data samples from two dataframes\n",
    "    and returns training and testing data sets.\n",
    "    random_state ensures replicability.\n",
    "    '''\n",
    "    des_test_df = des.sample(\n",
    "        n=test_sample_size, replace=False, random_state=random_state)\n",
    "    nondes_batch_df = nondes.sample(\n",
    "        n=nondes_batch_size, replace=False, random_state=random_state)\n",
    "    nondes_test_df = nondes_batch_df.sample(\n",
    "        n=test_sample_size, replace=False, random_state=random_state)\n",
    "    df = [des, nondes_batch_df, des_test_df, nondes_test_df]\n",
    "    df_train = pd.concat(df).drop_duplicates(keep=False)\n",
    "    df_train = df_train.reset_index()\n",
    "    # print(df_train.drop(columns=['output','index']).describe())\n",
    "\n",
    "    df_test_list = [des_test_df, nondes_test_df]\n",
    "    df_test = pd.concat(df_test_list).drop_duplicates(keep=False)\n",
    "    df_test = df_test.reset_index()\n",
    "    # print(df_test.drop(columns=['output','index']).describe())\n",
    "\n",
    "    X_train = np.array(df_train.drop(columns=['output', 'index']))\n",
    "    y_train = np.array(df_train['output'])\n",
    "\n",
    "    X_test = np.array(df_test.drop(columns=['output', 'index']))\n",
    "    y_test = np.array(df_test['output'])\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### data generation for merged\n",
    "This generates only training and testing data for hnum + hlife scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_generator(des, nondes, test_sample_size=8, nondes_batch_size=38, random_state=1):\n",
    "    '''\n",
    "    This generates batches of equally sized data samples from two dataframes\n",
    "    and returns training and testing data sets.\n",
    "    '''\n",
    "    des_test_df = des.sample(n=test_sample_size, replace=False, random_state=random_state)\n",
    "    nondes_batch_df = nondes.sample(n=nondes_batch_size, replace=False, random_state=random_state)\n",
    "    nondes_test_df = nondes_batch_df.sample(n=test_sample_size, replace=False, random_state=random_state)\n",
    "    df = [des, nondes_batch_df, des_test_df, nondes_test_df]\n",
    "    df_train = pd.concat(df).drop_duplicates(keep=False)\n",
    "    df_train = df_train.reset_index()\n",
    "    # print(df_train.drop(columns=['output','index']).describe())\n",
    "\n",
    "    df_test_list = [des_test_df, nondes_test_df]\n",
    "    df_test = pd.concat(df_test_list).drop_duplicates(keep=False)\n",
    "    df_test = df_test.reset_index()\n",
    "\n",
    "    X_train = np.array(df_train.drop(\n",
    "        columns=['output_l', 'output_n', 'index']))\n",
    "    y_train = np.array(df_train['output_n'])\n",
    "\n",
    "    X_test = np.array(df_test.drop(columns=['output_l', 'output_n', 'index']))\n",
    "    y_test = np.array(df_test['output_n'])\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### data generation for only CV\n",
    "Generates X_train and y_train that can then be split into train/test by the model.\n",
    "Useful for CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_crossval(des, nondes, batch_size=38, random_state=1):\n",
    "    '''\n",
    "    This generates batches of equally sized data samples from two dataframes\n",
    "    and returns training datasets.\n",
    "    '''\n",
    "    nondes_batch_df = nondes.sample(n=batch_size, replace=False, random_state=random_state)\n",
    "    df = [des, nondes_batch_df]\n",
    "    df_train = pd.concat(df).drop_duplicates(keep=False)\n",
    "    df_train = df_train.reset_index()\n",
    "\n",
    "    X_train = np.array(df_train.drop(columns=['output', 'index']))\n",
    "    y_train = np.array(df_train['output'])\n",
    "\n",
    "    return X_train, y_train\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training loop functions\n",
    "Functions for training different model types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ab_dt_ef_gb_rf(model, des_df, nondes_df, file_name, folder_type='unclassified', num=100, rand_seed=1000, features=features):\n",
    "    '''\n",
    "    This function trains a model on hnum/hlife/merged data.\n",
    "    Works with sklearn GradBoost, AdaBoost, RandomForest,\n",
    "    ExtraTreesForest, and DecisionTrees. It trains\n",
    "    for num loops.\n",
    "\n",
    "    model is the model instance,\n",
    "    des_df and nondes_df are the DES and non-DES data,    \n",
    "    file_name is the txt file for logs,\n",
    "    folder_type can be hlife, hnum, merged, or unclassified.\n",
    "    n_repeats is passed to grid search,\n",
    "    rand_seed ensures replicability of CV.\n",
    "    '''\n",
    "    xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "    # print(xdate)\n",
    "\n",
    "    roc_auc_list = []\n",
    "    folder_name = folder_type\n",
    "    model_name = model.__str__().split('(')[0]\n",
    "    if model_name.__contains__(\"XGBClassifier\"):\n",
    "        model_name = \"XGBClassifier\"\n",
    "\n",
    "        \n",
    "    # file = open(f\"./model-logs/hlife_{num}_{xdate}.txt\", \"w+\")\n",
    "    file = file_name\n",
    "    if folder_name == 'hlife' or folder_name == 'hnum':  # hlife/hnum have only 5 features\n",
    "        coeff = [0, 0, 0, 0, 0]\n",
    "    elif folder_name == 'merged':  # merged has 10 features\n",
    "        coeff = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    else:\n",
    "        coeff = [0, 0, 0, 0, 0]\n",
    "\n",
    "    for x in trange(num):\n",
    "        print(f\"Starting round {x+1}\", file=file)\n",
    "        if folder_name == 'hlife' or folder_name == 'hnum':\n",
    "            X_train, y_train, X_test, y_test = data_generator(\n",
    "                des_df, nondes_df, test_sample_size=8, nondes_batch_size=38, random_state=x)\n",
    "        elif folder_name == 'merged':\n",
    "            X_train, y_train, X_test, y_test = df_generator(\n",
    "                des_df, nondes_df, test_sample_size=8, nondes_batch_size=38, random_state=x)\n",
    "        else:\n",
    "            print(\"Check folder_type variable\")\n",
    "\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_proba = model.predict_proba(X_test)  # roc_auc_score needs probabilities\n",
    "        print(f'Prediction probabilities: \\n{y_pred_proba}', file=file)\n",
    "        # print('Prediction probabilities: \\n', y_pred_proba)\n",
    "        print(f'Predictions: {y_pred}', file=file)\n",
    "        # print('Predictions: ', y_pred)\n",
    "        target_names = ['non-DES', 'DES']  # non-DES is 0, DES is 1\n",
    "        print(metrics.classification_report(y_test, y_pred,\n",
    "            target_names=target_names), file=file)\n",
    "        roc_auc = metrics.roc_auc_score(y_test, y_pred_proba[:,1])\n",
    "        print(f\"roc_auc_score: {roc_auc}\", file=file)\n",
    "        roc_auc_list.append(roc_auc)\n",
    "        print(model.feature_importances_, file=file)\n",
    "        # print(f\"intercept: {model.intercept_}\", file=file)\n",
    "\n",
    "        model_feature_df = pd.DataFrame(\n",
    "            {'Importance': model.feature_importances_, 'Features': features})\n",
    "        max_coeff_index = list(model.feature_importances_).index(model.feature_importances_.max())\n",
    "        print(\n",
    "            f'max feature: {model.feature_importances_.max()} at index {max_coeff_index} [{features[max_coeff_index]}]', file=file)\n",
    "        coeff[max_coeff_index] += 1\n",
    "        print('\\n', file=file)\n",
    "        print(model_feature_df, file=file)\n",
    "        print('\\n'*2, file=file)\n",
    "    \n",
    "    # save model\n",
    "    dirmaker(f'./saved-models/{folder_name}/{xdate}')\n",
    "    dump(model, f'./saved-models/{folder_name}/{xdate}/{model_name}_{folder_name}.joblib')\n",
    "\n",
    "    # plotting roc_auc score\n",
    "    fig = plt.figure()\n",
    "    fig.set_size_inches(12, 10, forward=True)\n",
    "    fig_ax = fig.add_subplot(1, 1, 1)\n",
    "    fig_ax.set_xlabel(\"Number of runs\", fontsize=24, weight='bold')\n",
    "    fig_ax.set_ylabel(\"ROC-AUC score\", fontsize=24, weight='bold')\n",
    "\n",
    "    if folder_name == 'hlife':\n",
    "        title_tag = 'lifetimes'\n",
    "    elif folder_name == 'hnum':\n",
    "        title_tag = 'numbers'\n",
    "    elif folder_name == 'merged':\n",
    "        title_tag = 'numbers + lifetimes'\n",
    "    else:\n",
    "        title_tag = ''  # this could be an indication that the folder_type was not set properly\n",
    "\n",
    "\n",
    "    ytick = np.arange(0, 1.2, 0.2)\n",
    "    xtick = np.arange(0, num+2, 10)\n",
    "    plt.yticks(ytick, fontsize=22, weight='bold')\n",
    "    plt.xticks(xtick, fontsize=22, weight='bold')\n",
    "    fig_ax.set_ylim(0, 1.0)\n",
    "    fig_ax.set_xlim(0, num+2)\n",
    "    # plt.title(f'{model_name} hbond {title_tag}', fontsize=22, weight='bold')\n",
    "\n",
    "\n",
    "    roc = [z for z in range(1, num+1)]\n",
    "    print(f\"roc_auc scores: {roc_auc_list}\", file=file)\n",
    "    print(\n",
    "        f\"Average roc_auc scores: {np.average(roc_auc_list)}\", file=file)\n",
    "    print(\n",
    "        f\"std dev of roc_auc scores: {np.std(roc_auc_list)}\", file=file)\n",
    "    print(\n",
    "        f\"Best roc_auc score: {max(roc_auc_list)} at index {roc_auc_list.index(max(roc_auc_list)) + 1}\", file=file)\n",
    "    print('\\n', file=file)\n",
    "    coeff_df = pd.DataFrame(\n",
    "        {'Top Coefficients': coeff, 'Features': features})\n",
    "    print(f\"{coeff_df}\", file=file)\n",
    "    plt.plot(roc, roc_auc_list, '-o', linewidth=2, markersize=8.0, label=f\"avg roc_auc: {round(np.average(roc_auc_list),2)}\\nstd roc_auc : {round(np.std(roc_auc_list),2)}\")\n",
    "    plt.legend(loc='lower left', fontsize=16)\n",
    "    plt.show()\n",
    "    file.close()\n",
    "    dirmaker(f'./plots/roc-auc/{folder_name}/{xdate}')\n",
    "    fig.savefig(f'plots/roc-auc/{folder_name}/{xdate}/{model_name}_{folder_name}_{num}-{xdate}.tiff',\n",
    "                dpi=400, facecolor='white', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lr(model, des_df, nondes_df, file_name, folder_type='unclassified', num=100, rand_seed=1000, features=features, model_name='model'):\n",
    "    '''\n",
    "    This function trains a model on hnum/hlife/merged data.\n",
    "    Works with sklearn Logistic Reg. It trains for num loops.\n",
    "\n",
    "    model is the model instance,\n",
    "    des_df and nondes_df are the DES and non-DES data,    \n",
    "    file_name is the txt file for logs,\n",
    "    folder_type can be hlife, hnum, merged, or unclassified\n",
    "    n_repeats is passed to grid search,\n",
    "    rand_seed ensures replicability of CV\n",
    "    '''\n",
    "    xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "    # print(xdate)\n",
    "\n",
    "    roc_auc_list = []\n",
    "    folder_name = folder_type\n",
    "    model_name = model.__str__().split('(')[0]\n",
    "    # file = open(f\"./model-logs/hlife_{num}_{xdate}.txt\", \"w+\")\n",
    "    file = file_name\n",
    "\n",
    "    if folder_name == 'hlife' or folder_name == 'hnum':  # hlife/hnum have only 5 features\n",
    "        coeff = [0, 0, 0, 0, 0]\n",
    "    elif folder_name == 'merged':  # merged has 10 features\n",
    "        coeff = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    else:\n",
    "        coeff = [0, 0, 0, 0, 0]\n",
    "\n",
    "\n",
    "    for x in trange(num):\n",
    "        print(f\"Starting round {x+1}\", file=file)\n",
    "        if folder_name == 'hlife' or folder_name == 'hnum':\n",
    "            X_train, y_train, X_test, y_test = data_generator(\n",
    "                des_df, nondes_df, test_sample_size=8, nondes_batch_size=38, random_state=x)\n",
    "        elif folder_name == 'merged':\n",
    "            X_train, y_train, X_test, y_test = df_generator(\n",
    "                des_df, nondes_df, test_sample_size=8, nondes_batch_size=38, random_state=x)\n",
    "        else:\n",
    "            print(\"Check folder_type variable\")\n",
    "\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_proba = model.predict_proba(X_test)  # roc_auc_score needs probabilities\n",
    "        print(f'Prediction probabilities: {y_pred_proba}', file=file)\n",
    "        # print('Prediction probabilities: ', y_pred_proba)\n",
    "        print(f'Predictions: {y_pred}', file=file)\n",
    "        # print('Predictions: ', y_pred)\n",
    "        target_names = ['non-DES', 'DES']  # non-DES is 0, DES is 1\n",
    "        print(metrics.classification_report(y_test, y_pred,\n",
    "            target_names=target_names), file=file)\n",
    "        roc_auc = metrics.roc_auc_score(y_test, y_pred_proba[:,1])\n",
    "        print(f\"roc_auc_score: {roc_auc}\", file=file)\n",
    "        roc_auc_list.append(roc_auc)\n",
    "        print(model.coef_, file=file)\n",
    "        print(f\"intercept: {model.intercept_}\", file=file)\n",
    "\n",
    "        model_feature_df = pd.DataFrame(\n",
    "            {'Coefficients': model.coef_.squeeze(), 'Features': features})\n",
    "        max_coeff_index = list(model.coef_.squeeze()\n",
    "                            ).index(model.coef_.max())\n",
    "        print(\n",
    "            f'max coeff: {model.coef_.max()} at index {max_coeff_index} [{features[max_coeff_index]}]', file=file)\n",
    "        coeff[max_coeff_index] += 1\n",
    "        print('\\n', file=file)\n",
    "        print(model_feature_df, file=file)\n",
    "        print('\\n'*2, file=file)\n",
    "    \n",
    "    # save model\n",
    "    dirmaker(f'./saved-models/{folder_name}/{xdate}')\n",
    "    dump(model, f'./saved-models/{folder_name}/{xdate}/{model_name}_{folder_name}.joblib')\n",
    "\n",
    "    # plotting roc_auc score\n",
    "    fig = plt.figure()\n",
    "    fig.set_size_inches(12, 10, forward=True)\n",
    "    fig_ax = fig.add_subplot(1, 1, 1)\n",
    "    fig_ax.set_xlabel(\"Number of runs\", fontsize=24, weight='bold')\n",
    "    fig_ax.set_ylabel(\"ROC-AUC score\", fontsize=24, weight='bold')\n",
    "\n",
    "    if folder_name == 'hlife':\n",
    "        title_tag = 'lifetimes'\n",
    "    elif folder_name == 'hnum':\n",
    "        title_tag = 'numbers'\n",
    "    elif folder_name == 'merged':\n",
    "        title_tag = 'numbers + lifetimes'\n",
    "    else:\n",
    "        title_tag = ''  # this could be an indication that the folder_type was not set propelry\n",
    "\n",
    "\n",
    "    ytick = np.arange(0, 1.2, 0.2)\n",
    "    xtick = np.arange(0, num+2, 10)\n",
    "    plt.yticks(ytick, fontsize=22, weight='bold')\n",
    "    plt.xticks(xtick, fontsize=22, weight='bold')\n",
    "    fig_ax.set_ylim(0, 1.0)\n",
    "    fig_ax.set_xlim(0, num+2)\n",
    "    # plt.title(f'{model_name} hbond {title_tag}', fontsize=22, weight='bold')\n",
    "\n",
    "\n",
    "    roc = [z for z in range(1, num+1)]\n",
    "    print(f\"roc_auc scores: {roc_auc_list}\", file=file)\n",
    "    print(\n",
    "        f\"Average roc_auc scores: {np.average(roc_auc_list)}\", file=file)\n",
    "    print(\n",
    "        f\"std dev of roc_auc scores: {np.std(roc_auc_list)}\", file=file)\n",
    "    print(\n",
    "        f\"Best roc_auc score: {max(roc_auc_list)} at index {roc_auc_list.index(max(roc_auc_list)) + 1}\", file=file)\n",
    "    print('\\n', file=file)\n",
    "    coeff_df = pd.DataFrame(\n",
    "        {'Top Coefficients': coeff, 'Features': features})\n",
    "    print(f\"{coeff_df}\", file=file)\n",
    "    plt.plot(roc, roc_auc_list, '-o', linewidth=2, markersize=8.0, label=f\"avg roc_auc: {round(np.average(roc_auc_list),2)}\\nstd roc_auc : {round(np.std(roc_auc_list),2)}\")\n",
    "    plt.legend(loc='lower left', fontsize=16)\n",
    "    plt.show()\n",
    "    file.close()\n",
    "    dirmaker(f'./plots/roc-auc/{folder_name}/{xdate}')\n",
    "    fig.savefig(f'plots/roc-auc/{folder_name}/{xdate}/{model_name}_{folder_name}_{num}-{xdate}.tiff',\n",
    "                dpi=400, facecolor='white', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svc(model, des_df, nondes_df, file_name, folder_type='unclassified', num=100, rand_seed=1000, features=features, model_name='model'):\n",
    "    '''\n",
    "    This function trains a model on hnum/hlife/merged data.\n",
    "    Works with sklearn support vector machine\n",
    "\n",
    "    model is the model instance,\n",
    "    des_df and nondes_df are the DES and non-DES data,    \n",
    "    file_name is the txt file for logs,\n",
    "    folder_type can be hlife, hnum, merged, or unclassified\n",
    "    n_repeats is passed to grid search,\n",
    "    rand_seed ensures replicability of CV\n",
    "    '''\n",
    "    xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "    # print(xdate)\n",
    "\n",
    "    roc_auc_list = []\n",
    "    folder_name = folder_type\n",
    "    model_name=model_name\n",
    "    print(model_name)\n",
    "    # model_name = model.__str__().strip('(')[0]\n",
    "    # file = open(f\"./model-logs/hlife_{num}_{xdate}.txt\", \"w+\")\n",
    "    file = file_name\n",
    "\n",
    "    \n",
    "    if folder_name == 'hlife' or folder_name == 'hnum':  # hlife/hnum have only 5 features\n",
    "        coeff = [0, 0, 0, 0, 0]\n",
    "    elif folder_name == 'merged':  # merged has 10 features\n",
    "        coeff = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    else:\n",
    "        coeff = [0, 0, 0, 0, 0]\n",
    "\n",
    "\n",
    "    for x in trange(num):\n",
    "        print(f\"Starting round {x+1}\", file=file)\n",
    "        if folder_name == 'hlife' or folder_name == 'hnum':\n",
    "            X_train, y_train, X_test, y_test = data_generator(\n",
    "                des_df, nondes_df, test_sample_size=8, nondes_batch_size=38, random_state=x)\n",
    "        elif folder_name == 'merged':\n",
    "            X_train, y_train, X_test, y_test = df_generator(\n",
    "                des_df, nondes_df, test_sample_size=8, nondes_batch_size=38, random_state=x)\n",
    "        else:\n",
    "            print(\"Check folder_type variable\")\n",
    "\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_proba = model.predict_proba(X_test)  # roc_auc_score needs probabilities\n",
    "        print(f'Prediction probabilities: {y_pred_proba}', file=file)\n",
    "        # print('Prediction probabilities: ', y_pred_proba)\n",
    "        print(f'Predictions: {y_pred}', file=file)\n",
    "        # print('Predictions: ', y_pred)\n",
    "        target_names = ['non-DES', 'DES']  # non-DES is 0, DES is 1\n",
    "        print(metrics.classification_report(y_test, y_pred,\n",
    "            target_names=target_names), file=file)\n",
    "        roc_auc = metrics.roc_auc_score(y_test, y_pred_proba[:,1])\n",
    "        print(f\"roc_auc_score: {roc_auc}\", file=file)\n",
    "        roc_auc_list.append(roc_auc)\n",
    "        print(model._get_coef(), file=file)\n",
    "        print(f\"intercept: {model.intercept_}\", file=file)\n",
    "\n",
    "        model_feature_df = pd.DataFrame(\n",
    "            {'Coefficients': model._get_coef().squeeze(), 'Features': features})\n",
    "        max_coeff_index = list(model._get_coef().squeeze()\n",
    "                            ).index(model._get_coef().max())\n",
    "        print(\n",
    "            f'max coeff: {model._get_coef().max()} at index {max_coeff_index} [{features[max_coeff_index]}]', file=file)\n",
    "        coeff[max_coeff_index] += 1\n",
    "        print('\\n', file=file)\n",
    "        print(model_feature_df, file=file)\n",
    "        print('\\n'*2, file=file)\n",
    "\n",
    "    # save model\n",
    "    dirmaker(f'./saved-models/{folder_name}/{xdate}')\n",
    "    dump(model, f'./saved-models/{folder_name}/{xdate}/{model_name}_{folder_name}.joblib')\n",
    "\n",
    "    # plotting roc_auc score\n",
    "    fig = plt.figure()\n",
    "    fig.set_size_inches(12, 10, forward=True)\n",
    "    fig_ax = fig.add_subplot(1, 1, 1)\n",
    "    fig_ax.set_xlabel(\"Number of runs\", fontsize=24, weight='bold')\n",
    "    fig_ax.set_ylabel(\"ROC-AUC score\", fontsize=24, weight='bold')\n",
    "\n",
    "    if folder_name == 'hlife':\n",
    "        title_tag = 'lifetimes'\n",
    "    elif folder_name == 'hnum':\n",
    "        title_tag = 'numbers'\n",
    "    elif folder_name == 'merged':\n",
    "        title_tag = 'numbers + lifetimes'\n",
    "    else:\n",
    "        title_tag = ''  # this could be an indication that the folder_type was not set propelry\n",
    "\n",
    "\n",
    "    ytick = np.arange(0, 1.2, 0.2)\n",
    "    xtick = np.arange(0, num+2, 10)\n",
    "    plt.yticks(ytick, fontsize=22, weight='bold')\n",
    "    plt.xticks(xtick, fontsize=22, weight='bold')\n",
    "    fig_ax.set_ylim(0, 1.0)\n",
    "    fig_ax.set_xlim(0, num+2)\n",
    "    # plt.title(f'{model_name} hbond {title_tag}', fontsize=22, weight='bold')\n",
    "\n",
    "\n",
    "    roc = [z for z in range(1, num+1)]\n",
    "    print(f\"roc_auc scores: {roc_auc_list}\", file=file)\n",
    "    print(\n",
    "        f\"Average roc_auc scores: {np.average(roc_auc_list)}\", file=file)\n",
    "    print(\n",
    "        f\"std dev of roc_auc scores: {np.std(roc_auc_list)}\", file=file)\n",
    "    print(\n",
    "        f\"Best roc_auc score: {max(roc_auc_list)} at index {roc_auc_list.index(max(roc_auc_list)) + 1}\", file=file)\n",
    "    print('\\n', file=file)\n",
    "    coeff_df = pd.DataFrame(\n",
    "        {'Top Coefficients': coeff, 'Features': features})\n",
    "    print(f\"{coeff_df}\", file=file)\n",
    "    plt.plot(roc, roc_auc_list, '-o', linewidth=2, markersize=8.0, label=f\"avg roc_auc: {round(np.average(roc_auc_list),2)}\\nstd roc_auc : {round(np.std(roc_auc_list),2)}\")\n",
    "    plt.legend(loc='lower left', fontsize=16)\n",
    "    plt.show()\n",
    "    file.close()\n",
    "    dirmaker(f'./plots/roc-auc/{folder_name}/{xdate}')\n",
    "    fig.savefig(f'plots/roc-auc/{folder_name}/{xdate}/{model_name}_{folder_name}_{num}-{xdate}.tiff',\n",
    "                dpi=400, facecolor='white', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_knn(model, des_df, nondes_df, file_name, folder_type='unclassified', num=100, rand_seed=1000, features=features, model_name='model'):\n",
    "    '''\n",
    "    This function trains a model on hnum/hlife/merged data.\n",
    "    Works with sklearn KNN\n",
    "\n",
    "    model is the model instance,\n",
    "    des_df and nondes_df are the DES and non-DES data,    \n",
    "    file_name is the txt file for logs,\n",
    "    folder_type can be hlife, hnum, merged, or unclassified.\n",
    "    n_repeats is passed to grid search,\n",
    "    rand_seed ensures replicability of CV\n",
    "    '''\n",
    "    xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "    # print(xdate)\n",
    "\n",
    "    roc_auc_list = []\n",
    "    folder_name = folder_type\n",
    "    model_name = model.__str__().split('(')[0]\n",
    "    # file = open(f\"./model-logs/hlife_{num}_{xdate}.txt\", \"w+\")\n",
    "    file = file_name\n",
    "    for x in trange(num):\n",
    "        print(f\"Starting round {x+1}\", file=file)\n",
    "        if folder_name == 'hlife' or folder_name == 'hnum':\n",
    "            X_train, y_train, X_test, y_test = data_generator(\n",
    "                des_df, nondes_df, test_sample_size=8, nondes_batch_size=38, random_state=x)\n",
    "        elif folder_name == 'merged':\n",
    "            X_train, y_train, X_test, y_test = df_generator(\n",
    "                des_df, nondes_df, test_sample_size=8, nondes_batch_size=38, random_state=x)\n",
    "        else:\n",
    "            print(\"Check folder_type variable\")\n",
    "\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_proba = model.predict_proba(X_test)  # roc_auc_score needs probabilities\n",
    "        print(f'Prediction probabilities: {y_pred_proba}', file=file)\n",
    "        # print('Prediction probabilities: ', y_pred_proba)\n",
    "        print(f'Predictions: {y_pred}', file=file)\n",
    "        # print('Predictions: ', y_pred)\n",
    "        target_names = ['non-DES', 'DES']  # non-DES is 0, DES is 1\n",
    "        print(metrics.classification_report(y_test, y_pred,\n",
    "            target_names=target_names), file=file)\n",
    "        roc_auc = metrics.roc_auc_score(y_test, y_pred_proba[:,1])\n",
    "        print(f\"roc_auc_score: {roc_auc}\", file=file)\n",
    "        roc_auc_list.append(roc_auc)       \n",
    "        print('\\n'*2, file=file)\n",
    "\n",
    "    # save model\n",
    "    dirmaker(f'./saved-models/{folder_name}/{xdate}')\n",
    "    dump(model, f'./saved-models/{folder_name}/{xdate}/{model_name}_{folder_name}.joblib')\n",
    "    \n",
    "    # plotting roc_auc score\n",
    "    fig = plt.figure()\n",
    "    fig.set_size_inches(12, 10, forward=True)\n",
    "    fig_ax = fig.add_subplot(1, 1, 1)\n",
    "    fig_ax.set_xlabel(\"Number of runs\", fontsize=24, weight='bold')\n",
    "    fig_ax.set_ylabel(\"ROC-AUC score\", fontsize=24, weight='bold')\n",
    "\n",
    "    if folder_name == 'hlife':\n",
    "        title_tag = 'lifetimes'\n",
    "    elif folder_name == 'hnum':\n",
    "        title_tag = 'numbers'\n",
    "    elif folder_name == 'merged':\n",
    "        title_tag = 'numbers + lifetimes'\n",
    "    else:\n",
    "        title_tag = ''  # this could be an indication that the folder_type was not set propelry\n",
    "\n",
    "\n",
    "    ytick = np.arange(0, 1.2, 0.2)\n",
    "    xtick = np.arange(0, num+2, 10)\n",
    "    plt.yticks(ytick, fontsize=22, weight='bold')\n",
    "    plt.xticks(xtick, fontsize=22, weight='bold')\n",
    "    fig_ax.set_ylim(0, 1.0)\n",
    "    fig_ax.set_xlim(0, num+2)\n",
    "    # plt.title(f'{model_name} hbond {title_tag}', fontsize=22, weight='bold')\n",
    "\n",
    "\n",
    "    roc = [z for z in range(1, num+1)]\n",
    "    print(f\"roc_auc scores: {roc_auc_list}\", file=file)\n",
    "    print(\n",
    "        f\"Average roc_auc scores: {np.average(roc_auc_list)}\", file=file)\n",
    "    print(\n",
    "        f\"std dev of roc_auc scores: {np.std(roc_auc_list)}\", file=file)\n",
    "    print(\n",
    "        f\"Best roc_auc score: {max(roc_auc_list)} at index {roc_auc_list.index(max(roc_auc_list)) + 1}\", file=file)\n",
    "    print('\\n', file=file)\n",
    "    \n",
    "    plt.plot(roc, roc_auc_list, '-o', linewidth=2, markersize=8.0, label=f\"avg roc_auc: {round(np.average(roc_auc_list),2)}\\nstd roc_auc : {round(np.std(roc_auc_list),2)}\")\n",
    "    plt.legend(loc='lower left', fontsize=16)\n",
    "    plt.show()\n",
    "    file.close()\n",
    "    dirmaker(f'./plots/roc-auc/{folder_name}/{xdate}')\n",
    "    fig.savefig(f'plots/roc-auc/{folder_name}/{xdate}/{model_name}_{folder_name}_{num}-{xdate}.tiff',\n",
    "                dpi=400, facecolor='white', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgb(model, des_df, nondes_df, file_name, folder_type='unclassified', num=100, rand_seed=1000, features=features):\n",
    "    '''\n",
    "    This function trains a model on hnum/hlife/merged data.\n",
    "    Works with sklearn XGBClassifier or XGBRFClassifier.\n",
    "\n",
    "    model is the model instance,\n",
    "    des_df and nondes_df are the DES and non-DES data,    \n",
    "    file_name is the txt file for logs,\n",
    "    folder_type can be hlife, hnum, merged, or unclassified.\n",
    "    n_repeats is passed to grid search,\n",
    "    rand_seed ensures replicability of CV.\n",
    "    '''\n",
    "    xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "    xgb_roc_auc = []\n",
    "    folder_name = folder_type\n",
    "    model_name = model.__str__().split('(')[0]\n",
    "    if model_name.__contains__(\"XGBClassifier\"):\n",
    "        model_name = \"XGBClassifier\"\n",
    "\n",
    "            \n",
    "    file = file_name\n",
    "    if folder_name == 'hlife' or folder_name == 'hnum':  # hlife/hnum have only 5 features\n",
    "        coeff = [0, 0, 0, 0, 0]\n",
    "    elif folder_name == 'merged':  # merged has 10 features\n",
    "        coeff = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    else:\n",
    "        coeff = [0, 0, 0, 0, 0]\n",
    "\n",
    "\n",
    "    for x in trange(num):\n",
    "        print(f\"Starting round {x+1}\", file=file)\n",
    "        if folder_name == 'hlife' or folder_name == 'hnum':\n",
    "            X_train, y_train, X_test, y_test = data_generator(\n",
    "                des_df, nondes_df, test_sample_size=8, nondes_batch_size=38, random_state=x)\n",
    "        elif folder_name == 'merged':\n",
    "            X_train, y_train, X_test, y_test = df_generator(\n",
    "                des_df, nondes_df, test_sample_size=8, nondes_batch_size=38, random_state=x)\n",
    "        else:\n",
    "            print(\"Check folder_type variable\")\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_proba = model.predict_proba(X_test)  # roc_auc_score needs probabilities\n",
    "        print(f'Prediction probabilities: \\n{y_pred_proba}', file=file)\n",
    "        # print('Prediction probabilities: \\n', y_pred_proba)\n",
    "        print(f'Predictions: {y_pred}', file=file)\n",
    "        # print('Predictions: ', y_pred)\n",
    "        target_names = ['non-DES', 'DES']  # non-DES is 0, DES is 1\n",
    "        print(metrics.classification_report(y_test, y_pred,\n",
    "            target_names=target_names), file=file)\n",
    "        roc_auc = metrics.roc_auc_score(y_test, y_pred_proba[:,1])\n",
    "        print(f\"roc_auc_score: {roc_auc}\", file=file)\n",
    "        xgb_roc_auc.append(roc_auc)\n",
    "        print(model.feature_importances_, file=file)\n",
    "\n",
    "        model_feature_df = pd.DataFrame(\n",
    "            {'Importance': model.feature_importances_, 'Features': features})\n",
    "        max_coeff_index = list(model.feature_importances_).index(\n",
    "            model.feature_importances_.max())\n",
    "        print(\n",
    "            f'max feature: {model.feature_importances_.max()} at index {max_coeff_index} [{features[max_coeff_index]}]', file=file)\n",
    "        coeff[max_coeff_index] += 1\n",
    "        print('\\n', file=file)\n",
    "        print(model_feature_df, file=file)\n",
    "        print('\\n'*2, file=file)\n",
    "\n",
    "    # save model\n",
    "    dirmaker(f'./saved-models/{folder_name}/{xdate}')\n",
    "    dump(model, f'./saved-models/{folder_name}/{xdate}/{model_name}_{folder_name}.joblib')\n",
    "    \n",
    "    # plotting roc_auc score\n",
    "    fig = plt.figure()\n",
    "    fig.set_size_inches(12, 10, forward=True)\n",
    "    fig_ax = fig.add_subplot(1, 1, 1)\n",
    "    fig_ax.set_xlabel(\"Number of runs\", fontsize=24, weight='bold')\n",
    "    fig_ax.set_ylabel(\"ROC-AUC score\", fontsize=24, weight='bold')\n",
    "\n",
    "    if folder_name == 'hlife':\n",
    "        title_tag = 'lifetimes'\n",
    "    elif folder_name == 'hnum':\n",
    "        title_tag = 'numbers'\n",
    "    elif folder_name == 'merged':\n",
    "        title_tag = 'numbers + lifetimes'\n",
    "    else:\n",
    "        title_tag = ''  # this could be an indication that the folder_type was not set properly\n",
    "\n",
    "\n",
    "    ytick = np.arange(0, 1.2, 0.2)\n",
    "    xtick = np.arange(0, num+2, 10)\n",
    "    plt.yticks(ytick, fontsize=22, weight='bold')\n",
    "    plt.xticks(xtick, fontsize=22, weight='bold')\n",
    "    fig_ax.set_ylim(0, 1.0)\n",
    "    fig_ax.set_xlim(0, num+2)\n",
    "    # plt.title(f'{model_name} hbond {title_tag}', fontsize=22, weight='bold')\n",
    "\n",
    "    roc = [z for z in range(1, num+1)]\n",
    "    print(f\"roc_auc scores: {xgb_roc_auc}\", file=file)\n",
    "    print(\n",
    "        f\"Average roc_auc scores: {np.average(xgb_roc_auc)}\", file=file)\n",
    "    print(\n",
    "        f\"std dev of roc_auc scores: {np.std(xgb_roc_auc)}\", file=file)\n",
    "    print(\n",
    "        f\"Best roc_auc score: {max(xgb_roc_auc)} at index {xgb_roc_auc.index(max(xgb_roc_auc)) + 1}\", file=file)\n",
    "    print('\\n', file=file)\n",
    "    coeff_df_xgb = pd.DataFrame({'Top Features': coeff, 'Features': features})\n",
    "    print(f\"{coeff_df_xgb}\", file=file)\n",
    "    file.close()\n",
    "\n",
    "    plt.plot(roc, xgb_roc_auc, '-o', linewidth=2, markersize=8.0, label=f\"avg roc_auc: {round(np.average(xgb_roc_auc),2)}\\nstd roc_auc: {round(np.std(xgb_roc_auc),2)}\")\n",
    "\n",
    "    savedir = f'./plots/roc-auc/{folder_name}/{xdate}'\n",
    "    plt.legend(loc='lower left', fontsize=16)\n",
    "    \n",
    "    dirmaker(savedir)\n",
    "    fig.savefig(f'{savedir}/{model_name}_{num}-{xdate}.tiff',\n",
    "                dpi=400, facecolor='white', bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgb_eval(model, des_df, nondes_df, file_name, folder_type='unclassified', num=100, rand_seed=1000, features=features):\n",
    "    '''\n",
    "    This function trains a model on hnum/hlife/merged data.\n",
    "    Works with sklearn XGBClassifier and XGBRFClassifier. It trains\n",
    "    for num loops.\n",
    "\n",
    "    model is the model instance,\n",
    "    des_df and nondes_df are the DES and non-DES data,    \n",
    "    file_name is the txt file for logs,\n",
    "    folder_type can be hlife, hnum, merged, or unclassified.\n",
    "    n_repeats is passed to grid search,\n",
    "    rand_seed ensures replicability of CV.\n",
    "    '''\n",
    "    xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "    xgb_roc_auc = []\n",
    "    folder_name = folder_type\n",
    "    model_name = model.__str__().split('(')[0]\n",
    "    train_eval_scores = []\n",
    "    test_eval_scores = []\n",
    "\n",
    "    if model_name.__contains__(\"XGBClassifier\"):\n",
    "        model_name = \"XGBClassifier\"\n",
    "\n",
    "            \n",
    "    file = file_name\n",
    "    if folder_name == 'hlife' or folder_name == 'hnum':  # hlife/hnum have only 5 features\n",
    "        coeff = [0, 0, 0, 0, 0]\n",
    "    elif folder_name == 'merged':  # merged has 10 features\n",
    "        coeff = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    else:\n",
    "        coeff = [0, 0, 0, 0, 0]\n",
    "\n",
    "\n",
    "    for x in trange(num):\n",
    "        print(f\"Starting round {x+1}\", file=file)\n",
    "        if folder_name == 'hlife' or folder_name == 'hnum':\n",
    "            X_train, y_train, X_test, y_test = data_generator(\n",
    "                des_df, nondes_df, test_sample_size=8, nondes_batch_size=38, random_state=x)\n",
    "        elif folder_name == 'merged':\n",
    "            X_train, y_train, X_test, y_test = df_generator(\n",
    "                des_df, nondes_df, test_sample_size=8, nondes_batch_size=38, random_state=x)\n",
    "        else:\n",
    "            print(\"Check folder_type variable\")\n",
    "\n",
    "        model.fit(X_train, y_train, eval_set=[(X_train, y_train), (\n",
    "        X_test, y_test)], verbose=False)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_proba = model.predict_proba(X_test)  # roc_auc_score needs probabilities\n",
    "        print(f'Prediction probabilities: \\n{y_pred_proba}', file=file)\n",
    "        # print('Prediction probabilities: \\n', y_pred_proba)\n",
    "        print(f'Predictions: {y_pred}', file=file)\n",
    "        # print('Predictions: ', y_pred)\n",
    "        target_names = ['non-DES', 'DES']  # non-DES is 0, DES is 1\n",
    "        print(metrics.classification_report(y_test, y_pred,\n",
    "            target_names=target_names), file=file)\n",
    "        roc_auc = metrics.roc_auc_score(y_test, y_pred_proba[:,1])\n",
    "        print(f\"roc_auc_score: {roc_auc}\", file=file)\n",
    "        xgb_roc_auc.append(roc_auc)\n",
    "        print(model.feature_importances_, file=file)\n",
    "\n",
    "        model_feature_df = pd.DataFrame(\n",
    "            {'Importance': model.feature_importances_, 'Features': features})\n",
    "        max_coeff_index = list(model.feature_importances_).index(model.feature_importances_.max())\n",
    "        print(f'max feature: {model.feature_importances_.max()} at index {max_coeff_index} [{features[max_coeff_index]}]', file=file)\n",
    "        coeff[max_coeff_index] += 1\n",
    "        print('\\n', file=file)\n",
    "        print(model_feature_df, file=file)        \n",
    "        print('\\n'*2, file=file)\n",
    "\n",
    "        train_eval = list(model.evals_result()['validation_0'].items())\n",
    "        print(f'Number of training auc scores: {len(train_eval[0][1])}', file=file_name)\n",
    "        print(f'auc scores of training set: {train_eval[0][1]}', file=file_name)\n",
    "        print(f'Average and std-dev of auc scores of training set: {round(np.average(train_eval[0][1]),2)}, \\\n",
    "        {round(np.std(train_eval[0][1]),2)} \\n', file=file_name)\n",
    "\n",
    "        if model_name.__contains__(\"XGBClassifier\"):\n",
    "            train_eval_scores.append(np.average(train_eval[0][1]))\n",
    "        elif model_name.__contains__(\"XGBRFClassifier\"):\n",
    "            train_eval_scores.append(train_eval[0][1])\n",
    "\n",
    "        val_eval = list(model.evals_result()\n",
    "                        ['validation_1'].items())\n",
    "        print(f'Number of testing auc scores: {len(val_eval[0][1])}', file=file_name)\n",
    "        print(f'auc scores of testing set: {val_eval[0][1]}', file=file_name)\n",
    "        print(f'Average and std-dev of auc scores of testing set: {round(np.average(val_eval[0][1]),2)}, \\\n",
    "        {round(np.std(val_eval[0][1]),2)} \\n', file=file_name)\n",
    "        # test_eval_scores.append(val_eval[0][1])\n",
    "\n",
    "        if model_name.__contains__(\"XGBClassifier\"):\n",
    "            test_eval_scores.append(np.average(val_eval[0][1]))\n",
    "        elif model_name.__contains__(\"XGBRFClassifier\"):\n",
    "            test_eval_scores.append(val_eval[0][1])\n",
    "\n",
    "        print('\\n'*2, file=file)\n",
    "\n",
    "    \n",
    "    print('test scores', len(test_eval_scores))\n",
    "    print('train scores',len(train_eval_scores))\n",
    "\n",
    "    # print('test scores', test_eval_scores)\n",
    "    # print('train scores',train_eval_scores)\n",
    "\n",
    "    # save model\n",
    "    dirmaker(f'./saved-models/{folder_name}/{xdate}')\n",
    "    dump(model, f'./saved-models/{folder_name}/{xdate}/{model_name}_{folder_name}.joblib')\n",
    "\n",
    "    # plotting roc_auc score\n",
    "    fig = plt.figure()\n",
    "    fig.set_size_inches(12, 10, forward=True)\n",
    "    fig_ax = fig.add_subplot(1, 1, 1)\n",
    "    fig_ax.set_xlabel(\"Number of runs\", fontsize=24, weight='bold')\n",
    "    fig_ax.set_ylabel(\"ROC-AUC score\", fontsize=24, weight='bold')\n",
    "\n",
    "    if folder_name == 'hlife':\n",
    "        title_tag = 'lifetimes'\n",
    "    elif folder_name == 'hnum':\n",
    "        title_tag = 'numbers'\n",
    "    elif folder_name == 'merged':\n",
    "        title_tag = 'numbers + lifetimes'\n",
    "    else:\n",
    "        title_tag = ''  # this could be an indication that the folder_type was not set properly\n",
    "\n",
    "\n",
    "    ytick = np.arange(0, 1.2, 0.2)\n",
    "    xtick = np.arange(0, num+2, 10)\n",
    "    plt.yticks(ytick, fontsize=22, weight='bold')\n",
    "    plt.xticks(xtick, fontsize=22, weight='bold')\n",
    "    fig_ax.set_ylim(0, 1.0)\n",
    "    fig_ax.set_xlim(0, num+2)\n",
    "    # plt.title(f'{model_name} hbond {title_tag}', fontsize=22, weight='bold')\n",
    "\n",
    "    roc = [z for z in range(1, num+1)]\n",
    "    print(f\"roc_auc scores: {xgb_roc_auc}\", file=file)\n",
    "    print(\n",
    "        f\"Average roc_auc scores: {np.average(xgb_roc_auc)}\", file=file)\n",
    "    print(\n",
    "        f\"std dev of roc_auc scores: {np.std(xgb_roc_auc)}\", file=file)\n",
    "    print(\n",
    "        f\"Best roc_auc score: {max(xgb_roc_auc)} at index {xgb_roc_auc.index(max(xgb_roc_auc)) + 1}\", file=file)\n",
    "    print('\\n', file=file)\n",
    "    coeff_df_xgb = pd.DataFrame({'Top Features': coeff, 'Features': features})\n",
    "    print(f\"{coeff_df_xgb}\", file=file)\n",
    "    file.close()\n",
    "\n",
    "    fig_ax.plot(range(1, len(train_eval_scores)+1), train_eval_scores, '-o', linewidth=2, markersize=8.0, label=f\"avg training roc_auc: {round(np.average(train_eval_scores),2)}\\nstd training  roc_auc: {round(np.std(train_eval_scores),2)}\")\n",
    "\n",
    "    fig_ax.plot(range(1, len(test_eval_scores)+1), test_eval_scores, '-o', linewidth=2, markersize=8.0, label=f\"avg testing roc_auc:  {round(np.average(test_eval_scores),2)}\\nstd testing  roc_auc:  {round(np.std(test_eval_scores),2)}\")\n",
    "\n",
    "    plt.legend(loc='lower left')\n",
    "\n",
    "    # plt.plot(roc, xgb_roc_auc, '-o', linewidth=2, markersize=8.0, label=f\"avg roc_auc: {round(np.average(xgb_roc_auc),2)}\\n \\\n",
    "    # std roc_auc: {round(np.std(xgb_roc_auc),2)}\")\n",
    "\n",
    "    savedir = f'./plots/roc-auc/{folder_name}/{xdate}'\n",
    "    plt.legend(loc='best', fontsize=16)\n",
    "\n",
    "    dirmaker(savedir)\n",
    "    fig.savefig(f'{savedir}/{model_name}_eval_{num}-{xdate}.tiff',\n",
    "                dpi=400, facecolor='white', bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### kingmaker_xgb function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def kingmaker_xgb(xgb_model, p_grid, des_df, nondes_df, cv, file_name, folder_type='unclassified', n_repeat=10, rand_seed=1000, features=features):\n",
    "    '''\n",
    "    This function runs a grid search CV on an XGB classifier.\n",
    "    xgb_model is the classifier instance,\n",
    "    p_grid is the dictionary of values for the grid search,\n",
    "    cv is the cross-validation instance,\n",
    "    file_name is the txt file for logs,\n",
    "    folder_type can be hlife, hnum, merged, or unclassified\n",
    "    n_repeats is passed to grid search,\n",
    "    rand_seed ensures replicability of CV\n",
    "    '''\n",
    "    folder_name = folder_type\n",
    "    xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "\n",
    "    if folder_name == 'hlife' or folder_name == 'hnum':\n",
    "        X_train, y_train, X_test, y_test = data_generator(\n",
    "            des_df, nondes_df, test_sample_size=8, nondes_batch_size=38)\n",
    "    elif folder_name == 'merged':\n",
    "        X_train, y_train, X_test, y_test = df_generator(\n",
    "            des_df, nondes_df, test_sample_size=8, nondes_batch_size=38)\n",
    "    else:\n",
    "        print(\"Check folder_type variable\")\n",
    "\n",
    "    xgb_clf = GridSearchCV(xgb_model, param_grid=p_grid,\n",
    "                           verbose=1, scoring='roc_auc', cv=cv, refit=True)\n",
    "\n",
    "    xgb_model = xgb_clf.fit(X_train, y_train, eval_set=[(X_train, y_train), (\n",
    "        X_test, y_test)], verbose=False)  # , early_stopping_rounds=50\n",
    "    xgb_roc_auc_grid = []\n",
    "\n",
    "    if folder_name == 'hlife' or folder_name == 'hnum':  # hlife/hnum have only 5 features\n",
    "        coeff_xgb_grid = [0, 0, 0, 0, 0]\n",
    "    elif folder_name == 'merged':  # merged has 10 features\n",
    "        coeff_xgb_grid = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    else:\n",
    "        coeff_xgb_grid = [0, 0, 0, 0, 0]\n",
    "\n",
    "    print('Best score', xgb_model.best_score_, file=file_name)\n",
    "    print('Best params', xgb_model.best_params_, file=file_name)\n",
    "    y_pred_xgb_proba = xgb_model.best_estimator_.predict_proba(X_test)  # roc_auc_score needs probabilities\n",
    "    print(y_pred_xgb_proba)\n",
    "    y_pred_xgb = xgb_model.best_estimator_.predict(X_test)  # roc_auc_score needs probabilities\n",
    "    print(y_pred_xgb)\n",
    "    target_names = ['non-DES', 'DES']  # non-DES is 0, DES is 1\n",
    "    print(metrics.classification_report(y_test, y_pred_xgb,\n",
    "          target_names=target_names), file=file_name)\n",
    "    roc_auc_xgb = metrics.roc_auc_score(y_test, y_pred_xgb_proba[:,1])\n",
    "    print(f\"roc_auc_score: {roc_auc_xgb}\", file=file_name)\n",
    "    xgb_roc_auc_grid.append(roc_auc_xgb)\n",
    "    print(xgb_model.best_estimator_.feature_importances_, file=file_name)\n",
    "    # print(f\"intercept: {xgb_model.intercept_}\", file=file_name)\n",
    "\n",
    "    xgb_model_feature_df = pd.DataFrame(\n",
    "        {'Importance': xgb_model.best_estimator_.feature_importances_, 'features': features})\n",
    "    max_coeff_index = list(xgb_model.best_estimator_.feature_importances_).index(\n",
    "        xgb_model.best_estimator_.feature_importances_.max())\n",
    "    print(\n",
    "        f'max feature: {xgb_model.best_estimator_.feature_importances_.max()} at index {max_coeff_index} [{features[max_coeff_index]}]', file=file_name)\n",
    "    coeff_xgb_grid[max_coeff_index] += 1\n",
    "    print('\\n', file=file_name)\n",
    "    print(xgb_model_feature_df, file=file_name)\n",
    "    print('\\n'*2, file=file_name)\n",
    "\n",
    "    # roc = [ z for z in range(1,num+1)]\n",
    "    print(f\"roc_auc scores on test set: {xgb_roc_auc_grid}\", file=file_name)\n",
    "    print(\n",
    "        f\"Average roc_auc scores on test set: {np.average(xgb_roc_auc_grid)}\", file=file_name)\n",
    "    print(\n",
    "        f\"std dev of roc_auc scores on test set: {np.std(xgb_roc_auc_grid)}\", file=file_name)\n",
    "    print(\n",
    "        f\"Best roc_auc score on test set: {max(xgb_roc_auc_grid)} at index {xgb_roc_auc_grid.index(max(xgb_roc_auc_grid)) + 1}\", file=file_name)\n",
    "    print(\n",
    "        f\"Best model's roc_auc score from early stopping: {xgb_model.best_estimator_.best_score}\", file=file_name)\n",
    "    print(\n",
    "        f\"Best model's iteration from early stopping: {xgb_model.best_estimator_.best_iteration}\", file=file_name)\n",
    "    # print(f\"model's eval_results: {xgb_model.best_estimator_.evals_result()}\", file=file_name)\n",
    "    train_eval = list(xgb_model.best_estimator_.evals_result()[\n",
    "                      'validation_0'].items())\n",
    "    print(\n",
    "        f'Number of training auc scores: {len(train_eval[0][1])}', file=file_name)\n",
    "    print(f'auc scores of training set: {train_eval[0][1]}', file=file_name)\n",
    "    print(f'Average and std-dev of auc scores of training set: {round(np.average(train_eval[0][1]),2)}, \\\n",
    "    {round(np.std(train_eval[0][1]),2)} \\n', file=file_name)\n",
    "\n",
    "    val_eval = list(xgb_model.best_estimator_.evals_result()\n",
    "                    ['validation_1'].items())\n",
    "    print(\n",
    "        f'Number of testing auc scores: {len(val_eval[0][1])}', file=file_name)\n",
    "    print(f'auc scores of testing set: {val_eval[0][1]}', file=file_name)\n",
    "    print(f'Average and std-dev of auc scores of testing set: {round(np.average(val_eval[0][1]),2)}, \\\n",
    "    {round(np.std(val_eval[0][1]),2)} \\n', file=file_name)\n",
    "\n",
    "    print('\\n', file=file_name)\n",
    "    coeff_df_xgb = pd.DataFrame(\n",
    "        {'Top features': coeff_xgb_grid, 'features': features})\n",
    "    print(f\"Coefficients: {coeff_df_xgb} \\n\", file=file_name)\n",
    "\n",
    "    print(f'Best estimator: {xgb_model.best_estimator_} \\n', file=file_name)\n",
    "    print(f'Best params: {xgb_model.best_params_} \\n', file=file_name)\n",
    "    print(\n",
    "        f\"Best estimator's score from early stopping: {xgb_model.best_estimator_.best_score} \\n\", file=file_name)\n",
    "    # plotting roc_auc score\n",
    "    fig = plt.figure()\n",
    "    fig_ax = fig.add_subplot(1, 1, 1)\n",
    "    fig.set_size_inches(12, 8, forward=True)\n",
    "    fig_ax.set_xlabel(\"Number of runs\")\n",
    "    fig_ax.set_ylabel(\"Cross-validation ROC-AUC score\")\n",
    "    fig_ax.set_ylim(0, 1.1)\n",
    "\n",
    "    if folder_name == 'hlife':\n",
    "        title_tag = 'lifetimes'\n",
    "    elif folder_name == 'hnum':\n",
    "        title_tag = 'numbers'\n",
    "    elif folder_name == 'merged':\n",
    "        title_tag = 'numbers + lifetimes'\n",
    "    else:\n",
    "        title_tag = ''  # this could be an indication that the folder_type was not set properly\n",
    "\n",
    "    plt.title(\n",
    "        f'XGBoost (Repeated KFold) hbond {title_tag}', fontsize=12, weight='bold')\n",
    "\n",
    "    fig_ax.plot(range(1, len(train_eval[0][1])+1), train_eval[0][1], '-o', linewidth=2, markersize=8.0, label=f\"avg training roc_auc: {round(np.average(train_eval[0][1]),2)}\\nstd training roc_auc : {round(np.std(train_eval[0][1]),2)}\")\n",
    "\n",
    "    fig_ax.plot(range(1, len(val_eval[0][1])+1), val_eval[0][1], '-o', linewidth=2, markersize=8.0, label=f\"avg testing roc_auc: {round(np.average(val_eval[0][1]),2)}\\nstd testing roc_auc : {round(np.std(val_eval[0][1]),2)}\")\n",
    "\n",
    "    plt.legend(loc='best')\n",
    "    file_name.close()\n",
    "    dirmaker(f'./plots/roc-auc/{folder_name}/{xdate}')\n",
    "    fig.savefig(f'plots/roc-auc/{folder_name}/{xdate}/XGB_{folder_name}_{n_repeat}grid-{xdate}_{rand_seed}.png',\n",
    "                dpi=500, facecolor='white', bbox_inches='tight')\n",
    "\n",
    "    xgb.plot_importance(xgb_model.best_estimator_).set_yticklabels(features)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def kingmaker_xgbrf(xgb_model, p_grid, des_df, nondes_df, cv, file_name, folder_type='unclassified', n_repeat=10, \n",
    "rand_seed=1000, features=features, model_name=\"XGBRFClassifier\"):\n",
    "    '''\n",
    "    This function runs a grid search CV on an XGB classifier.\n",
    "    xgb_model is the classifier instance,\n",
    "    p_grid is the dictionary of values for the grid search,\n",
    "    cv is the cross-validation instance,\n",
    "    file_name is the txt file for logs,\n",
    "    folder_type can be hlife, hnum, merged, or unclassified\n",
    "    n_repeats is passed to grid search,\n",
    "    rand_seed ensures replicability of CV\n",
    "    '''\n",
    "    folder_name = folder_type\n",
    "    model_name = model_name\n",
    "    xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "\n",
    "    if folder_name == 'hlife' or folder_name == 'hnum':\n",
    "        X_train, y_train, X_test, y_test = data_generator(\n",
    "            des_df, nondes_df, test_sample_size=8, nondes_batch_size=38)\n",
    "    elif folder_name == 'merged':\n",
    "        X_train, y_train, X_test, y_test = df_generator(\n",
    "            des_df, nondes_df, test_sample_size=8, nondes_batch_size=38)\n",
    "    else:\n",
    "        print(\"Check folder_type variable\")\n",
    "\n",
    "    xgb_clf = GridSearchCV(xgb_model, param_grid=p_grid,\n",
    "                           verbose=1, scoring='roc_auc', cv=cv, refit=True)\n",
    "\n",
    "    xgb_model = xgb_clf.fit(X_train, y_train, eval_set=[(X_train, y_train), (\n",
    "        X_test, y_test)], verbose=False)  # , early_stopping_rounds=50\n",
    "    xgb_roc_auc_grid = []\n",
    "\n",
    "    if folder_name == 'hlife' or folder_name == 'hnum':  # hlife/hnum have only 5 features\n",
    "        coeff_xgb_grid = [0, 0, 0, 0, 0]\n",
    "    elif folder_name == 'merged':  # merged has 10 features\n",
    "        coeff_xgb_grid = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    else:\n",
    "        coeff_xgb_grid = [0, 0, 0, 0, 0]\n",
    "\n",
    "    print('Best score', xgb_model.best_score_, file=file_name)\n",
    "    print('Best params', xgb_model.best_params_, file=file_name)\n",
    "    y_pred_xgb_proba = xgb_model.best_estimator_.predict_proba(X_test)  # roc_auc_score needs probabilities\n",
    "    print(y_pred_xgb_proba)\n",
    "    y_pred_xgb = xgb_model.best_estimator_.predict(X_test)  # roc_auc_score needs probabilities\n",
    "    print(y_pred_xgb)\n",
    "    target_names = ['non-DES', 'DES']  # non-DES is 0, DES is 1\n",
    "    print(metrics.classification_report(y_test, y_pred_xgb,\n",
    "          target_names=target_names), file=file_name)\n",
    "    roc_auc_xgb = metrics.roc_auc_score(y_test, y_pred_xgb_proba[:,1])\n",
    "    print(f\"roc_auc_score: {roc_auc_xgb}\", file=file_name)\n",
    "    xgb_roc_auc_grid.append(roc_auc_xgb)\n",
    "    print(xgb_model.best_estimator_.feature_importances_, file=file_name)\n",
    "    # print(f\"intercept: {xgb_model.intercept_}\", file=file_name)\n",
    "\n",
    "    xgb_model_feature_df = pd.DataFrame(\n",
    "        {'Importance': xgb_model.best_estimator_.feature_importances_, 'features': features})\n",
    "    max_coeff_index = list(xgb_model.best_estimator_.feature_importances_).index(\n",
    "        xgb_model.best_estimator_.feature_importances_.max())\n",
    "    print(\n",
    "        f'max feature: {xgb_model.best_estimator_.feature_importances_.max()} at index {max_coeff_index} [{features[max_coeff_index]}]', file=file_name)\n",
    "    coeff_xgb_grid[max_coeff_index] += 1\n",
    "    print('\\n', file=file_name)\n",
    "    print(xgb_model_feature_df, file=file_name)\n",
    "    print('\\n'*2, file=file_name)\n",
    "\n",
    "    # roc = [ z for z in range(1,num+1)]\n",
    "    print(f\"roc_auc scores on test set: {xgb_roc_auc_grid}\", file=file_name)\n",
    "    print(\n",
    "        f\"Average roc_auc scores on test set: {np.average(xgb_roc_auc_grid)}\", file=file_name)\n",
    "    print(\n",
    "        f\"std dev of roc_auc scores on test set: {np.std(xgb_roc_auc_grid)}\", file=file_name)\n",
    "    print(\n",
    "        f\"Best roc_auc score on test set: {max(xgb_roc_auc_grid)} at index {xgb_roc_auc_grid.index(max(xgb_roc_auc_grid)) + 1}\", file=file_name)\n",
    "    # print(\n",
    "    #     f\"Best model's roc_auc score from early stopping: {xgb_model.best_estimator_.best_score}\", file=file_name)\n",
    "    # print(\n",
    "    #     f\"Best model's iteration from early stopping: {xgb_model.best_estimator_.best_iteration}\", file=file_name)\n",
    "    # print(f\"model's eval_results: {xgb_model.best_estimator_.evals_result()}\", file=file_name)\n",
    "    train_eval = list(xgb_model.best_estimator_.evals_result()[\n",
    "                      'validation_0'].items())\n",
    "    print(\n",
    "        f'Number of training auc scores: {len(train_eval[0][1])}', file=file_name)\n",
    "    print(f'auc scores of training set: {train_eval[0][1]}', file=file_name)\n",
    "    print(f'Average and std-dev of auc scores of training set: {round(np.average(train_eval[0][1]),2)}, \\\n",
    "    {round(np.std(train_eval[0][1]),2)} \\n', file=file_name)\n",
    "\n",
    "    val_eval = list(xgb_model.best_estimator_.evals_result()\n",
    "                    ['validation_1'].items())\n",
    "    print(\n",
    "        f'Number of testing auc scores: {len(val_eval[0][1])}', file=file_name)\n",
    "    print(f'auc scores of testing set: {val_eval[0][1]}', file=file_name)\n",
    "    print(f'Average and std-dev of auc scores of testing set: {round(np.average(val_eval[0][1]),2)}, \\\n",
    "    {round(np.std(val_eval[0][1]),2)} \\n', file=file_name)\n",
    "\n",
    "    print('\\n', file=file_name)\n",
    "    coeff_df_xgb = pd.DataFrame(\n",
    "        {'Top features': coeff_xgb_grid, 'features': features})\n",
    "    print(f\"Coefficients: {coeff_df_xgb} \\n\", file=file_name)\n",
    "\n",
    "    print(f'Best estimator: {xgb_model.best_estimator_} \\n', file=file_name)\n",
    "    print(f'Best params: {xgb_model.best_params_} \\n', file=file_name)\n",
    "    # print(\n",
    "    #     f\"Best estimator's score from early stopping: {xgb_model.best_estimator_.best_score} \\n\", file=file_name)\n",
    "    # plotting roc_auc score\n",
    "    fig = plt.figure()\n",
    "    fig_ax = fig.add_subplot(1, 1, 1)\n",
    "    fig.set_size_inches(12, 8, forward=True)\n",
    "    fig_ax.set_xlabel(\"Number of runs\")\n",
    "    fig_ax.set_ylabel(\"Cross-validation ROC-AUC score\")\n",
    "    fig_ax.set_ylim(0, 1.1)\n",
    "\n",
    "    if folder_name == 'hlife':\n",
    "        title_tag = 'lifetimes'\n",
    "    elif folder_name == 'hnum':\n",
    "        title_tag = 'numbers'\n",
    "    elif folder_name == 'merged':\n",
    "        title_tag = 'numbers + lifetimes'\n",
    "    else:\n",
    "        title_tag = ''  # this could be an indication that the folder_type was not set properly\n",
    "\n",
    "    plt.title(\n",
    "        f'{model_name} (Repeated KFold) hbond {title_tag}', fontsize=12, weight='bold')\n",
    "\n",
    "    fig_ax.plot(range(1, len(train_eval[0][1])+1), train_eval[0][1], '-o', linewidth=2, markersize=8.0, label=f\"avg training roc_auc: {round(np.average(train_eval[0][1]),2)}\\n \\\n",
    "    std training roc_auc : {round(np.std(train_eval[0][1]),2)}\")\n",
    "\n",
    "    fig_ax.plot(range(1, len(val_eval[0][1])+1), val_eval[0][1], '-o', linewidth=2, markersize=8.0, label=f\"avg testing roc_auc: {round(np.average(val_eval[0][1]),2)}\\n \\\n",
    "    std testing roc_auc : {round(np.std(val_eval[0][1]),2)}\")\n",
    "\n",
    "    plt.legend(loc='best')\n",
    "    file_name.close()\n",
    "    dirmaker(f'./plots/roc-auc/{folder_name}/{xdate}')\n",
    "    fig.savefig(f'plots/roc-auc/{folder_name}/{xdate}/{model_name}_{folder_name}_{n_repeat}grid-{xdate}_{rand_seed}.png',\n",
    "                dpi=500, facecolor='white', bbox_inches='tight')\n",
    "\n",
    "    xgb.plot_importance(xgb_model.best_estimator_).set_yticklabels(features)\n",
    "    plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### kingmaker_generic function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def kingmaker_generic(model, p_grid, des_df, nondes_df, cv, file_name, folder_type='unclassified', n_repeat=10, rand_seed=1000, features=features):\n",
    "    '''\n",
    "    This function runs a grid search CV on sklearn GradBoost,\n",
    "    AdaBoost, RandomForest, ExtraTreesForest, DecisionTrees.\n",
    "    model is the classifier instance,\n",
    "    p_grid is the dictionary of values for the grid search,\n",
    "    cv is the cross-validation instance,\n",
    "    file_name is the txt file for logs,\n",
    "    folder_type can be hlife, hnum, merged, or unclassified\n",
    "    n_repeats is passed to grid search,\n",
    "    rand_seed ensures replicability of CV\n",
    "    '''\n",
    "    folder_name = folder_type\n",
    "    xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "    model_name = model.__str__().strip('()')\n",
    "    if model_name.__contains__(\"XGBClassifier\"):\n",
    "        model_name = \"XGBClassifier\"\n",
    "\n",
    "        \n",
    "    if folder_name == 'hlife' or folder_name == 'hnum':\n",
    "        X_train, y_train, X_test, y_test = data_generator(\n",
    "            des_df, nondes_df, test_sample_size=8, nondes_batch_size=38)\n",
    "    elif folder_name == 'merged':\n",
    "        X_train, y_train, X_test, y_test = df_generator(\n",
    "            des_df, nondes_df, test_sample_size=8, nondes_batch_size=38)\n",
    "    else:\n",
    "        print(\"Check folder_type variable\")\n",
    "\n",
    "    clf = GridSearchCV(model, param_grid=p_grid,\n",
    "                           verbose=1, scoring='roc_auc', cv=cv, refit=True, return_train_score = True)\n",
    "\n",
    "    # model = clf.fit(X_train, y_train, eval_set=[(X_train, y_train), (\n",
    "    #     X_test, y_test)], verbose=False, early_stopping_rounds=50)\n",
    "    model = clf.fit(X_train, y_train)\n",
    "    roc_auc_grid = []\n",
    "\n",
    "    if folder_name == 'hlife' or folder_name == 'hnum':  # hlife/hnum have only 5 features\n",
    "        coeff_grid = [0, 0, 0, 0, 0]\n",
    "    elif folder_name == 'merged':  # merged has 10 features\n",
    "        coeff_grid = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    else:\n",
    "        coeff_grid = [0, 0, 0, 0, 0]\n",
    "\n",
    "    \n",
    "    \n",
    "    results = pd.DataFrame(model.cv_results_)\n",
    "    # print(results)\n",
    "\n",
    "    # take the most relevant columns and sort (for readability)\n",
    "    results = results.loc[:, ('rank_test_score', 'mean_test_score', 'params')]\n",
    "    results.sort_values(by='rank_test_score', ascending=True, inplace=True)\n",
    "    print(results.head(1))    \n",
    "    print(results, file=file_name)\n",
    "    print('\\n'*2, file=file_name)\n",
    "\n",
    "    print('Best score', model.best_score_, file=file_name)\n",
    "    print('Best params', model.best_params_, file=file_name)\n",
    "\n",
    "    y_test_pred_proba = model.best_estimator_.predict_proba(X_test)  # roc_auc_score needs probabilities\n",
    "    # print('Prediction probabilities: ', y_test_pred_proba)\n",
    "    print(f'Prediction probabilities: {y_test_pred_proba}', file=file_name)\n",
    "\n",
    "    y_test_pred = model.best_estimator_.predict(X_test) \n",
    "    # print('Predictions: ', y_test_pred)\n",
    "    print(f'Predictions: {y_test_pred}', file=file_name)\n",
    "    target_names = ['non-DES', 'DES']  # non-DES is 0, DES is 1\n",
    "    print(metrics.classification_report(y_test, y_test_pred,\n",
    "          target_names=target_names), file=file_name)\n",
    "    roc_auc = metrics.roc_auc_score(y_test, y_test_pred_proba[:,1])\n",
    "    print(f\"roc_auc_score: {roc_auc}\", file=file_name)\n",
    "    roc_auc_grid.append(roc_auc)\n",
    "    print(model.best_estimator_.feature_importances_, file=file_name)\n",
    "    # print(f\"intercept: {model.intercept_}\", file=file_name)\n",
    "\n",
    "    model_feature_df = pd.DataFrame(\n",
    "        {'Importance': model.best_estimator_.feature_importances_, 'features': features})\n",
    "    max_coeff_index = list(model.best_estimator_.feature_importances_).index(\n",
    "        model.best_estimator_.feature_importances_.max())\n",
    "    print(\n",
    "        f'max feature: {model.best_estimator_.feature_importances_.max()} at index {max_coeff_index} [{features[max_coeff_index]}]', file=file_name)\n",
    "    coeff_grid[max_coeff_index] += 1\n",
    "    print('\\n', file=file_name)\n",
    "    print(model_feature_df, file=file_name)\n",
    "    print('\\n'*2, file=file_name)\n",
    "\n",
    "    # roc = [ z for z in range(1,num+1)]\n",
    "    print(f\"roc_auc scores on test set: {roc_auc_grid}\", file=file_name)\n",
    "    print(\n",
    "        f\"Average roc_auc scores on test set: {np.average(roc_auc_grid)}\", file=file_name)\n",
    "    print(\n",
    "        f\"std dev of roc_auc scores on test set: {np.std(roc_auc_grid)}\", file=file_name)\n",
    "    print(\n",
    "        f\"Best roc_auc score on test set: {max(roc_auc_grid)} at index {roc_auc_grid.index(max(roc_auc_grid)) + 1}\", file=file_name)\n",
    "    # print(\n",
    "    #     f\"Best model's roc_auc score from early stopping: {model.best_estimator_.best_score_}\", file=file_name)\n",
    "    # print(\n",
    "    #     f\"Best model's iteration from early stopping: {model.best_estimator_.best_iteration_}\", file=file_name)\n",
    "    # print(f\"model's eval_results: {model.best_estimator_.evals_result()}\", file=file_name)\n",
    "    # train_eval = list(model.best_estimator_.evals_result()[\n",
    "    #                   'validation_0'].items())\n",
    "    # print(\n",
    "    #     f'Number of training auc scores: {len(train_eval[0][1])}', file=file_name)\n",
    "    # print(f'auc scores of training set: {train_eval[0][1]}', file=file_name)\n",
    "    # print(f'Average and std-dev of auc scores of training set: {round(np.average(train_eval[0][1]),2)}, \\\n",
    "    # {round(np.std(train_eval[0][1]),2)} \\n', file=file_name)\n",
    "\n",
    "    # val_eval = list(model.best_estimator_.evals_result()\n",
    "    #                 ['validation_1'].items())\n",
    "    # print(\n",
    "    #     f'Number of testing auc scores: {len(val_eval[0][1])}', file=file_name)\n",
    "    # print(f'auc scores of testing set: {val_eval[0][1]}', file=file_name)\n",
    "    # print(f'Average and std-dev of auc scores of testing set: {round(np.average(val_eval[0][1]),2)}, \\\n",
    "    # {round(np.std(val_eval[0][1]),2)} \\n', file=file_name)\n",
    "\n",
    "    print('\\n', file=file_name)\n",
    "    # coeff_df = pd.DataFrame(\n",
    "    #     {'Top features': coeff_grid, 'features': features})\n",
    "    # print(f\"Coefficients: {coeff_df} \\n\", file=file_name)\n",
    "\n",
    "    print(f'Best estimator: {model.best_estimator_} \\n', file=file_name)\n",
    "    print(f'Best params: {model.best_params_} \\n', file=file_name)\n",
    "    print(f'Best estimator: {model.best_estimator_} \\n')\n",
    "    print(f'Best params: {model.best_params_} \\n')\n",
    "    print('\\n', file=file_name)\n",
    "    print(model.cv_results_, file=file_name)\n",
    "    # print(\n",
    "    #     f\"Best estimator's score from early stopping: {model.best_estimator_.best_score} \\n\", file=file_name)\n",
    "    # plotting roc_auc score\n",
    "    fig = plt.figure()\n",
    "    fig_ax = fig.add_subplot(1, 1, 1)\n",
    "    fig.set_size_inches(12, 8, forward=True)\n",
    "    fig_ax.set_xlabel(\"Number of runs\")\n",
    "    fig_ax.set_ylabel(\"Cross-validation ROC-AUC score\")\n",
    "    fig_ax.set_ylim(0, 1.1)\n",
    "\n",
    "    if folder_name == 'hlife':\n",
    "        title_tag = 'lifetimes'\n",
    "    elif folder_name == 'hnum':\n",
    "        title_tag = 'numbers'\n",
    "    elif folder_name == 'merged':\n",
    "        title_tag = 'numbers + lifetimes'\n",
    "    else:\n",
    "        title_tag = ''  # this could be an indication that the folder_type was not set properly\n",
    "\n",
    "    plt.title(\n",
    "        f'{model_name} (Repeated KFold) hbond {title_tag}', fontsize=12, weight='bold')\n",
    "\n",
    "    fig_ax.plot(range(1, len(roc_auc_grid)+1), roc_auc_grid, '-o', linewidth=2, markersize=8.0, label=f\"avg training roc_auc: {round(np.average(roc_auc_grid),2)}\\n \\\n",
    "    std training roc_auc : {round(np.std(roc_auc_grid),2)}\")\n",
    "\n",
    "    # fig_ax.plot(range(1, len(val_eval[0][1])+1), val_eval[0][1], '-o', linewidth=2, markersize=8.0, label=f\"avg testing roc_auc: {round(np.average(val_eval[0][1]),2)}\\n \\\n",
    "    # std testing roc_auc : {round(np.std(val_eval[0][1]),2)}\")\n",
    "\n",
    "    plt.legend(loc='best')\n",
    "    file_name.close()\n",
    "    dirmaker(f'./plots/roc-auc/{folder_name}/{xdate}')\n",
    "    fig.savefig(f'plots/roc-auc/{folder_name}/{xdate}/{model_name}_{folder_name}_{n_repeat}grid-{xdate}_{rand_seed}.png',\n",
    "                dpi=500, facecolor='white', bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def kingmaker_svc(model, p_grid, des_df, nondes_df, cv, file_name, folder_type='unclassified', n_repeat=10, rand_seed=1000, features=features):\n",
    "    '''\n",
    "    This function runs a grid search CV on sklearn Logistic \n",
    "    Regression.\n",
    "    model is the classifier instance,\n",
    "    p_grid is the dictionary of values for the grid search,\n",
    "    cv is the cross-validation instance,\n",
    "    file_name is the txt file for logs,\n",
    "    folder_type can be hlife, hnum, merged, or unclassified\n",
    "    n_repeats is passed to grid search,\n",
    "    rand_seed ensures replicability of CV\n",
    "    '''\n",
    "    folder_name = folder_type\n",
    "    xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "    model_name = model.__str__().split('(')[0]\n",
    "    if model_name.__contains__(\"XGBClassifier\"):\n",
    "        model_name = \"XGBClassifier\"\n",
    "\n",
    "        \n",
    "    if folder_name == 'hlife' or folder_name == 'hnum':\n",
    "        X_train, y_train, X_test, y_test = data_generator(\n",
    "            des_df, nondes_df, test_sample_size=8, nondes_batch_size=38)\n",
    "    elif folder_name == 'merged':\n",
    "        X_train, y_train, X_test, y_test = df_generator(\n",
    "            des_df, nondes_df, test_sample_size=8, nondes_batch_size=38)\n",
    "    else:\n",
    "        print(\"Check folder_type variable\")\n",
    "    \n",
    "\n",
    "    # print(X_train.shape, y_train.shape)\n",
    "    clf = GridSearchCV(model, param_grid=p_grid,\n",
    "                           verbose=1, scoring='roc_auc', cv=cv, refit=True, return_train_score = True)\n",
    "    \n",
    "    model = clf.fit(X_train, y_train)\n",
    "    roc_auc_grid = []\n",
    "\n",
    "    if folder_name == 'hlife' or folder_name == 'hnum':  # hlife/hnum have only 5 features\n",
    "        coeff_grid = [0, 0, 0, 0, 0]\n",
    "    elif folder_name == 'merged':  # merged has 10 features\n",
    "        coeff_grid = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    else:\n",
    "        coeff_grid = [0, 0, 0, 0, 0]\n",
    "\n",
    "    \n",
    "    print(model.cv_results_)\n",
    "    results = pd.DataFrame(model.cv_results_)\n",
    "    # print(results)\n",
    "\n",
    "    # take the most relevant columns and sort (for readability)\n",
    "    results = results.loc[:, ('rank_test_score', 'mean_test_score', 'params')]\n",
    "    results.sort_values(by='rank_test_score', ascending=True, inplace=True)\n",
    "    print(results.head(1))    \n",
    "    print(results, file=file_name)\n",
    "    print('\\n'*2, file=file_name)\n",
    "\n",
    "    print('Best score', model.best_score_, file=file_name)\n",
    "    print('Best params', model.best_params_, file=file_name)\n",
    "\n",
    "    y_test_pred_proba = model.best_estimator_.predict_proba(X_test)  # roc_auc_score needs probabilities\n",
    "    # print('Prediction probabilities: ', y_test_pred_proba)\n",
    "    print(f'Prediction probabilities: {y_test_pred_proba}', file=file_name)\n",
    "\n",
    "    y_test_pred = model.best_estimator_.predict(X_test) \n",
    "    # print('Predictions: ', y_test_pred)\n",
    "    print(f'Predictions: {y_test_pred}', file=file_name)\n",
    "    target_names = ['non-DES', 'DES']  # non-DES is 0, DES is 1\n",
    "    print(metrics.classification_report(y_test, y_test_pred,\n",
    "          target_names=target_names), file=file_name)\n",
    "    roc_auc = metrics.roc_auc_score(y_test, y_test_pred_proba[:,1])\n",
    "    print(f\"roc_auc_score: {roc_auc}\", file=file_name)\n",
    "    roc_auc_grid.append(roc_auc)\n",
    "    print(model.best_estimator_._get_coef(), file=file_name)\n",
    "    print(f\"intercept: {model.best_estimator_.intercept_}\", file=file_name)\n",
    "\n",
    "\n",
    "    model_feature_df = pd.DataFrame(\n",
    "        {'Importance': model.best_estimator_._get_coef().squeeze(), 'features': features})\n",
    "    max_coeff_index = list(model.best_estimator_._get_coef().squeeze()).index(\n",
    "        model.best_estimator_._get_coef().max())\n",
    "    print(\n",
    "        f'max feature: {model.best_estimator_._get_coef().max()} at index {max_coeff_index} [{features[max_coeff_index]}]', file=file_name)\n",
    "    coeff_grid[max_coeff_index] += 1\n",
    "    print('\\n', file=file_name)\n",
    "    print(model_feature_df, file=file_name)\n",
    "    print('\\n'*2, file=file_name)\n",
    "\n",
    "    # roc = [ z for z in range(1,num+1)]\n",
    "    print(f\"roc_auc scores on test set: {roc_auc_grid}\", file=file_name)\n",
    "    print(\n",
    "        f\"Average roc_auc scores on test set: {np.average(roc_auc_grid)}\", file=file_name)\n",
    "    print(\n",
    "        f\"std dev of roc_auc scores on test set: {np.std(roc_auc_grid)}\", file=file_name)\n",
    "    print(\n",
    "        f\"Best roc_auc score on test set: {max(roc_auc_grid)} at index {roc_auc_grid.index(max(roc_auc_grid)) + 1}\", file=file_name)\n",
    "    \n",
    "    print('\\n', file=file_name)\n",
    "    coeff_df = pd.DataFrame(\n",
    "        {'Top features': coeff_grid, 'features': features})\n",
    "        \n",
    "    print(f\"Coefficients: {coeff_df} \\n\", file=file_name)\n",
    "\n",
    "    print(f'Best estimator: {model.best_estimator_} \\n', file=file_name)\n",
    "    print(f'Best params: {model.best_params_} \\n', file=file_name)\n",
    "    print(f'Best estimator: {model.best_estimator_} \\n')\n",
    "    print(f'Best params: {model.best_params_} \\n')\n",
    "\n",
    "    fig = plt.figure()\n",
    "    fig_ax = fig.add_subplot(1, 1, 1)\n",
    "    fig.set_size_inches(12, 8, forward=True)\n",
    "    fig_ax.set_xlabel(\"Number of runs\")\n",
    "    fig_ax.set_ylabel(\"Cross-validation ROC-AUC score\")\n",
    "    fig_ax.set_ylim(0, 1.1)\n",
    "\n",
    "    if folder_name == 'hlife':\n",
    "        title_tag = 'lifetimes'\n",
    "    elif folder_name == 'hnum':\n",
    "        title_tag = 'numbers'\n",
    "    elif folder_name == 'merged':\n",
    "        title_tag = 'numbers + lifetimes'\n",
    "    else:\n",
    "        title_tag = ''  # this could be an indication that the folder_type was not set properly\n",
    "\n",
    "    plt.title(\n",
    "        f'{model_name} (Repeated KFold) hbond {title_tag}', fontsize=12, weight='bold')\n",
    "\n",
    "    fig_ax.plot(range(1, len(roc_auc_grid)+1), roc_auc_grid, '-o', linewidth=2, markersize=8.0, label=f\"avg training roc_auc: {round(np.average(roc_auc_grid),2)}\\n \\\n",
    "    std training roc_auc : {round(np.std(roc_auc_grid),2)}\")\n",
    "\n",
    "    plt.legend(loc='best')\n",
    "    file_name.close()\n",
    "    dirmaker(f'./plots/roc-auc/{folder_name}/{xdate}')\n",
    "    fig.savefig(f'plots/roc-auc/{folder_name}/{xdate}/{model_name}_{folder_name}_{n_repeat}grid-{xdate}_{rand_seed}.png',\n",
    "                dpi=500, facecolor='white', bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def kingmaker_knn(model, p_grid, des_df, nondes_df, cv, file_name, folder_type='unclassified', n_repeat=10, rand_seed=1000, features=features):\n",
    "    '''\n",
    "    This function runs a grid search CV on sklearn KNN.\n",
    "    model is the classifier instance,\n",
    "    p_grid is the dictionary of values for the grid search,\n",
    "    cv is the cross-validation instance,\n",
    "    file_name is the txt file for logs,\n",
    "    folder_type can be hlife, hnum, merged, or unclassified\n",
    "    n_repeats is passed to grid search,\n",
    "    rand_seed ensures replicability of CV\n",
    "    '''\n",
    "    folder_name = folder_type\n",
    "    xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "    model_name = model.__str__().split('(')[0]\n",
    "    if model_name.__contains__(\"XGBClassifier\"):\n",
    "        model_name = \"XGBClassifier\"\n",
    "\n",
    "        \n",
    "    if folder_name == 'hlife' or folder_name == 'hnum':\n",
    "        X_train, y_train, X_test, y_test = data_generator(\n",
    "            des_df, nondes_df, test_sample_size=8, nondes_batch_size=38)\n",
    "    elif folder_name == 'merged':\n",
    "        X_train, y_train, X_test, y_test = df_generator(\n",
    "            des_df, nondes_df, test_sample_size=8, nondes_batch_size=38)\n",
    "    else:\n",
    "        print(\"Check folder_type variable\")\n",
    "    \n",
    "\n",
    "    # print(X_train.shape, y_train.shape)\n",
    "    clf = GridSearchCV(model, param_grid=p_grid,\n",
    "                           verbose=1, scoring='roc_auc', cv=cv, refit=True, return_train_score = True)\n",
    "    \n",
    "    model = clf.fit(X_train, y_train)\n",
    "    roc_auc_grid = []\n",
    "\n",
    "    if folder_name == 'hlife' or folder_name == 'hnum':  # hlife/hnum have only 5 features\n",
    "        coeff_grid = [0, 0, 0, 0, 0]\n",
    "    elif folder_name == 'merged':  # merged has 10 features\n",
    "        coeff_grid = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    else:\n",
    "        coeff_grid = [0, 0, 0, 0, 0]\n",
    "\n",
    "    \n",
    "    print(model.cv_results_)\n",
    "    results = pd.DataFrame(model.cv_results_)\n",
    "    # print(results)\n",
    "\n",
    "    # take the most relevant columns and sort (for readability)\n",
    "    results = results.loc[:, ('rank_test_score', 'mean_test_score', 'params')]\n",
    "    results.sort_values(by='rank_test_score', ascending=True, inplace=True)\n",
    "    print(results.head(1))    \n",
    "    print(results, file=file_name)\n",
    "    print('\\n'*2, file=file_name)\n",
    "\n",
    "    print('Best score', model.best_score_, file=file_name)\n",
    "    print('Best params', model.best_params_, file=file_name)\n",
    "\n",
    "    y_test_pred_proba = model.best_estimator_.predict_proba(X_test)  # roc_auc_score needs probabilities\n",
    "    # print('Prediction probabilities: ', y_test_pred_proba)\n",
    "    print(f'Prediction probabilities: {y_test_pred_proba}', file=file_name)\n",
    "\n",
    "    y_test_pred = model.best_estimator_.predict(X_test) \n",
    "    # print('Predictions: ', y_test_pred)\n",
    "    print(f'Predictions: {y_test_pred}', file=file_name)\n",
    "    target_names = ['non-DES', 'DES']  # non-DES is 0, DES is 1\n",
    "    print(metrics.classification_report(y_test, y_test_pred,\n",
    "          target_names=target_names), file=file_name)\n",
    "    roc_auc = metrics.roc_auc_score(y_test, y_test_pred_proba[:,1])\n",
    "    print(f\"roc_auc_score: {roc_auc}\", file=file_name)\n",
    "    roc_auc_grid.append(roc_auc)\n",
    "    # print(model.best_estimator_._get_coef(), file=file_name)\n",
    "    # print(f\"intercept: {model.best_estimator_.intercept_}\", file=file_name)\n",
    "\n",
    "\n",
    "    # model_feature_df = pd.DataFrame(\n",
    "    #     {'Importance': model.best_estimator_._get_coef().squeeze(), 'features': features})\n",
    "    # max_coeff_index = list(model.best_estimator_._get_coef().squeeze()).index(\n",
    "    #     model.best_estimator_._get_coef().max())\n",
    "    # print(\n",
    "    #     f'max feature: {model.best_estimator_._get_coef().max()} at index {max_coeff_index} [{features[max_coeff_index]}]', file=file_name)\n",
    "    # coeff_grid[max_coeff_index] += 1\n",
    "    # print('\\n', file=file_name)\n",
    "    # print(model_feature_df, file=file_name)\n",
    "    # print('\\n'*2, file=file_name)\n",
    "\n",
    "    # roc = [ z for z in range(1,num+1)]\n",
    "    print(f\"roc_auc scores on test set: {roc_auc_grid}\", file=file_name)\n",
    "    print(\n",
    "        f\"Average roc_auc scores on test set: {np.average(roc_auc_grid)}\", file=file_name)\n",
    "    print(\n",
    "        f\"std dev of roc_auc scores on test set: {np.std(roc_auc_grid)}\", file=file_name)\n",
    "    print(\n",
    "        f\"Best roc_auc score on test set: {max(roc_auc_grid)} at index {roc_auc_grid.index(max(roc_auc_grid)) + 1}\", file=file_name)\n",
    "    \n",
    "    print('\\n', file=file_name)\n",
    "    # coeff_df = pd.DataFrame(\n",
    "    #     {'Top features': coeff_grid, 'features': features})\n",
    "        \n",
    "    # print(f\"Coefficients: {coeff_df} \\n\", file=file_name)\n",
    "\n",
    "    print(f'Best estimator: {model.best_estimator_} \\n', file=file_name)\n",
    "    print(f'Best params: {model.best_params_} \\n', file=file_name)\n",
    "    print(f'Best estimator: {model.best_estimator_} \\n')\n",
    "    print(f'Best params: {model.best_params_} \\n')\n",
    "\n",
    "    fig = plt.figure()\n",
    "    fig_ax = fig.add_subplot(1, 1, 1)\n",
    "    fig.set_size_inches(12, 8, forward=True)\n",
    "    fig_ax.set_xlabel(\"Number of runs\")\n",
    "    fig_ax.set_ylabel(\"Cross-validation ROC-AUC score\")\n",
    "    fig_ax.set_ylim(0, 1.1)\n",
    "\n",
    "    if folder_name == 'hlife':\n",
    "        title_tag = 'lifetimes'\n",
    "    elif folder_name == 'hnum':\n",
    "        title_tag = 'numbers'\n",
    "    elif folder_name == 'merged':\n",
    "        title_tag = 'numbers + lifetimes'\n",
    "    else:\n",
    "        title_tag = ''  # this could be an indication that the folder_type was not set properly\n",
    "\n",
    "    plt.title(\n",
    "        f'{model_name} (Repeated KFold) hbond {title_tag}', fontsize=12, weight='bold')\n",
    "\n",
    "    fig_ax.plot(range(1, len(roc_auc_grid)+1), roc_auc_grid, '-o', linewidth=2, markersize=8.0, label=f\"avg training roc_auc: {round(np.average(roc_auc_grid),2)}\\n \\\n",
    "    std training roc_auc : {round(np.std(roc_auc_grid),2)}\")\n",
    "\n",
    "    plt.legend(loc='best')\n",
    "    file_name.close()\n",
    "    dirmaker(f'./plots/roc-auc/{folder_name}/{xdate}')\n",
    "    fig.savefig(f'plots/roc-auc/{folder_name}/{xdate}/{model_name}_{folder_name}_{n_repeat}grid-{xdate}_{rand_seed}.png',\n",
    "                dpi=500, facecolor='white', bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def kingmaker_lr(model, p_grid, des_df, nondes_df, cv, file_name, folder_type='unclassified', n_repeat=10, rand_seed=1000, features=features):\n",
    "    '''\n",
    "    This function runs a grid search CV on sklearn Logistic \n",
    "    Regression.\n",
    "    model is the classifier instance,\n",
    "    p_grid is the dictionary of values for the grid search,\n",
    "    cv is the cross-validation instance,\n",
    "    file_name is the txt file for logs,\n",
    "    folder_type can be hlife, hnum, merged, or unclassified\n",
    "    n_repeats is passed to grid search,\n",
    "    rand_seed ensures replicability of CV\n",
    "    '''\n",
    "    folder_name = folder_type\n",
    "    xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "    model_name = model.__str__().strip('()')\n",
    "    if model_name.__contains__(\"XGBClassifier\"):\n",
    "        model_name = \"XGBClassifier\"\n",
    "\n",
    "        \n",
    "    if folder_name == 'hlife' or folder_name == 'hnum':\n",
    "        X_train, y_train, X_test, y_test = data_generator(\n",
    "            des_df, nondes_df, test_sample_size=8, nondes_batch_size=38)\n",
    "    elif folder_name == 'merged':\n",
    "        X_train, y_train, X_test, y_test = df_generator(\n",
    "            des_df, nondes_df, test_sample_size=8, nondes_batch_size=38)\n",
    "    else:\n",
    "        print(\"Check folder_type variable\")\n",
    "\n",
    "    clf = GridSearchCV(model, param_grid=p_grid,\n",
    "                           verbose=1, scoring='roc_auc', cv=cv, refit=True, return_train_score = True)\n",
    "    \n",
    "    model = clf.fit(X_train, y_train)\n",
    "    roc_auc_grid = []\n",
    "\n",
    "    if folder_name == 'hlife' or folder_name == 'hnum':  # hlife/hnum have only 5 features\n",
    "        coeff_grid = [0, 0, 0, 0, 0]\n",
    "    elif folder_name == 'merged':  # merged has 10 features\n",
    "        coeff_grid = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    else:\n",
    "        coeff_grid = [0, 0, 0, 0, 0]\n",
    "\n",
    "    \n",
    "    print(model.cv_results_)\n",
    "    results = pd.DataFrame(model.cv_results_)\n",
    "    # print(results)\n",
    "\n",
    "    # take the most relevant columns and sort (for readability)\n",
    "    results = results.loc[:, ('rank_test_score', 'mean_test_score', 'params')]\n",
    "    results.sort_values(by='rank_test_score', ascending=True, inplace=True)\n",
    "    print(results.head(1))    \n",
    "    print(results, file=file_name)\n",
    "    print('\\n'*2, file=file_name)\n",
    "\n",
    "    print('Best score', model.best_score_, file=file_name)\n",
    "    print('Best params', model.best_params_, file=file_name)\n",
    "\n",
    "    y_test_pred_proba = model.best_estimator_.predict_proba(X_test)  # roc_auc_score needs probabilities\n",
    "    # print('Prediction probabilities: ', y_test_pred_proba)\n",
    "    print(f'Prediction probabilities: {y_test_pred_proba}', file=file_name)\n",
    "\n",
    "    y_test_pred = model.best_estimator_.predict(X_test) \n",
    "    # print('Predictions: ', y_test_pred)\n",
    "    print(f'Predictions: {y_test_pred}', file=file_name)\n",
    "    target_names = ['non-DES', 'DES']  # non-DES is 0, DES is 1\n",
    "    print(metrics.classification_report(y_test, y_test_pred,\n",
    "          target_names=target_names), file=file_name)\n",
    "    roc_auc = metrics.roc_auc_score(y_test, y_test_pred_proba[:,1])\n",
    "    print(f\"roc_auc_score: {roc_auc}\", file=file_name)\n",
    "    roc_auc_grid.append(roc_auc)\n",
    "    print(model.best_estimator_.coef_, file=file_name)\n",
    "    print(f\"intercept: {model.best_estimator_.intercept_}\", file=file_name)\n",
    "\n",
    "\n",
    "    model_feature_df = pd.DataFrame(\n",
    "        {'Importance': model.best_estimator_.coef_.squeeze(), 'features': features})\n",
    "    max_coeff_index = list(model.best_estimator_.coef_.squeeze()).index(\n",
    "        model.best_estimator_.coef_.max())\n",
    "    print(\n",
    "        f'max feature: {model.best_estimator_.coef_.max()} at index {max_coeff_index} [{features[max_coeff_index]}]', file=file_name)\n",
    "    coeff_grid[max_coeff_index] += 1\n",
    "    print('\\n', file=file_name)\n",
    "    print(model_feature_df, file=file_name)\n",
    "    print('\\n'*2, file=file_name)\n",
    "\n",
    "    # roc = [ z for z in range(1,num+1)]\n",
    "    print(f\"roc_auc scores on test set: {roc_auc_grid}\", file=file_name)\n",
    "    print(\n",
    "        f\"Average roc_auc scores on test set: {np.average(roc_auc_grid)}\", file=file_name)\n",
    "    print(\n",
    "        f\"std dev of roc_auc scores on test set: {np.std(roc_auc_grid)}\", file=file_name)\n",
    "    print(\n",
    "        f\"Best roc_auc score on test set: {max(roc_auc_grid)} at index {roc_auc_grid.index(max(roc_auc_grid)) + 1}\", file=file_name)\n",
    "    \n",
    "    print('\\n', file=file_name)\n",
    "    coeff_df = pd.DataFrame(\n",
    "        {'Top features': coeff_grid, 'features': features})\n",
    "        \n",
    "    print(f\"Coefficients: {coeff_df} \\n\", file=file_name)\n",
    "\n",
    "    print(f'Best estimator: {model.best_estimator_} \\n', file=file_name)\n",
    "    print(f'Best params: {model.best_params_} \\n', file=file_name)\n",
    "    print(f'Best estimator: {model.best_estimator_} \\n')\n",
    "    print(f'Best params: {model.best_params_} \\n')\n",
    "\n",
    "    fig = plt.figure()\n",
    "    fig_ax = fig.add_subplot(1, 1, 1)\n",
    "    fig.set_size_inches(12, 8, forward=True)\n",
    "    fig_ax.set_xlabel(\"Number of runs\")\n",
    "    fig_ax.set_ylabel(\"Cross-validation ROC-AUC score\")\n",
    "    fig_ax.set_ylim(0, 1.1)\n",
    "\n",
    "    if folder_name == 'hlife':\n",
    "        title_tag = 'lifetimes'\n",
    "    elif folder_name == 'hnum':\n",
    "        title_tag = 'numbers'\n",
    "    elif folder_name == 'merged':\n",
    "        title_tag = 'numbers + lifetimes'\n",
    "    else:\n",
    "        title_tag = ''  # this could be an indication that the folder_type was not set properly\n",
    "\n",
    "    plt.title(\n",
    "        f'{model_name} (Repeated KFold) hbond {title_tag}', fontsize=12, weight='bold')\n",
    "\n",
    "    fig_ax.plot(range(1, len(roc_auc_grid)+1), roc_auc_grid, '-o', linewidth=2, markersize=8.0, label=f\"avg training roc_auc: {round(np.average(roc_auc_grid),2)}\\n \\\n",
    "    std training roc_auc : {round(np.std(roc_auc_grid),2)}\")\n",
    "\n",
    "    plt.legend(loc='best')\n",
    "    file_name.close()\n",
    "    dirmaker(f'./plots/roc-auc/{folder_name}/{xdate}')\n",
    "    fig.savefig(f'plots/roc-auc/{folder_name}/{xdate}/{model_name}_{folder_name}_{n_repeat}grid-{xdate}_{rand_seed}.png',\n",
    "                dpi=500, facecolor='white', bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hbond lifetimes\n",
    "Train models using hlife data alone."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### hlife house cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nondes_df_hlife = nondes_hlife.drop(columns=['Non-DES'])\n",
    "nondes_df_hlife['output'] = 0\n",
    "# nondes_df_hlife"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "des_df_hlife = des_hlife.drop(columns=['DES'])\n",
    "des_df_hlife['output'] = 1\n",
    "# des_df_hlife"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loops"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBClassifier\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"xtick.labelsize\": 14,\n",
    "    \"ytick.labelsize\": 14,\n",
    "    'font.size': 18,\n",
    "    'axes.labelweight': 'bold',\n",
    "    'figure.dpi': 150.0,\n",
    "    'axes.linewidth':2.0,\n",
    "})\n",
    "\n",
    "models = {    \n",
    "    \"XGB\": XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=0.1,\n",
    "              enable_categorical=False, eval_metric='auc', gamma=0, gpu_id=-1,\n",
    "              importance_type=None, interaction_constraints='',\n",
    "              learning_rate=0.01, max_delta_step=0, max_depth=2,\n",
    "              min_child_weight=1, monotone_constraints='()',\n",
    "              n_estimators=10, n_jobs=12, num_parallel_tree=1, predictor='auto',\n",
    "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
    "              subsample=1, tree_method='hist', \n",
    "              validate_parameters=1, verbosity=None\n",
    ")\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "rand_seed = 100\n",
    "n_repeat = 100\n",
    "folder_type='hlife'\n",
    "\n",
    "tag = \"XGB\"\n",
    "model_type = models[tag]\n",
    "model_name = model_type.__str__().split('(')[0]\n",
    "\n",
    "print(f\"{tag} training for {n_repeat} runs\")\n",
    "\n",
    "if model_name.__contains__(\"XGBClassifier\"):\n",
    "    model_name = \"XGBClassifier\"\n",
    "\n",
    "dirmaker(f'./model-logs/training/{folder_type}/{xdate}')\n",
    "file_name = open(\n",
    "    f\"./model-logs/training/{folder_type}/{xdate}/{model_name}_{folder_type}_{n_repeat}_{xdate}_{rand_seed}.txt\", \"w+\")\n",
    "\n",
    "train_xgb(model_type, des_df_hlife, nondes_df_hlife, \n",
    "file_name=file_name, folder_type=folder_type, num=n_repeat, rand_seed=rand_seed, features=features)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# XGBRF\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"xtick.labelsize\": 14,\n",
    "    \"ytick.labelsize\": 14,\n",
    "    'font.size': 18,\n",
    "    'axes.labelweight': 'bold',\n",
    "    'figure.dpi': 150.0,\n",
    "    'axes.linewidth':2.0,\n",
    "})\n",
    "\n",
    "models = {    \n",
    "    \"XGBRF\": XGBRFClassifier(base_score=None, booster=None, callbacks=None,\n",
    "                colsample_bylevel=None, colsample_bytree=0.4,\n",
    "                early_stopping_rounds=None, enable_categorical=False,\n",
    "                eval_metric='auc', feature_types=None, gamma=None, gpu_id=None,\n",
    "                grow_policy=None, importance_type=None,\n",
    "                interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
    "                max_cat_threshold=None, max_cat_to_onehot=None,\n",
    "                max_delta_step=None, max_depth=2, max_leaves=None,\n",
    "                min_child_weight=None, monotone_constraints=None,\n",
    "                n_estimators=10, n_jobs=12, num_parallel_tree=None,\n",
    "                objective='binary:logistic', predictor=None, random_state=None) \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "rand_seed = 100\n",
    "n_repeat = 100\n",
    "folder_type='hlife'\n",
    "\n",
    "tag = \"XGBRF\"\n",
    "model_type = models[tag]\n",
    "model_name = model_type.__str__().split('(')[0]\n",
    "\n",
    "print(f\"{tag} training for {n_repeat} runs\")\n",
    "\n",
    "if model_name.__contains__(\"XGBClassifier\"):\n",
    "    model_name = \"XGBClassifier\"\n",
    "\n",
    "dirmaker(f'./model-logs/training/{folder_type}/{xdate}')\n",
    "file_name = open(\n",
    "    f\"./model-logs/training/{folder_type}/{xdate}/{model_name}_{folder_type}_{n_repeat}_{xdate}_{rand_seed}.txt\", \"w+\")\n",
    "\n",
    "train_xgb(model_type, des_df_hlife, nondes_df_hlife, \n",
    "file_name=file_name, folder_type=folder_type, num=n_repeat, rand_seed=rand_seed, features=features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGB and XGBRF eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBClassifier\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"xtick.labelsize\": 14,\n",
    "    \"ytick.labelsize\": 14,\n",
    "    'font.size': 18,\n",
    "    'axes.labelweight': 'bold',\n",
    "    'figure.dpi': 150.0,\n",
    "    'axes.linewidth':2.0,\n",
    "})\n",
    "\n",
    "models = {    \n",
    "    \"XGB\": XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=0.1,\n",
    "              enable_categorical=False, eval_metric='auc', gamma=0, gpu_id=-1,\n",
    "              importance_type=None, interaction_constraints='',\n",
    "              learning_rate=0.01, max_delta_step=0, max_depth=2,\n",
    "              min_child_weight=1, monotone_constraints='()',\n",
    "              n_estimators=10, n_jobs=12, num_parallel_tree=1, predictor='auto',\n",
    "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
    "              subsample=1, tree_method='hist', \n",
    "              validate_parameters=1, verbosity=None),\n",
    "     \"XGBRF\": XGBRFClassifier(base_score=None, booster=None, callbacks=None,\n",
    "                colsample_bylevel=None, colsample_bytree=0.4,\n",
    "                early_stopping_rounds=None, enable_categorical=False,\n",
    "                eval_metric='auc', feature_types=None, gamma=None, gpu_id=None,\n",
    "                grow_policy=None, importance_type=None,\n",
    "                interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
    "                max_cat_threshold=None, max_cat_to_onehot=None,\n",
    "                max_delta_step=None, max_depth=2, max_leaves=None,\n",
    "                min_child_weight=None, monotone_constraints=None,\n",
    "                n_estimators=10, n_jobs=12, num_parallel_tree=None,\n",
    "                objective='binary:logistic', predictor=None, random_state=None)\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "rand_seed = 100\n",
    "n_repeat = 100\n",
    "folder_type='hlife'\n",
    "\n",
    "tag = \"XGBRF\"\n",
    "model_type = models[tag]\n",
    "model_name = model_type.__str__().split('(')[0]\n",
    "\n",
    "print(f\"{tag} training for {n_repeat} runs\")\n",
    "\n",
    "if model_name.__contains__(\"XGBClassifier\"):\n",
    "    model_name = \"XGBClassifier\"\n",
    "\n",
    "dirmaker(f'./model-logs/training/{folder_type}/{xdate}')\n",
    "file_name = open(\n",
    "    f\"./model-logs/training/{folder_type}/{xdate}/{model_name}_eval_{folder_type}_{n_repeat}_{xdate}_{rand_seed}.txt\", \"w+\")\n",
    "\n",
    "# Use this for getting validation metrics plotted alongside training metrics\n",
    "train_xgb_eval(model_type, des_df_hlife, nondes_df_hlife, \n",
    "file_name=file_name, folder_type=folder_type, num=n_repeat, rand_seed=rand_seed, features=features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN old\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"xtick.labelsize\": 14,\n",
    "    \"ytick.labelsize\": 14,\n",
    "    'font.size': 18,\n",
    "    'axes.labelweight': 'bold',\n",
    "    'figure.dpi': 150.0,\n",
    "})\n",
    "\n",
    "\n",
    "models = {\n",
    "    \"KNN\": KNeighborsClassifier(metric='manhattan', n_jobs=-1, n_neighbors=15,\n",
    "                     weights='distance')\n",
    "}\n",
    "\n",
    "xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "rand_seed = 100\n",
    "n_repeat = 100\n",
    "folder_type='hlife'\n",
    "\n",
    "tag = \"KNN\"\n",
    "model_type = models[tag]\n",
    "model_name = model_type.__str__().split('(')[0]\n",
    "print(model_name)\n",
    "print(f\"{tag} training for {n_repeat} runs\")\n",
    "\n",
    "dirmaker(f'./model-logs/training/{folder_type}/{xdate}')\n",
    "file_name = open(\n",
    "    f\"./model-logs/training/{folder_type}/{xdate}/{model_name}_{folder_type}_{n_repeat}_{xdate}_{rand_seed}.txt\", \"w+\")\n",
    "\n",
    "\n",
    "train_knn(model_type, des_df_hlife, nondes_df_hlife, \n",
    "file_name=file_name, folder_type=folder_type, num=n_repeat, rand_seed=rand_seed, features=features, model_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"xtick.labelsize\": 14,\n",
    "    \"ytick.labelsize\": 14,\n",
    "    'font.size': 18,\n",
    "    'axes.labelweight': 'bold',\n",
    "    'figure.dpi': 150.0,\n",
    "})\n",
    "\n",
    "\n",
    "models = {\n",
    "    \"LR\": LogisticRegression(max_iter=400)\n",
    "}\n",
    "\n",
    "xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "rand_seed = 100\n",
    "n_repeat = 100\n",
    "folder_type='hlife'\n",
    "# cv = RepeatedKFold(n_splits=6, n_repeats=n_repeat, random_state=rand_seed)\n",
    "\n",
    "tag = \"LR\"\n",
    "model_type = models[tag]\n",
    "model_name = model_type.__str__().split('(')[0]\n",
    "print(f\"{tag} training for {n_repeat} runs\")\n",
    "\n",
    "dirmaker(f'./model-logs/training/{folder_type}/{xdate}')\n",
    "file_name = open(\n",
    "    f\"./model-logs/training/{folder_type}/{xdate}/{model_name}_{folder_type}_{n_repeat}_{xdate}_{rand_seed}.txt\", \"w+\")\n",
    "\n",
    "\n",
    "train_lr(model_type, des_df_hlife, nondes_df_hlife, \n",
    "file_name=file_name, folder_type=folder_type, num=n_repeat, rand_seed=rand_seed, features=features, model_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AB, DT, EF, GB, RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AB, DT, EF, GB, RF\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"xtick.labelsize\": 14,\n",
    "    \"ytick.labelsize\": 14,\n",
    "    'font.size': 18,\n",
    "    'axes.labelweight': 'bold',\n",
    "    'figure.dpi': 150.0,\n",
    "})\n",
    "\n",
    "models = {\n",
    "    \"RF\": RandomForestClassifier(max_depth=10, max_features='sqrt', min_samples_leaf=3,\n",
    "                       min_samples_split=4, n_estimators=30),\n",
    "    \"EF\": ExtraTreesClassifier(max_depth=10, max_features='sqrt', min_samples_leaf=3,\n",
    "                     min_samples_split=6, n_estimators=20),\n",
    "    \"GB\": GradientBoostingClassifier(learning_rate=0.01, max_depth=4, max_features='log2',\n",
    "                           n_estimators=20),\n",
    "    \"AB\": AdaBoostClassifier(learning_rate=0.01, n_estimators=80),\n",
    "    \"DT\": DecisionTreeClassifier(max_depth=10, max_features='log2', min_samples_leaf=3,\n",
    "                       min_samples_split=6)\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "rand_seed = 100\n",
    "n_repeat = 100\n",
    "folder_type='hlife'\n",
    "\n",
    "# tag = \"DT\"\n",
    "for x in models.keys():\n",
    "    tag = x\n",
    "    model_type = models[tag]\n",
    "    model_name = model_type.__str__().split('(')[0]\n",
    "\n",
    "    print(f\"{tag} training for {n_repeat} runs\")\n",
    "\n",
    "    if model_name.__contains__(\"XGBClassifier\"):\n",
    "        model_name = \"XGBClassifier\"\n",
    "\n",
    "    dirmaker(f'./model-logs/training/{folder_type}/{xdate}')\n",
    "    file_name = open(\n",
    "        f\"./model-logs/training/{folder_type}/{xdate}/{model_name}_{folder_type}_{n_repeat}_{xdate}_{rand_seed}.txt\", \"w+\")\n",
    "\n",
    "    train_ab_dt_ef_gb_rf(model_type, des_df_hlife, nondes_df_hlife, \n",
    "    file_name=file_name, folder_type=folder_type, num=n_repeat, rand_seed=rand_seed, features=features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"xtick.labelsize\": 14,\n",
    "    \"ytick.labelsize\": 14,\n",
    "    'font.size': 18,\n",
    "    'axes.labelweight': 'bold',\n",
    "    'figure.dpi': 150.0,\n",
    "})\n",
    "\n",
    "\n",
    "models = {\n",
    "    \"KNN\": KNeighborsClassifier(metric='manhattan', n_jobs=-1, weights='distance')\n",
    "}\n",
    "\n",
    "xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "rand_seed = 100\n",
    "n_repeat = 100\n",
    "folder_type='hlife'\n",
    "\n",
    "tag = \"KNN\"\n",
    "model_type = models[tag]\n",
    "model_name = model_type.__str__().split('(')[0]\n",
    "print(model_name)\n",
    "print(f\"{tag} training for {n_repeat} runs\")\n",
    "\n",
    "dirmaker(f'./model-logs/training/{folder_type}/{xdate}')\n",
    "file_name = open(\n",
    "    f\"./model-logs/training/{folder_type}/{xdate}/{model_name}_{folder_type}_{n_repeat}_{xdate}_{rand_seed}.txt\", \"w+\")\n",
    "\n",
    "\n",
    "train_knn(model_type, des_df_hlife, nondes_df_hlife, \n",
    "file_name=file_name, folder_type=folder_type, num=n_repeat, rand_seed=rand_seed, features=features, model_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"xtick.labelsize\": 14,\n",
    "    \"ytick.labelsize\": 14,\n",
    "    'font.size': 18,\n",
    "    'axes.labelweight': 'bold',\n",
    "    'figure.dpi': 150.0,\n",
    "})\n",
    "\n",
    "\n",
    "models = {\n",
    "    \"SVC\": SVC(kernel='linear', probability=True)\n",
    "}\n",
    "\n",
    "xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "rand_seed = 100\n",
    "n_repeat = 100\n",
    "folder_type='hlife'\n",
    "\n",
    "tag = \"SVC\"\n",
    "model_type = models[tag]\n",
    "model_name = model_type.__str__().split('(')[0]\n",
    "print(model_name)\n",
    "print(f\"{tag} training for {n_repeat} runs\")\n",
    "\n",
    "dirmaker(f'./model-logs/training/{folder_type}/{xdate}')\n",
    "file_name = open(\n",
    "    f\"./model-logs/training/{folder_type}/{xdate}/{model_name}_{folder_type}_{n_repeat}_{xdate}_{rand_seed}.txt\", \"w+\")\n",
    "\n",
    "\n",
    "train_svc(model_type, des_df_hlife, nondes_df_hlife, \n",
    "file_name=file_name, folder_type=folder_type, num=n_repeat, rand_seed=rand_seed, features=features, model_name=model_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparam optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.rcParams.update({\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"xtick.labelsize\": 14,\n",
    "    \"ytick.labelsize\": 14,\n",
    "    'font.size': 18,\n",
    "    'axes.labelweight': 'bold',\n",
    "    'figure.dpi': 300.0,\n",
    "    'axes.linewidth':2.0,\n",
    "})\n",
    "\n",
    "models = {\n",
    "     \"XGB\": XGBClassifier(\n",
    "            tree_method='hist',\n",
    "            use_label_encoder=False,\n",
    "            eval_metric='auc',\n",
    "            objective='binary:logistic',\n",
    "            n_jobs=multiprocessing.cpu_count())  \n",
    "}\n",
    "\n",
    "params = { 'XGB':{'max_depth': [2, 4, 6, 8, 10],\n",
    "             'n_estimators': [10, 20, 30, 40, 50, 100],\n",
    "             'learning_rate': [0.01, 0.1],\n",
    "             'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "             }\n",
    "}\n",
    "\n",
    "print(\"Parallel Parameter optimization\")\n",
    "xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "rand_seed = 100\n",
    "n_repeat = 10\n",
    "cv = RepeatedKFold(n_splits=6, n_repeats=n_repeat, random_state=rand_seed)\n",
    "tag = \"XGB\"\n",
    "print(f\"{tag} Parallel Parameter optimization\")\n",
    "\n",
    "model_generic = models[tag]  \n",
    "p_repeatK = params[tag]\n",
    "model_name = model_generic.__str__().split('(')[0]\n",
    "folder_type = 'hlife'\n",
    "\n",
    "dirmaker(f'./model-logs/gridsearch/{folder_type}/{xdate}')\n",
    "file_hlife_xgb_repeatK = open(\n",
    "    f\"./model-logs/gridsearch/{folder_type}/{xdate}/{model_name}_{folder_type}_{n_repeat}_{xdate}_{rand_seed}.txt\", \"w+\")\n",
    "\n",
    "\n",
    "kingmaker_xgb(model_generic, p_repeatK, des_df_hlife, nondes_df_hlife, cv=cv,\n",
    "           file_name=file_hlife_xgb_repeatK, folder_type=folder_type, n_repeat=n_repeat, rand_seed=rand_seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBRF\n",
    "plt.rcParams.update({\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"xtick.labelsize\": 14,\n",
    "    \"ytick.labelsize\": 14,\n",
    "    'font.size': 18,\n",
    "    'axes.labelweight': 'bold',\n",
    "    'figure.dpi': 300.0,\n",
    "    'axes.linewidth':2.0,\n",
    "})\n",
    "\n",
    "models = {\n",
    "    \"XGBRF\": XGBRFClassifier(\n",
    "            tree_method='hist',\n",
    "            eval_metric='auc',\n",
    "            objective='binary:logistic',\n",
    "            n_jobs=multiprocessing.cpu_count())  \n",
    "}\n",
    "\n",
    "params = {\n",
    "           'XGBRF':{'max_depth': [2, 4, 6, 8, 10],\n",
    "             'n_estimators': [10, 20, 30, 40, 50, 100],\n",
    "             'learning_rate': [0.01, 0.1],\n",
    "             'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "             }\n",
    "}\n",
    "\n",
    "print(\"Parallel Parameter optimization\")\n",
    "xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "rand_seed = 100\n",
    "n_repeat = 10\n",
    "cv = RepeatedKFold(n_splits=6, n_repeats=n_repeat, random_state=rand_seed)\n",
    "tag = \"XGBRF\"\n",
    "print(f\"{tag} Parallel Parameter optimization\")\n",
    "\n",
    "model_generic = models[tag]  \n",
    "p_repeatK = params[tag]\n",
    "model_name = model_generic.__str__().split('(')[0]\n",
    "print(model_name)\n",
    "folder_type = 'hlife'\n",
    "\n",
    "dirmaker(f'./model-logs/gridsearch/{folder_type}/{xdate}')\n",
    "file_hlife_xgb_repeatK = open(\n",
    "    f\"./model-logs/gridsearch/{folder_type}/{xdate}/{model_name}_{folder_type}_{n_repeat}_{xdate}_{rand_seed}.txt\", \"w+\")\n",
    "\n",
    "\n",
    "kingmaker_xgbrf(model_generic, p_repeatK, des_df_hlife, nondes_df_hlife, cv=cv, features=features,\n",
    "           file_name=file_hlife_xgb_repeatK, folder_type=folder_type, n_repeat=n_repeat, rand_seed=rand_seed)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LR\n",
    "plt.rcParams.update({\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"xtick.labelsize\": 14,\n",
    "    \"ytick.labelsize\": 14,\n",
    "    'font.size': 18,\n",
    "    'axes.labelweight': 'bold',\n",
    "    'figure.dpi': 150.0,\n",
    "})\n",
    "\n",
    "models = {\n",
    "    \"LR\": LogisticRegression()\n",
    "}\n",
    "\n",
    "params = {\n",
    "    \"LR\": {'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "            'tol': [1e-4, 1e-6],\n",
    "             'max_iter': [100, 200, 300, 400, 500],\n",
    "             'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "             }\n",
    "}\n",
    "\n",
    "\n",
    "xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "rand_seed = 100\n",
    "n_repeat = 10\n",
    "cv = RepeatedKFold(n_splits=6, n_repeats=n_repeat, random_state=rand_seed)\n",
    "tag = \"LR\"\n",
    "print(f\"{tag} Parallel Parameter optimization\")\n",
    "\n",
    "model_generic = models[tag]  \n",
    "p_repeatK = params[tag]\n",
    "model_name = model_generic.__str__().strip('()')\n",
    "folder_type = 'hlife'\n",
    "\n",
    "dirmaker(f'./model-logs/{folder_type}/{xdate}')\n",
    "file_name = open(\n",
    "    f\"./model-logs/{folder_type}/{xdate}/{model_name}_{folder_type}_{n_repeat}_{xdate}_{rand_seed}.txt\", \"w+\")\n",
    "\n",
    "kingmaker_lr(model_generic, p_repeatK, des_df_hlife, nondes_df_hlife, cv=cv,\n",
    "           file_name=file_name, folder_type=folder_type, n_repeat=n_repeat, rand_seed=rand_seed)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "plt.rcParams.update({\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"xtick.labelsize\": 14,\n",
    "    \"ytick.labelsize\": 14,\n",
    "    'font.size': 18,\n",
    "    'axes.labelweight': 'bold',\n",
    "    'figure.dpi': 150.0,\n",
    "})\n",
    "\n",
    "models = {\n",
    "    \"KNN\": KNeighborsClassifier(n_jobs=-1)\n",
    "}\n",
    "\n",
    "params = {\n",
    "    \"KNN\": {'n_neighbors' : [5,7,9,11,13,15],\n",
    "               'weights' : ['uniform','distance'],\n",
    "               'metric' : ['minkowski','euclidean','manhattan'],\n",
    "               'leaf_size' : [30, 40, 50, 60]\n",
    "               }\n",
    "}\n",
    "\n",
    "\n",
    "xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "rand_seed = 100\n",
    "n_repeat = 10\n",
    "cv = RepeatedKFold(n_splits=6, n_repeats=n_repeat, random_state=rand_seed)\n",
    "tag = \"KNN\"\n",
    "print(f\"{tag} Parallel Parameter optimization\")\n",
    "\n",
    "model_generic = models[tag]  \n",
    "p_repeatK = params[tag]\n",
    "model_name = model_generic.__str__().split('(')[0]\n",
    "folder_type = 'hlife'\n",
    "\n",
    "dirmaker(f'./model-logs/gridsearch/{folder_type}/{xdate}')\n",
    "file_name = open(\n",
    "    f\"./model-logs/gridsearch/{folder_type}/{xdate}/{model_name}_{folder_type}_{n_repeat}_{xdate}_{rand_seed}.txt\", \"w+\")\n",
    "\n",
    "kingmaker_knn(model_generic, p_repeatK, des_df_hlife, nondes_df_hlife, cv=cv,\n",
    "           file_name=file_name, folder_type=folder_type, n_repeat=n_repeat, rand_seed=rand_seed)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC\n",
    "plt.rcParams.update({\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"xtick.labelsize\": 14,\n",
    "    \"ytick.labelsize\": 14,\n",
    "    'font.size': 18,\n",
    "    'axes.labelweight': 'bold',\n",
    "    'figure.dpi': 150.0,\n",
    "})\n",
    "\n",
    "models = {\n",
    "    \"SVC\": SVC(probability=True),\n",
    "    \"SVC1\": SVC(probability=True)\n",
    "}\n",
    "\n",
    "# 'gamma': ['scale', 'auto'],\n",
    "\n",
    "params = {\n",
    "    \"SVC\": {'gamma': ['scale', 'auto'],\n",
    "            'tol': [1e-3, 1e-4, 1e-5, 1e-6],\n",
    "             'degree': [3, 5, 7],\n",
    "             'kernel' : ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "             }\n",
    "}\n",
    "\n",
    "\n",
    "xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "rand_seed = 100\n",
    "n_repeat = 10\n",
    "cv = RepeatedKFold(n_splits=6, n_repeats=n_repeat, random_state=rand_seed)\n",
    "tag = \"SVC\"\n",
    "print(f\"{tag} Parallel Parameter optimization\")\n",
    "\n",
    "model_generic = models[tag]  \n",
    "p_repeatK = params[tag]\n",
    "model_name = model_generic.__str__().split('(')[0]\n",
    "folder_type = 'hlife'\n",
    "\n",
    "dirmaker(f'./model-logs/gridsearch/{folder_type}/{xdate}')\n",
    "file_name = open(\n",
    "    f\"./model-logs/gridsearch/{folder_type}/{xdate}/{model_name}_{folder_type}_{n_repeat}_{xdate}_{rand_seed}.txt\", \"w+\")\n",
    "\n",
    "kingmaker_svc(model_generic, p_repeatK, des_df_hlife, nondes_df_hlife, cv=cv,\n",
    "           file_name=file_name, folder_type=folder_type, n_repeat=n_repeat, rand_seed=rand_seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.rcParams.update({\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"xtick.labelsize\": 14,\n",
    "    \"ytick.labelsize\": 14,\n",
    "    'font.size': 18,\n",
    "    'axes.labelweight': 'bold',\n",
    "    'figure.dpi': 150.0,\n",
    "})\n",
    "\n",
    "models = {\n",
    "    \"RF\": RandomForestClassifier(),\n",
    "    \"EF\": ExtraTreesClassifier(),\n",
    "    \"GB\": GradientBoostingClassifier(),\n",
    "    \"AB\": AdaBoostClassifier(),\n",
    "    \"DT\": DecisionTreeClassifier(),\n",
    "    \"XGB\": XGBClassifier(),\n",
    "}\n",
    "\n",
    "params = {\n",
    "    \"RF\": {'max_depth': [2, 4, 6, 8, 10],\n",
    "             'n_estimators': [10, 20, 30, 40, 50, 100],\n",
    "             'min_samples_leaf': [1, 2, 3],\n",
    "            'min_samples_split': [2,4,6],\n",
    "             'max_features': [\"auto\", \"sqrt\", \"log2\"],\n",
    "             },\n",
    "    \"EF\": {'max_depth': [2, 4, 6, 8, 10],\n",
    "             'n_estimators': [10, 20, 30, 40, 50, 100],\n",
    "             'min_samples_leaf': [1, 2, 3],\n",
    "            'min_samples_split': [2,4,6],\n",
    "             'max_features': [\"auto\", \"sqrt\", \"log2\"],\n",
    "             },\n",
    "    \"GB\": {'max_depth': [2, 4, 6, 8, 10],\n",
    "             'n_estimators': [10, 20, 30, 40, 50, 100],\n",
    "             'min_samples_leaf': [1, 2, 3],\n",
    "            'min_samples_split': [2,4,6],\n",
    "             'max_features': [\"auto\", \"sqrt\", \"log2\"],\n",
    "             'learning_rate': [0.01, 0.1],\n",
    "             },\n",
    "    \"AB\": {'n_estimators': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "             'learning_rate': [0.001, 0.01, 0.1, 1.0],\n",
    "             },\n",
    "    \"DT\": {'max_depth': [2, 4, 6, 8, 10],\n",
    "             'min_samples_leaf': [1, 2, 3],\n",
    "            'min_samples_split': [2,4,6],\n",
    "             'max_features': [\"auto\", \"sqrt\", \"log2\"],\n",
    "             }\n",
    "}\n",
    "\n",
    "\n",
    "xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "rand_seed = 100\n",
    "n_repeat = 10\n",
    "cv = RepeatedKFold(n_splits=6, n_repeats=n_repeat, random_state=rand_seed)\n",
    "tag = \"RF\"\n",
    "print(f\"{tag} Parallel Parameter optimization\")\n",
    "\n",
    "model_generic = models[tag]  \n",
    "p_repeatK = params[tag]\n",
    "model_name = model_generic.__str__().strip('()')\n",
    "folder_type = 'hlife'\n",
    "\n",
    "if model_name.__contains__(\"XGBClassifier\"):\n",
    "    model_name = \"XGBClassifier\"\n",
    "\n",
    "\n",
    "dirmaker(f'./model-logs/{folder_type}/{xdate}')\n",
    "file_name = open(\n",
    "    f\"./model-logs/{folder_type}/{xdate}/{model_name}_{folder_type}_{n_repeat}_{xdate}_{rand_seed}.txt\", \"w+\")\n",
    "\n",
    "kingmaker_generic(model_generic, p_repeatK, des_df_hlife, nondes_df_hlife, cv=cv,\n",
    "           file_name=file_name, folder_type=folder_type, n_repeat=n_repeat, rand_seed=rand_seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost with Repeated KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "import multiprocessing\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"xtick.labelsize\": 14,\n",
    "    \"ytick.labelsize\": 14,\n",
    "    'font.size': 18,\n",
    "    'axes.labelweight': 'bold',\n",
    "    'figure.dpi': 150.0,\n",
    "})  # 'figure.figsize': [14.0, 10.0],\n",
    "\n",
    "\n",
    "print(\"Parallel Parameter optimization\")\n",
    "xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "xgb_roc_auc_repeatK = []\n",
    "coeff_xgb_repeatK = [0, 0, 0, 0, 0]\n",
    "rand_seed = 100\n",
    "n_repeat = 10\n",
    "cv = RepeatedKFold(n_splits=5, n_repeats=n_repeat, random_state=rand_seed)\n",
    "\n",
    "dirmaker(f'./model-logs/hlife/{xdate}')\n",
    "file_hlife_xgb_repeatK = open(\n",
    "    f\"./model-logs/hlife/{xdate}/XGB_hlife_{n_repeat}repeatKFold_{xdate}_{rand_seed}.txt\", \"w+\")\n",
    "\n",
    "xgb_class_hliferepeatK = XGBClassifier(\n",
    "    tree_method='hist',\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='auc',\n",
    "    objective='binary:logistic',\n",
    "    n_jobs=multiprocessing.cpu_count() // 2)  # tree_method='gpu_hist', enable_categorical=True, predictor='gpu_predictor',\n",
    "\n",
    "p_repeatK = {'max_depth': [2, 4, 6, 8, 10],\n",
    "             'n_estimators': [10, 20, 30, 40, 50, 100],\n",
    "             'learning_rate': [0.01, 0.1],\n",
    "             # ,0.6,0.7,0.8,0.9,1.0\n",
    "             'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "             }\n",
    "\n",
    "\n",
    "X_train_hlife, y_train_hlife, X_test_hlife, y_test_hlife = data_generator(\n",
    "    des_df_hlife, nondes_df_hlife, test_sample_size=8, nondes_batch_size=38)\n",
    "\n",
    "xgb_clf = GridSearchCV(xgb_class_hliferepeatK,\n",
    "                       param_grid=p_repeatK, verbose=1, scoring='roc_auc', cv=cv)\n",
    "\n",
    "xgb_class_hlife_repeatK = xgb_clf.fit(X_train_hlife, y_train_hlife, eval_set=[(X_train_hlife, y_train_hlife), (\n",
    "    X_test_hlife, y_test_hlife)], verbose=False, early_stopping_rounds=50)  # , early_stopping_rounds=50\n",
    "\n",
    "print('Best score', xgb_class_hlife_repeatK.best_score_,\n",
    "      file=file_hlife_xgb_repeatK)\n",
    "print('Best params', xgb_class_hlife_repeatK.best_params_,\n",
    "      file=file_hlife_xgb_repeatK)\n",
    "y_pred_hlife_xgb = xgb_class_hlife_repeatK.best_estimator_.predict(\n",
    "    X_test_hlife)\n",
    "target_names = ['non-DES', 'DES']  # non-DES is 0, DES is 1\n",
    "print(metrics.classification_report(y_test_hlife, y_pred_hlife_xgb,\n",
    "      target_names=target_names), file=file_hlife_xgb_repeatK)\n",
    "roc_auc_xgb = metrics.roc_auc_score(y_test_hlife, y_pred_hlife_xgb)\n",
    "print(f\"roc_auc_score: {roc_auc_xgb}\", file=file_hlife_xgb_repeatK)\n",
    "xgb_roc_auc_repeatK.append(roc_auc_xgb)\n",
    "print(xgb_class_hlife_repeatK.best_estimator_.feature_importances_,\n",
    "      file=file_hlife_xgb_repeatK)\n",
    "# print(f\"intercept: {xgb_class_hlife_repeatK.intercept_}\", file=file_hlife_xgb_repeatK)\n",
    "\n",
    "xgb_class_hlife_repeatK_feature_df = pd.DataFrame(\n",
    "    {'Importance': xgb_class_hlife_repeatK.best_estimator_.feature_importances_, 'features': features})\n",
    "max_coeff_index = list(xgb_class_hlife_repeatK.best_estimator_.feature_importances_).index(\n",
    "    xgb_class_hlife_repeatK.best_estimator_.feature_importances_.max())\n",
    "print(\n",
    "    f'max feature: {xgb_class_hlife_repeatK.best_estimator_.feature_importances_.max()} at index {max_coeff_index} [{features[max_coeff_index]}]', file=file_hlife_xgb_repeatK)\n",
    "coeff_xgb_repeatK[max_coeff_index] += 1\n",
    "print('\\n', file=file_hlife_xgb_repeatK)\n",
    "print(xgb_class_hlife_repeatK_feature_df, file=file_hlife_xgb_repeatK)\n",
    "print('\\n'*2, file=file_hlife_xgb_repeatK)\n",
    "\n",
    "# roc = [ z for z in range(1,num+1)]\n",
    "print(\n",
    "    f\"roc_auc scores on test set: {xgb_roc_auc_repeatK}\", file=file_hlife_xgb_repeatK)\n",
    "print(\n",
    "    f\"Average roc_auc scores on test set: {np.average(xgb_roc_auc_repeatK)}\", file=file_hlife_xgb_repeatK)\n",
    "print(\n",
    "    f\"std dev of roc_auc scores on test set: {np.std(xgb_roc_auc_repeatK)}\", file=file_hlife_xgb_repeatK)\n",
    "print(\n",
    "    f\"Best roc_auc score on test set: {max(xgb_roc_auc_repeatK)} at index {xgb_roc_auc_repeatK.index(max(xgb_roc_auc_repeatK)) + 1}\", file=file_hlife_xgb_repeatK)\n",
    "print(\n",
    "    f\"Best model's roc_auc score from early stopping: {xgb_class_hlife_repeatK.best_estimator_.best_score}\", file=file_hlife_xgb_repeatK)\n",
    "print(\n",
    "    f\"Best model's iteration from early stopping: {xgb_class_hlife_repeatK.best_estimator_.best_iteration}\", file=file_hlife_xgb_repeatK)\n",
    "# print(f\"model's eval_results: {xgb_class_hlife_repeatK.best_estimator_.evals_result()}\", file=file_hlife_xgb_repeatK)\n",
    "train_eval = list(xgb_class_hlife_repeatK.best_estimator_.evals_result()[\n",
    "                  'validation_0'].items())\n",
    "print(\n",
    "    f'Number of training auc scores: {len(train_eval[0][1])}', file=file_hlife_xgb_repeatK)\n",
    "print(\n",
    "    f'auc scores of training set: {train_eval[0][1]}', file=file_hlife_xgb_repeatK)\n",
    "print(f'Average and std-dev of auc scores of training set: {round(np.average(train_eval[0][1]),2)}, \\\n",
    "{round(np.std(train_eval[0][1]),2)} \\n', file=file_hlife_xgb_repeatK)\n",
    "\n",
    "val_eval = list(xgb_class_hlife_repeatK.best_estimator_.evals_result()[\n",
    "                'validation_1'].items())\n",
    "print(\n",
    "    f'Number of testing auc scores: {len(val_eval[0][1])}', file=file_hlife_xgb_repeatK)\n",
    "print(\n",
    "    f'auc scores of testing set: {val_eval[0][1]}', file=file_hlife_xgb_repeatK)\n",
    "print(f'Average and std-dev of auc scores of testing set: {round(np.average(val_eval[0][1]),2)}, \\\n",
    "{round(np.std(val_eval[0][1]),2)} \\n', file=file_hlife_xgb_repeatK)\n",
    "\n",
    "print('\\n', file=file_hlife_xgb_repeatK)\n",
    "coeff_df_xgb = pd.DataFrame(\n",
    "    {'Top features': coeff_xgb_repeatK, 'features': features})\n",
    "print(f\"Coefficients: {coeff_df_xgb} \\n\", file=file_hlife_xgb_repeatK)\n",
    "\n",
    "print(f'Best estimator: {xgb_class_hlife_repeatK.best_estimator_} \\n',\n",
    "      file=file_hlife_xgb_repeatK)\n",
    "print(f'Best params: {xgb_class_hlife_repeatK.best_params_} \\n',\n",
    "      file=file_hlife_xgb_repeatK)\n",
    "print(\n",
    "    f\"Best estimator's score from early stopping: {xgb_class_hlife_repeatK.best_estimator_.best_score} \\n\", file=file_hlife_xgb_repeatK)\n",
    "# plotting roc_auc score\n",
    "fig = plt.figure()\n",
    "fig_ax = fig.add_subplot(1, 1, 1)\n",
    "fig.set_size_inches(12, 8, forward=True)\n",
    "fig_ax.set_xlabel(\"Number of runs\")\n",
    "fig_ax.set_ylabel(\"Cross-validation ROC-AUC score\")\n",
    "fig_ax.set_ylim(0, 1.1)\n",
    "plt.title('XGBoost (Repeated KFold) hbond lifetime',\n",
    "          fontsize=12, weight='bold')\n",
    "\n",
    "fig_ax.plot(range(1, len(train_eval[0][1])+1), train_eval[0][1], '-o', linewidth=2, markersize=8.0, label=f\"avg training roc_auc: {round(np.average(train_eval[0][1]),2)}\\n \\\n",
    "std training roc_auc : {round(np.std(train_eval[0][1]),2)}\")\n",
    "\n",
    "fig_ax.plot(range(1, len(val_eval[0][1])+1), val_eval[0][1], '-o', linewidth=2, markersize=8.0, label=f\"avg testing roc_auc: {round(np.average(val_eval[0][1]),2)}\\n \\\n",
    "std testing roc_auc : {round(np.std(val_eval[0][1]),2)}\")\n",
    "\n",
    "plt.legend(loc='best')\n",
    "file_hlife_xgb_repeatK.close()\n",
    "dirmaker(f'./plots/roc-auc/hlife/{xdate}')\n",
    "fig.savefig(f'plots/roc-auc/hlife/{xdate}/XGB_hlife_{n_repeat}repeatK-{xdate}_{rand_seed}.png',\n",
    "            dpi=500, facecolor='white', bbox_inches='tight')\n",
    "\n",
    "xgb.plot_importance(\n",
    "    xgb_class_hlife_repeatK.best_estimator_).set_yticklabels(features)\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost with Repeated stratified KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "import multiprocessing\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold, RepeatedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"xtick.labelsize\": 16,\n",
    "    \"ytick.labelsize\": 16,\n",
    "    'font.size': 18,\n",
    "    'axes.labelweight': 'bold',\n",
    "    'figure.dpi': 150.0,\n",
    "})  # 'figure.figsize': [14.0, 10.0],\n",
    "\n",
    "\n",
    "print(\"Parallel Parameter optimization\")\n",
    "xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "xgb_roc_auc_stratK = []\n",
    "coeff_xgb_stratK = [0, 0, 0, 0, 0]\n",
    "rand_seed = 1000\n",
    "n_repeat = 10\n",
    "cv = RepeatedStratifiedKFold(\n",
    "    n_splits=10, n_repeats=n_repeat, random_state=rand_seed)\n",
    "\n",
    "dirmaker(f'./model-logs/hlife/{xdate}')\n",
    "file_hlife_xgb_stratK = open(\n",
    "    f\"./model-logs/hlife/{xdate}/XGB_hlife_{n_repeat}stratKFold_{xdate}_{rand_seed}.txt\", \"w+\")\n",
    "\n",
    "xgb_class_hlifestratK = XGBClassifier(\n",
    "    tree_method='hist',\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='auc',\n",
    "    objective='binary:logistic',\n",
    "    n_jobs=-1)  # tree_method='gpu_hist', enable_categorical=True, predictor='gpu_predictor',\n",
    "\n",
    "p_stratK = {'max_depth': [2, 4, 6, 8, 10],\n",
    "            'n_estimators': [10, 20, 30, 40, 50, 100],\n",
    "            'learning_rate': [0.01, 0.1],\n",
    "            # ,0.6,0.7,0.8,0.9,1.0\n",
    "            'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "            }\n",
    "\n",
    "\n",
    "X_train_hlife, y_train_hlife, X_test_hlife, y_test_hlife = data_generator(\n",
    "    des_df_hlife, nondes_df_hlife, test_sample_size=8, nondes_batch_size=38)\n",
    "\n",
    "xgb_clf = GridSearchCV(xgb_class_hlifestratK,\n",
    "                       param_grid=p_stratK, verbose=1, scoring='roc_auc', cv=cv)\n",
    "\n",
    "xgb_class_hlife_stratK = xgb_clf.fit(X_train_hlife, y_train_hlife, eval_set=[(X_train_hlife, y_train_hlife), (\n",
    "    X_test_hlife, y_test_hlife)], verbose=False, early_stopping_rounds=50)  # , early_stopping_rounds=50\n",
    "\n",
    "print('Best score', xgb_class_hlife_stratK.best_score_, file=file_hlife_xgb_stratK)\n",
    "print('Best params', xgb_class_hlife_stratK.best_params_,\n",
    "      file=file_hlife_xgb_stratK)\n",
    "y_pred_hlife_xgb = xgb_class_hlife_stratK.best_estimator_.predict(X_test_hlife)\n",
    "target_names = ['non-DES', 'DES']  # non-DES is 0, DES is 1\n",
    "print(metrics.classification_report(y_test_hlife, y_pred_hlife_xgb,\n",
    "      target_names=target_names), file=file_hlife_xgb_stratK)\n",
    "roc_auc_xgb = metrics.roc_auc_score(y_test_hlife, y_pred_hlife_xgb)\n",
    "print(f\"roc_auc_score: {roc_auc_xgb}\", file=file_hlife_xgb_stratK)\n",
    "xgb_roc_auc_stratK.append(roc_auc_xgb)\n",
    "print(xgb_class_hlife_stratK.best_estimator_.feature_importances_,\n",
    "      file=file_hlife_xgb_stratK)\n",
    "# print(f\"intercept: {xgb_class_hlife_stratK.intercept_}\", file=file_hlife_xgb_stratK)\n",
    "\n",
    "xgb_class_hlife_stratK_feature_df = pd.DataFrame(\n",
    "    {'Importance': xgb_class_hlife_stratK.best_estimator_.feature_importances_, 'features': features})\n",
    "max_coeff_index = list(xgb_class_hlife_stratK.best_estimator_.feature_importances_).index(\n",
    "    xgb_class_hlife_stratK.best_estimator_.feature_importances_.max())\n",
    "print(\n",
    "    f'max feature: {xgb_class_hlife_stratK.best_estimator_.feature_importances_.max()} at index {max_coeff_index} [{features[max_coeff_index]}]', file=file_hlife_xgb_stratK)\n",
    "coeff_xgb_stratK[max_coeff_index] += 1\n",
    "print('\\n', file=file_hlife_xgb_stratK)\n",
    "print(xgb_class_hlife_stratK_feature_df, file=file_hlife_xgb_stratK)\n",
    "print('\\n'*2, file=file_hlife_xgb_stratK)\n",
    "\n",
    "# roc = [ z for z in range(1,num+1)]\n",
    "print(\n",
    "    f\"roc_auc scores on test set: {xgb_roc_auc_stratK}\", file=file_hlife_xgb_stratK)\n",
    "print(\n",
    "    f\"Average roc_auc scores on test set: {np.average(xgb_roc_auc_stratK)}\", file=file_hlife_xgb_stratK)\n",
    "print(\n",
    "    f\"std dev of roc_auc scores on test set: {np.std(xgb_roc_auc_stratK)}\", file=file_hlife_xgb_stratK)\n",
    "print(\n",
    "    f\"Best roc_auc score on test set: {max(xgb_roc_auc_stratK)} at index {xgb_roc_auc_stratK.index(max(xgb_roc_auc_stratK)) + 1}\", file=file_hlife_xgb_stratK)\n",
    "print(\n",
    "    f\"Best model's roc_auc score from early stopping: {xgb_class_hlife_stratK.best_estimator_.best_score}\", file=file_hlife_xgb_stratK)\n",
    "print(\n",
    "    f\"Best model's iteration from early stopping: {xgb_class_hlife_stratK.best_estimator_.best_iteration}\", file=file_hlife_xgb_stratK)\n",
    "# print(f\"model's eval_results: {xgb_class_hlife_stratK.best_estimator_.evals_result()}\", file=file_hlife_xgb_stratK)\n",
    "train_eval = list(xgb_class_hlife_stratK.best_estimator_.evals_result()[\n",
    "                  'validation_0'].items())\n",
    "print(\n",
    "    f'Number of training auc scores: {len(train_eval[0][1])}', file=file_hlife_xgb_stratK)\n",
    "print(\n",
    "    f'auc scores of training set: {train_eval[0][1]}', file=file_hlife_xgb_stratK)\n",
    "print(f'Average and std-dev of auc scores of training set: {round(np.average(train_eval[0][1]),2)}, \\\n",
    "{round(np.std(train_eval[0][1]),2)} \\n', file=file_hlife_xgb_stratK)\n",
    "\n",
    "val_eval = list(xgb_class_hlife_stratK.best_estimator_.evals_result()[\n",
    "                'validation_1'].items())\n",
    "print(\n",
    "    f'Number of testing auc scores: {len(val_eval[0][1])}', file=file_hlife_xgb_stratK)\n",
    "print(\n",
    "    f'auc scores of testing set: {val_eval[0][1]}', file=file_hlife_xgb_stratK)\n",
    "print(f'Average and std-dev of auc scores of testing set: {round(np.average(val_eval[0][1]),2)}, \\\n",
    "{round(np.std(val_eval[0][1]),2)} \\n', file=file_hlife_xgb_stratK)\n",
    "\n",
    "print('\\n', file=file_hlife_xgb_stratK)\n",
    "coeff_df_xgb = pd.DataFrame(\n",
    "    {'Top features': coeff_xgb_stratK, 'features': features})\n",
    "print(f\"Coefficients: {coeff_df_xgb} \\n\", file=file_hlife_xgb_stratK)\n",
    "\n",
    "print(f'Best estimator: {xgb_class_hlife_stratK.best_estimator_} \\n',\n",
    "      file=file_hlife_xgb_stratK)\n",
    "print(f'Best params: {xgb_class_hlife_stratK.best_params_} \\n',\n",
    "      file=file_hlife_xgb_stratK)\n",
    "print(\n",
    "    f\"Best estimator's score from early stopping: {xgb_class_hlife_stratK.best_estimator_.best_score} \\n\", file=file_hlife_xgb_stratK)\n",
    "# plotting roc_auc score\n",
    "fig = plt.figure()\n",
    "fig_ax = fig.add_subplot(1, 1, 1)\n",
    "fig.set_size_inches(12, 8, forward=True)\n",
    "fig_ax.set_xlabel(\"Number of runs\")\n",
    "fig_ax.set_ylabel(\"Cross-validation ROC-AUC score\")\n",
    "fig_ax.set_ylim(0, 1.1)\n",
    "plt.title('XGBoost (Repeated stratified KFold) hbond lifetime',\n",
    "          fontsize=12, weight='bold')\n",
    "\n",
    "fig_ax.plot(range(1, len(train_eval[0][1])+1), train_eval[0][1], '-o', linewidth=2, markersize=8.0, label=f\"avg training roc_auc: {round(np.average(train_eval[0][1]),2)}\\n \\\n",
    "std training roc_auc : {round(np.std(train_eval[0][1]),2)}\")\n",
    "\n",
    "fig_ax.plot(range(1, len(val_eval[0][1])+1), val_eval[0][1], '-o', linewidth=2, markersize=8.0, label=f\"avg testing roc_auc: {round(np.average(val_eval[0][1]),2)}\\n \\\n",
    "std testing roc_auc : {round(np.std(val_eval[0][1]),2)}\")\n",
    "\n",
    "plt.legend(loc='best')\n",
    "file_hlife_xgb_stratK.close()\n",
    "dirmaker(f'./plots/roc-auc/hlife/{xdate}')\n",
    "fig.savefig(f'plots/roc-auc/hlife/{xdate}/XGB_hlife_{n_repeat}stratKsearch-{xdate}_{rand_seed}.png',\n",
    "            dpi=500, facecolor='white', bbox_inches='tight')\n",
    "\n",
    "xgb.plot_importance(\n",
    "    xgb_class_hlife_stratK.best_estimator_).set_yticklabels(features)\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nested and non-Nested CVs\n",
    "Generates X_train and y_train that can then be split into train/test by the model.\n",
    "Useful for CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold\n",
    "import numpy as np\n",
    "\n",
    "# Number of random trials\n",
    "NUM_TRIALS = 30\n",
    "\n",
    "# Load the dataset\n",
    "X_train, y_train = data_crossval(des_df_hlife, nondes_df_hlife, batch_size=38)\n",
    "\n",
    "# Set up possible values of parameters to optimize over\n",
    "p_grid = {\"C\": [1, 10, 100, 1000], \"gamma\": [0.0001, 0.001, 0.01, 0.1]}\n",
    "# p_grid = {\"C\": [1, 10, 100, 1000]}\n",
    "\n",
    "# p_grid = [\n",
    "#   {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "#   {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n",
    "#  ]\n",
    "\n",
    "# We will use a Support Vector Classifier with \"rbf\" kernel\n",
    "svm = SVC(kernel=\"rbf\")\n",
    "# svm = SVC(kernel=\"linear\")\n",
    "# svm = SVC()\n",
    "\n",
    "# Arrays to store scores\n",
    "non_nested_scores = np.zeros(NUM_TRIALS)\n",
    "nested_scores = np.zeros(NUM_TRIALS)\n",
    "\n",
    "# Loop for each trial\n",
    "for i in range(NUM_TRIALS):\n",
    "\n",
    "    # Choose cross-validation techniques for the inner and outer loops,\n",
    "    # independently of the dataset.\n",
    "    # E.g \"GroupKFold\", \"LeaveOneOut\", \"LeaveOneGroupOut\", etc.\n",
    "    inner_cv = KFold(n_splits=4, shuffle=True, random_state=i)\n",
    "    outer_cv = KFold(n_splits=4, shuffle=True, random_state=i)\n",
    "\n",
    "    # Non_nested parameter search and scoring\n",
    "    clf = GridSearchCV(estimator=svm, param_grid=p_grid, cv=outer_cv)\n",
    "    clf.fit(X_train, y_train)\n",
    "    non_nested_scores[i] = clf.best_score_\n",
    "\n",
    "    # Nested CV with parameter optimization\n",
    "    clf = GridSearchCV(estimator=svm, param_grid=p_grid, cv=inner_cv)\n",
    "    nested_score = cross_val_score(clf, X=X_train, y=y_train, cv=outer_cv, scoring=\"roc_auc\")\n",
    "    nested_scores[i] = nested_score.mean()\n",
    "\n",
    "score_difference = non_nested_scores - nested_scores\n",
    "\n",
    "print(\n",
    "    \"Average difference of {:6f} with std. dev. of {:6f}.\".format(\n",
    "        score_difference.mean(), score_difference.std()\n",
    "    )\n",
    ")\n",
    "\n",
    "# Plot scores on each trial for nested and non-nested CV\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(211)\n",
    "(non_nested_scores_line,) = plt.plot(non_nested_scores, color=\"r\")\n",
    "(nested_line,) = plt.plot(nested_scores, color=\"b\")\n",
    "plt.ylabel(\"score\", fontsize=\"14\")\n",
    "plt.legend(\n",
    "    [non_nested_scores_line, nested_line],\n",
    "    [\"Non-Nested CV\", \"Nested CV\"],\n",
    "    bbox_to_anchor=(0, 0.4, 0.5, 0),\n",
    ")\n",
    "plt.title(\n",
    "    \"Non-Nested and Nested Cross Validation on Iris Dataset\",\n",
    "    x=0.5,\n",
    "    y=1.1,\n",
    "    fontsize=\"15\",\n",
    ")\n",
    "\n",
    "# Plot bar chart of the difference.\n",
    "plt.subplot(212)\n",
    "difference_plot = plt.bar(range(NUM_TRIALS), score_difference)\n",
    "plt.xlabel(\"Individual Trial #\")\n",
    "plt.legend(\n",
    "    [difference_plot],\n",
    "    [\"Non-Nested CV - Nested CV score\"],\n",
    "    bbox_to_anchor=(0, 1, 0.8, 0),\n",
    ")\n",
    "plt.ylabel(\"score difference\", fontsize=\"14\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "import multiprocessing\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedKFold, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"xtick.labelsize\": 14,\n",
    "    \"ytick.labelsize\": 14,\n",
    "    'font.size': 18,\n",
    "    'axes.labelweight': 'bold',\n",
    "    'figure.dpi': 150.0,\n",
    "})  # 'figure.figsize': [14.0, 10.0],\n",
    "\n",
    "\n",
    "print(\"Parallel Parameter optimization\")\n",
    "xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "xgb_roc_auc_repeatK_nestedCV = []\n",
    "coeff_xgb_repeatK_nestedCV = [0, 0, 0, 0, 0]\n",
    "rand_seed = 100\n",
    "n_repeat = 10\n",
    "inner_cv = RepeatedKFold(n_splits=3, n_repeats=n_repeat, random_state=rand_seed)\n",
    "outer_cv = RepeatedKFold(n_splits=4, n_repeats=n_repeat, random_state=rand_seed)\n",
    "\n",
    "dirmaker(f'./model-logs/hlife/{xdate}')\n",
    "file_hlife_xgb_repeatK_nestedCV = open(\n",
    "    f\"./model-logs/hlife/{xdate}/XGB_hlife_{n_repeat}repeatK_nestedCV_{xdate}_{rand_seed}.txt\", \"w+\")\n",
    "\n",
    "xgb_class_hliferepeatK_nestedCV = XGBClassifier(\n",
    "    tree_method='hist',\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='auc',\n",
    "    objective='binary:logistic',\n",
    "    n_jobs=-1) \n",
    "\n",
    "p_repeatK_nestedCV = {'max_depth': [2, 4, 6, 8, 10],\n",
    "             'n_estimators': [10, 20, 30, 40, 50, 100],\n",
    "             'learning_rate': [0.01, 0.1],\n",
    "             'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "             }\n",
    "\n",
    "\n",
    "X_train_hlife, y_train_hlife, X_test_hlife, y_test_hlife = data_generator(\n",
    "    des_df_hlife, nondes_df_hlife, test_sample_size=8, nondes_batch_size=38)\n",
    "\n",
    "xgb_clf = GridSearchCV(xgb_class_hliferepeatK_nestedCV,\n",
    "                       param_grid=p_repeatK_nestedCV, verbose=1, scoring='roc_auc', cv=inner_cv, refit=True)\n",
    "\n",
    "xgb_class_hlife_repeatK_nestedCV = cross_val_score(xgb_clf, X_train_hlife, y_train_hlife, scoring='roc_auc', cv=outer_cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(xgb_class_hlife_repeatK_nestedCV), np.std(xgb_class_hlife_repeatK_nestedCV)))\n",
    "\n",
    "print('Best score', xgb_class_hlife_repeatK_nestedCV.best_score_,\n",
    "      file=file_hlife_xgb_repeatK_nestedCV)\n",
    "print('Best params', xgb_class_hlife_repeatK_nestedCV.best_params_,\n",
    "      file=file_hlife_xgb_repeatK_nestedCV)\n",
    "y_pred_hlife_xgb = xgb_class_hlife_repeatK_nestedCV.best_estimator_.predict(\n",
    "    X_test_hlife)\n",
    "target_names = ['non-DES', 'DES']  # non-DES is 0, DES is 1\n",
    "print(metrics.classification_report(y_test_hlife, y_pred_hlife_xgb,\n",
    "      target_names=target_names), file=file_hlife_xgb_repeatK_nestedCV)\n",
    "roc_auc_xgb = metrics.roc_auc_score(y_test_hlife, y_pred_hlife_xgb)\n",
    "print(f\"roc_auc_score: {roc_auc_xgb}\", file=file_hlife_xgb_repeatK_nestedCV)\n",
    "xgb_roc_auc_repeatK_nestedCV.append(roc_auc_xgb)\n",
    "print(xgb_class_hlife_repeatK_nestedCV.best_estimator_.feature_importances_,\n",
    "      file=file_hlife_xgb_repeatK_nestedCV)\n",
    "# print(f\"intercept: {xgb_class_hlife_repeatK_nestedCV.intercept_}\", file=file_hlife_xgb_repeatK_nestedCV)\n",
    "\n",
    "xgb_class_hlife_repeatK_nestedCV_feature_df = pd.DataFrame(\n",
    "    {'Importance': xgb_class_hlife_repeatK_nestedCV.best_estimator_.feature_importances_, 'features': features})\n",
    "max_coeff_index = list(xgb_class_hlife_repeatK_nestedCV.best_estimator_.feature_importances_).index(\n",
    "    xgb_class_hlife_repeatK_nestedCV.best_estimator_.feature_importances_.max())\n",
    "print(\n",
    "    f'max feature: {xgb_class_hlife_repeatK_nestedCV.best_estimator_.feature_importances_.max()} at index {max_coeff_index} [{features[max_coeff_index]}]', file=file_hlife_xgb_repeatK_nestedCV)\n",
    "coeff_xgb_repeatK_nestedCV[max_coeff_index] += 1\n",
    "print('\\n', file=file_hlife_xgb_repeatK_nestedCV)\n",
    "print(xgb_class_hlife_repeatK_nestedCV_feature_df, file=file_hlife_xgb_repeatK_nestedCV)\n",
    "print('\\n'*2, file=file_hlife_xgb_repeatK_nestedCV)\n",
    "\n",
    "# roc = [ z for z in range(1,num+1)]\n",
    "print(\n",
    "    f\"roc_auc scores on test set: {xgb_roc_auc_repeatK_nestedCV}\", file=file_hlife_xgb_repeatK_nestedCV)\n",
    "print(\n",
    "    f\"Average roc_auc scores on test set: {np.average(xgb_roc_auc_repeatK_nestedCV)}\", file=file_hlife_xgb_repeatK_nestedCV)\n",
    "print(\n",
    "    f\"std dev of roc_auc scores on test set: {np.std(xgb_roc_auc_repeatK_nestedCV)}\", file=file_hlife_xgb_repeatK_nestedCV)\n",
    "print(\n",
    "    f\"Best roc_auc score on test set: {max(xgb_roc_auc_repeatK_nestedCV)} at index {xgb_roc_auc_repeatK_nestedCV.index(max(xgb_roc_auc_repeatK_nestedCV)) + 1}\", file=file_hlife_xgb_repeatK_nestedCV)\n",
    "print(\n",
    "    f\"Best model's roc_auc score from early stopping: {xgb_class_hlife_repeatK_nestedCV.best_estimator_.best_score}\", file=file_hlife_xgb_repeatK_nestedCV)\n",
    "print(\n",
    "    f\"Best model's iteration from early stopping: {xgb_class_hlife_repeatK_nestedCV.best_estimator_.best_iteration}\", file=file_hlife_xgb_repeatK_nestedCV)\n",
    "# print(f\"model's eval_results: {xgb_class_hlife_repeatK_nestedCV.best_estimator_.evals_result()}\", file=file_hlife_xgb_repeatK_nestedCV)\n",
    "train_eval = list(xgb_class_hlife_repeatK_nestedCV.best_estimator_.evals_result()[\n",
    "                  'validation_0'].items())\n",
    "print(\n",
    "    f'Number of training auc scores: {len(train_eval[0][1])}', file=file_hlife_xgb_repeatK_nestedCV)\n",
    "print(\n",
    "    f'auc scores of training set: {train_eval[0][1]}', file=file_hlife_xgb_repeatK_nestedCV)\n",
    "print(f'Average and std-dev of auc scores of training set: {round(np.average(train_eval[0][1]),2)}, \\\n",
    "{round(np.std(train_eval[0][1]),2)} \\n', file=file_hlife_xgb_repeatK_nestedCV)\n",
    "\n",
    "val_eval = list(xgb_class_hlife_repeatK_nestedCV.best_estimator_.evals_result()[\n",
    "                'validation_1'].items())\n",
    "print(\n",
    "    f'Number of testing auc scores: {len(val_eval[0][1])}', file=file_hlife_xgb_repeatK_nestedCV)\n",
    "print(\n",
    "    f'auc scores of testing set: {val_eval[0][1]}', file=file_hlife_xgb_repeatK_nestedCV)\n",
    "print(f'Average and std-dev of auc scores of testing set: {round(np.average(val_eval[0][1]),2)}, \\\n",
    "{round(np.std(val_eval[0][1]),2)} \\n', file=file_hlife_xgb_repeatK_nestedCV)\n",
    "\n",
    "print('\\n', file=file_hlife_xgb_repeatK_nestedCV)\n",
    "coeff_df_xgb = pd.DataFrame(\n",
    "    {'Top features': coeff_xgb_repeatK_nestedCV, 'features': features})\n",
    "print(f\"Coefficients: {coeff_df_xgb} \\n\", file=file_hlife_xgb_repeatK_nestedCV)\n",
    "\n",
    "print(f'Best estimator: {xgb_class_hlife_repeatK_nestedCV.best_estimator_} \\n',\n",
    "      file=file_hlife_xgb_repeatK_nestedCV)\n",
    "print(f'Best params: {xgb_class_hlife_repeatK_nestedCV.best_params_} \\n',\n",
    "      file=file_hlife_xgb_repeatK_nestedCV)\n",
    "print(\n",
    "    f\"Best estimator's score from early stopping: {xgb_class_hlife_repeatK_nestedCV.best_estimator_.best_score} \\n\", file=file_hlife_xgb_repeatK_nestedCV)\n",
    "# plotting roc_auc score\n",
    "fig = plt.figure()\n",
    "fig_ax = fig.add_subplot(1, 1, 1)\n",
    "fig.set_size_inches(12, 8, forward=True)\n",
    "fig_ax.set_xlabel(\"Number of runs\")\n",
    "fig_ax.set_ylabel(\"Cross-validation ROC-AUC score\")\n",
    "fig_ax.set_ylim(0, 1.1)\n",
    "plt.title('XGBoost (Repeated KFold) hbond lifetime',\n",
    "          fontsize=12, weight='bold')\n",
    "\n",
    "fig_ax.plot(range(1, len(train_eval[0][1])+1), train_eval[0][1], '-o', linewidth=2, markersize=8.0, label=f\"avg training roc_auc: {round(np.average(train_eval[0][1]),2)}\\n \\\n",
    "std training roc_auc : {round(np.std(train_eval[0][1]),2)}\")\n",
    "\n",
    "fig_ax.plot(range(1, len(val_eval[0][1])+1), val_eval[0][1], '-o', linewidth=2, markersize=8.0, label=f\"avg testing roc_auc: {round(np.average(val_eval[0][1]),2)}\\n \\\n",
    "std testing roc_auc : {round(np.std(val_eval[0][1]),2)}\")\n",
    "\n",
    "plt.legend(loc='best')\n",
    "file_hlife_xgb_repeatK_nestedCV.close()\n",
    "dirmaker(f'./plots/roc-auc/hlife/{xdate}')\n",
    "fig.savefig(f'plots/roc-auc/hlife/{xdate}/XGB_hlife_{n_repeat}repeatK_nestedCV-{xdate}_{rand_seed}.png',\n",
    "            dpi=500, facecolor='white', bbox_inches='tight')\n",
    "\n",
    "xgb.plot_importance(\n",
    "    xgb_class_hlife_repeatK_nestedCV.best_estimator_).set_yticklabels(features)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf.best_estimator_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hnumber only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### non-des hnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nondes_df_hnum = nondes_hnum.drop(columns=['DES'])  # should change this to non-DES\n",
    "nondes_df_hnum['output'] = 0\n",
    "# nondes_df_hnum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### des hnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "des_df_hnum = des_hnum.drop(columns=['DES'])  # should change this to DES\n",
    "des_df_hnum['output'] = 1\n",
    "# des_df_hnum"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter optimization\n",
    "Using gridsearch cv to find the best model params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generic GridSearch funtion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.rcParams.update({\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"xtick.labelsize\": 14,\n",
    "    \"ytick.labelsize\": 14,\n",
    "    'font.size': 18,\n",
    "    'axes.labelweight': 'bold',\n",
    "    'figure.dpi': 300.0,\n",
    "    'axes.linewidth':2.0,\n",
    "})\n",
    "\n",
    "models = {\n",
    "     \"XGB\": XGBClassifier(\n",
    "            tree_method='hist',\n",
    "            eval_metric='auc',\n",
    "            objective='binary:logistic',\n",
    "            n_jobs=multiprocessing.cpu_count(), early_stopping_rounds=50)\n",
    "}\n",
    "\n",
    "params = { 'XGB':{'max_depth': [2, 4, 6, 8, 10],\n",
    "             'n_estimators': [10, 20, 30, 40, 50, 100],\n",
    "             'learning_rate': [0.01, 0.1],\n",
    "             'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "             }\n",
    "}\n",
    "\n",
    "print(\"Parallel Parameter optimization\")\n",
    "xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "rand_seed = 100\n",
    "n_repeat = 10\n",
    "cv = RepeatedKFold(n_splits=6, n_repeats=n_repeat, random_state=rand_seed)\n",
    "tag = \"XGB\"\n",
    "print(f\"{tag} Parallel Parameter optimization\")\n",
    "\n",
    "model_generic = models[tag]  \n",
    "p_repeatK = params[tag]\n",
    "model_name = model_generic.__str__().split('(')[0]\n",
    "folder_type = 'hnum'\n",
    "\n",
    "dirmaker(f'./model-logs/gridsearch/{folder_type}/{xdate}')\n",
    "file_hnum_xgb_repeatK = open(\n",
    "    f\"./model-logs/gridsearch/{folder_type}/{xdate}/{model_name}_{folder_type}_{n_repeat}_{xdate}_{rand_seed}.txt\", \"w+\")\n",
    "\n",
    "\n",
    "kingmaker_xgb(model_generic, p_repeatK, des_df_hnum, nondes_df_hnum, cv=cv,\n",
    "           file_name=file_hnum_xgb_repeatK, folder_type=folder_type, n_repeat=n_repeat, rand_seed=rand_seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBRF\n",
    "plt.rcParams.update({\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"xtick.labelsize\": 14,\n",
    "    \"ytick.labelsize\": 14,\n",
    "    'font.size': 18,\n",
    "    'axes.labelweight': 'bold',\n",
    "    'figure.dpi': 300.0,\n",
    "    'axes.linewidth':2.0,\n",
    "})\n",
    "\n",
    "models = {\n",
    "    \"XGBRF\": XGBRFClassifier(\n",
    "            tree_method='hist',\n",
    "            eval_metric='auc',\n",
    "            objective='binary:logistic',\n",
    "            n_jobs=multiprocessing.cpu_count())  \n",
    "}\n",
    "\n",
    "params = {\n",
    "           'XGBRF':{'max_depth': [2, 4, 6, 8, 10],\n",
    "             'n_estimators': [10, 20, 30, 40, 50, 100],\n",
    "             'learning_rate': [0.01, 0.1],\n",
    "             'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "             }\n",
    "}\n",
    "\n",
    "print(\"Parallel Parameter optimization\")\n",
    "xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "rand_seed = 100\n",
    "n_repeat = 10\n",
    "cv = RepeatedKFold(n_splits=6, n_repeats=n_repeat, random_state=rand_seed)\n",
    "tag = \"XGBRF\"\n",
    "print(f\"{tag} Parallel Parameter optimization\")\n",
    "\n",
    "model_generic = models[tag]  \n",
    "p_repeatK = params[tag]\n",
    "model_name = model_generic.__str__().split('(')[0]\n",
    "print(model_name)\n",
    "folder_type = 'hnum'\n",
    "\n",
    "dirmaker(f'./model-logs/gridsearch/{folder_type}/{xdate}')\n",
    "file_hnum_xgb_repeatK = open(\n",
    "    f\"./model-logs/gridsearch/{folder_type}/{xdate}/{model_name}_{folder_type}_{n_repeat}_{xdate}_{rand_seed}.txt\", \"w+\")\n",
    "\n",
    "\n",
    "kingmaker_xgbrf(model_generic, p_repeatK, des_df_hnum, nondes_df_hnum, cv=cv, features=features,\n",
    "           file_name=file_hnum_xgb_repeatK, folder_type=folder_type, n_repeat=n_repeat, rand_seed=rand_seed)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LR\n",
    "plt.rcParams.update({\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"xtick.labelsize\": 14,\n",
    "    \"ytick.labelsize\": 14,\n",
    "    'font.size': 18,\n",
    "    'axes.labelweight': 'bold',\n",
    "    'figure.dpi': 150.0,\n",
    "})\n",
    "\n",
    "models = {\n",
    "    \"LR\": LogisticRegression()\n",
    "}\n",
    "\n",
    "params = {\n",
    "    \"LR\": {'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "            'tol': [1e-4, 1e-6],\n",
    "             'max_iter': [100, 200, 300, 400, 500],\n",
    "             'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "             }\n",
    "}\n",
    "\n",
    "\n",
    "xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "rand_seed = 100\n",
    "n_repeat = 10\n",
    "cv = RepeatedKFold(n_splits=6, n_repeats=n_repeat, random_state=rand_seed)\n",
    "tag = \"LR\"\n",
    "print(f\"{tag} Parallel Parameter optimization\")\n",
    "\n",
    "model_generic = models[tag]  \n",
    "p_repeatK = params[tag]\n",
    "model_name = model_generic.__str__().strip('()')\n",
    "folder_type = 'hnum'\n",
    "\n",
    "dirmaker(f'./model-logs/gridsearch/{folder_type}/{xdate}')\n",
    "file_name = open(\n",
    "    f\"./model-logs/gridsearch/{folder_type}/{xdate}/{model_name}_{folder_type}_{n_repeat}_{xdate}_{rand_seed}.txt\", \"w+\")\n",
    "\n",
    "kingmaker_lr(model_generic, p_repeatK, des_df_hnum, nondes_df_hnum, cv=cv,\n",
    "           file_name=file_name, folder_type=folder_type, n_repeat=n_repeat, rand_seed=rand_seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.rcParams.update({\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"xtick.labelsize\": 14,\n",
    "    \"ytick.labelsize\": 14,\n",
    "    'font.size': 18,\n",
    "    'axes.labelweight': 'bold',\n",
    "    'figure.dpi': 150.0,\n",
    "})\n",
    "\n",
    "models = {\n",
    "    \"RF\": RandomForestClassifier(),\n",
    "    \"EF\": ExtraTreesClassifier(),\n",
    "    \"GB\": GradientBoostingClassifier(),\n",
    "    \"AB\": AdaBoostClassifier(),\n",
    "    \"DT\": DecisionTreeClassifier()\n",
    "}\n",
    "\n",
    "params = {\n",
    "    \"RF\": {'max_depth': [2, 4, 6, 8, 10],\n",
    "             'n_estimators': [10, 20, 30, 40, 50, 100],\n",
    "             'min_samples_leaf': [1, 2, 3],\n",
    "            'min_samples_split': [2,4,6],\n",
    "             'max_features': [\"sqrt\", \"log2\"],\n",
    "             },\n",
    "    \"EF\": {'max_depth': [2, 4, 6, 8, 10],\n",
    "             'n_estimators': [10, 20, 30, 40, 50, 100],\n",
    "             'min_samples_leaf': [1, 2, 3],\n",
    "            'min_samples_split': [2,4,6],\n",
    "             'max_features': [\"sqrt\", \"log2\"],\n",
    "             },\n",
    "    \"GB\": {'max_depth': [2, 4, 6, 8, 10],\n",
    "             'n_estimators': [10, 20, 30, 40, 50, 100],\n",
    "             'min_samples_leaf': [1, 2, 3],\n",
    "            'min_samples_split': [2,4,6],\n",
    "             'max_features': [\"sqrt\", \"log2\"],\n",
    "             'learning_rate': [0.01, 0.1],\n",
    "             },\n",
    "    \"AB\": {'n_estimators': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "             'learning_rate': [0.001, 0.01, 0.1, 1.0],\n",
    "             },\n",
    "    \"DT\": {'max_depth': [2, 4, 6, 8, 10],\n",
    "             'min_samples_leaf': [1, 2, 3],\n",
    "            'min_samples_split': [2,4,6],\n",
    "             'max_features': [ \"sqrt\", \"log2\"],\n",
    "             }\n",
    "}\n",
    "\n",
    "\n",
    "xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "rand_seed = 100\n",
    "n_repeat = 10\n",
    "# cv = RepeatedKFold(n_splits=6, n_repeats=n_repeat, random_state=rand_seed)\n",
    "\n",
    "for x in models.keys():\n",
    "    cv = RepeatedKFold(n_splits=6, n_repeats=n_repeat, random_state=rand_seed)\n",
    "\n",
    "    tag = x\n",
    "    print(f\"{tag} Parallel Parameter optimization\")\n",
    "\n",
    "    model_generic = models[tag]  \n",
    "    p_repeatK = params[tag]\n",
    "    model_name = model_generic.__str__().strip('()')\n",
    "    folder_type = 'hnum'\n",
    "\n",
    "    if model_name.__contains__(\"XGBClassifier\"):\n",
    "        model_name = \"XGBClassifier\"\n",
    "\n",
    "\n",
    "    dirmaker(f'./model-logs/gridsearch/{folder_type}/{xdate}')\n",
    "    file_name = open(\n",
    "        f\"./model-logs/gridsearch/{folder_type}/{xdate}/{model_name}_{folder_type}_{n_repeat}_{xdate}_{rand_seed}.txt\", \"w+\")\n",
    "\n",
    "    kingmaker_generic(model_generic, p_repeatK, des_df_hnum, nondes_df_hnum, cv=cv,\n",
    "           file_name=file_name, folder_type=folder_type, n_repeat=n_repeat, rand_seed=rand_seed)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "plt.rcParams.update({\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"xtick.labelsize\": 14,\n",
    "    \"ytick.labelsize\": 14,\n",
    "    'font.size': 18,\n",
    "    'axes.labelweight': 'bold',\n",
    "    'figure.dpi': 150.0,\n",
    "})\n",
    "\n",
    "models = {\n",
    "    \"KNN\": KNeighborsClassifier(n_jobs=-1)\n",
    "}\n",
    "\n",
    "params = {\n",
    "    \"KNN\": {'n_neighbors' : [5,7,9,11,13,15],\n",
    "               'weights' : ['uniform','distance'],\n",
    "               'metric' : ['minkowski','euclidean','manhattan'],\n",
    "               'leaf_size' : [30, 40, 50, 60]\n",
    "               }\n",
    "}\n",
    "\n",
    "\n",
    "xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "rand_seed = 100\n",
    "n_repeat = 10\n",
    "cv = RepeatedKFold(n_splits=6, n_repeats=n_repeat, random_state=rand_seed)\n",
    "tag = \"KNN\"\n",
    "print(f\"{tag} Parallel Parameter optimization\")\n",
    "\n",
    "model_generic = models[tag]  \n",
    "p_repeatK = params[tag]\n",
    "model_name = model_generic.__str__().split('(')[0]\n",
    "folder_type = 'hnum'\n",
    "\n",
    "dirmaker(f'./model-logs/gridsearch/{folder_type}/{xdate}')\n",
    "file_name = open(\n",
    "    f\"./model-logs/gridsearch/{folder_type}/{xdate}/{model_name}_{folder_type}_{n_repeat}_{xdate}_{rand_seed}.txt\", \"w+\")\n",
    "\n",
    "kingmaker_knn(model_generic, p_repeatK, des_df_hnum, nondes_df_hnum, cv=cv,\n",
    "           file_name=file_name, folder_type=folder_type, n_repeat=n_repeat, rand_seed=rand_seed)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC\n",
    "plt.rcParams.update({\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"xtick.labelsize\": 14,\n",
    "    \"ytick.labelsize\": 14,\n",
    "    'font.size': 18,\n",
    "    'axes.labelweight': 'bold',\n",
    "    'figure.dpi': 150.0,\n",
    "})\n",
    "\n",
    "models = {\n",
    "    \"SVC\": SVC(probability=True),\n",
    "    \"SVC1\": SVC(probability=True)\n",
    "}\n",
    "\n",
    "# 'gamma': ['scale', 'auto'],\n",
    "# 'gamma': [0.001, 0.0001],\n",
    "# \"C\": [1, 10, 100, 1000]\n",
    "#             \n",
    "params = {\n",
    "    \"SVC\": { \n",
    "             'degree': [3, 5, 7],\n",
    "             'kernel' : ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "             'tol': [1e-3, 1e-4, 1e-5, 1e-6],\n",
    "             \"C\": [1, 10]\n",
    "             }\n",
    "}\n",
    "\n",
    "\n",
    "xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "rand_seed = 100\n",
    "n_repeat = 10\n",
    "cv = RepeatedKFold(n_splits=6, n_repeats=n_repeat, random_state=rand_seed)\n",
    "tag = \"SVC\"\n",
    "print(f\"{tag} Parallel Parameter optimization\")\n",
    "\n",
    "model_generic = models[tag]  \n",
    "p_repeatK = params[tag]\n",
    "model_name = model_generic.__str__().split('(')[0]\n",
    "folder_type = 'hnum'\n",
    "\n",
    "dirmaker(f'./model-logs/gridsearch/{folder_type}/{xdate}')\n",
    "file_name = open(\n",
    "    f\"./model-logs/gridsearch/{folder_type}/{xdate}/{model_name}_{folder_type}_{n_repeat}_{xdate}_{rand_seed}.txt\", \"w+\")\n",
    "\n",
    "kingmaker_svc(model_generic, p_repeatK, des_df_hnum, nondes_df_hnum, cv=cv,\n",
    "           file_name=file_name, folder_type=folder_type, n_repeat=n_repeat, rand_seed=rand_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC().__str__().strip('()')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loops"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# XGB\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"xtick.labelsize\": 14,\n",
    "    \"ytick.labelsize\": 14,\n",
    "    'font.size': 18,\n",
    "    'axes.labelweight': 'bold',\n",
    "    'figure.dpi': 350.0,\n",
    "    'axes.linewidth':2.0,\n",
    "})\n",
    "\n",
    "models = {    \n",
    "    \"XGB-old\": XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=0.1,\n",
    "              enable_categorical=False, eval_metric='auc', gamma=0, gpu_id=-1,\n",
    "              importance_type=None, interaction_constraints='',\n",
    "              learning_rate=0.1, max_delta_step=0, max_depth=8,\n",
    "              min_child_weight=1, monotone_constraints='()',\n",
    "              n_estimators=100, n_jobs=12, num_parallel_tree=1,\n",
    "              predictor='auto', random_state=0, reg_alpha=0, reg_lambda=1,\n",
    "              scale_pos_weight=1, subsample=1, tree_method='hist',\n",
    "              validate_parameters=1, verbosity=None),\n",
    "    \"XGB\": XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
    "              colsample_bylevel=None, colsample_bynode=None,\n",
    "              colsample_bytree=0.4, \n",
    "              enable_categorical=False, eval_metric='auc', feature_types=None,\n",
    "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
    "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
    "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
    "              max_delta_step=None, max_depth=2, max_leaves=None,\n",
    "              min_child_weight=None, monotone_constraints=None,\n",
    "              n_estimators=50, n_jobs=12, num_parallel_tree=None,\n",
    "              predictor=None, random_state=None)\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "rand_seed = 100\n",
    "n_repeat = 100\n",
    "folder_type='hnum'\n",
    "\n",
    "tag = \"XGB\"\n",
    "model_type = models[tag]\n",
    "model_name = model_type.__str__().split('(')[0]\n",
    "\n",
    "print(f\"{tag} training for {n_repeat} runs\")\n",
    "\n",
    "if model_name.__contains__(\"XGBClassifier\"):\n",
    "    model_name = \"XGBClassifier\"\n",
    "\n",
    "dirmaker(f'./model-logs/training/{folder_type}/{xdate}')\n",
    "file_name = open(\n",
    "    f\"./model-logs/training/{folder_type}/{xdate}/{model_name}_{folder_type}_{n_repeat}_{xdate}_{rand_seed}.txt\", \"w+\")\n",
    "\n",
    "train_xgb(model_type, des_df_hnum, nondes_df_hnum, \n",
    "file_name=file_name, folder_type=folder_type, num=n_repeat, rand_seed=rand_seed, features=features)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# XGBRF\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"xtick.labelsize\": 14,\n",
    "    \"ytick.labelsize\": 14,\n",
    "    'font.size': 18,\n",
    "    'axes.labelweight': 'bold',\n",
    "    'figure.dpi': 350.0,\n",
    "    'axes.linewidth':2.0,\n",
    "})\n",
    "\n",
    "models = {    \n",
    "    \"XGBRF-old\": XGBRFClassifier(base_score=None, booster=None, callbacks=None,\n",
    "                colsample_bylevel=None, colsample_bytree=0.1,\n",
    "                early_stopping_rounds=None, enable_categorical=False,\n",
    "                eval_metric='auc', feature_types=None, gamma=None, gpu_id=None,\n",
    "                grow_policy=None, importance_type=None,\n",
    "                interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
    "                max_cat_threshold=None, max_cat_to_onehot=None,\n",
    "                max_delta_step=None, max_depth=6, max_leaves=None,\n",
    "                min_child_weight=None, monotone_constraints=None,\n",
    "                n_estimators=100, n_jobs=12, num_parallel_tree=None,\n",
    "                objective='binary:logistic', predictor=None, random_state=None),\n",
    "    \"XGBRF\": XGBRFClassifier(base_score=None, booster=None, callbacks=None,\n",
    "                colsample_bylevel=None, colsample_bytree=0.4,\n",
    "                early_stopping_rounds=None, enable_categorical=False,\n",
    "                eval_metric='auc', feature_types=None, gamma=None, gpu_id=None,\n",
    "                grow_policy=None, importance_type=None,\n",
    "                interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
    "                max_cat_threshold=None, max_cat_to_onehot=None,\n",
    "                max_delta_step=None, max_depth=8, max_leaves=None,\n",
    "                min_child_weight=None, monotone_constraints=None,\n",
    "                n_estimators=100, n_jobs=12, num_parallel_tree=None,\n",
    "                objective='binary:logistic', predictor=None, random_state=None)  \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "rand_seed = 100\n",
    "n_repeat = 100\n",
    "folder_type='hnum'\n",
    "\n",
    "tag = \"XGBRF\"\n",
    "model_type = models[tag]\n",
    "model_name = model_type.__str__().split('(')[0]\n",
    "\n",
    "print(f\"{tag} training for {n_repeat} runs\")\n",
    "\n",
    "if model_name.__contains__(\"XGBClassifier\"):\n",
    "    model_name = \"XGBClassifier\"\n",
    "\n",
    "dirmaker(f'./model-logs/training/{folder_type}/{xdate}')\n",
    "file_name = open(\n",
    "    f\"./model-logs/training/{folder_type}/{xdate}/{model_name}_{folder_type}_{n_repeat}_{xdate}_{rand_seed}.txt\", \"w+\")\n",
    "\n",
    "train_xgb(model_type, des_df_hnum, nondes_df_hnum, \n",
    "file_name=file_name, folder_type=folder_type, num=n_repeat, rand_seed=rand_seed, features=features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGB and XGBRF eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBClassifier\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"xtick.labelsize\": 14,\n",
    "    \"ytick.labelsize\": 14,\n",
    "    'font.size': 18,\n",
    "    'axes.labelweight': 'bold',\n",
    "    'figure.dpi': 350.0,\n",
    "    'axes.linewidth':2.0,\n",
    "})\n",
    "\n",
    "models = {    \n",
    "    \"XGB\": XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
    "              colsample_bylevel=None, colsample_bynode=None,\n",
    "              colsample_bytree=0.4, \n",
    "              enable_categorical=False, eval_metric='auc', feature_types=None,\n",
    "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
    "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
    "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
    "              max_delta_step=None, max_depth=2, max_leaves=None,\n",
    "              min_child_weight=None, monotone_constraints=None,\n",
    "              n_estimators=50, n_jobs=12, num_parallel_tree=None,\n",
    "              predictor=None, random_state=None),\n",
    "     \"XGBRF\": XGBRFClassifier(base_score=None, booster=None, callbacks=None,\n",
    "                colsample_bylevel=None, colsample_bytree=0.4,\n",
    "                early_stopping_rounds=None, enable_categorical=False,\n",
    "                eval_metric='auc', feature_types=None, gamma=None, gpu_id=None,\n",
    "                grow_policy=None, importance_type=None,\n",
    "                interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
    "                max_cat_threshold=None, max_cat_to_onehot=None,\n",
    "                max_delta_step=None, max_depth=8, max_leaves=None,\n",
    "                min_child_weight=None, monotone_constraints=None,\n",
    "                n_estimators=100, n_jobs=12, num_parallel_tree=None,\n",
    "                objective='binary:logistic', predictor=None, random_state=None)\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "rand_seed = 100\n",
    "n_repeat = 100\n",
    "folder_type='hnum'\n",
    "\n",
    "tag = \"XGB\"  #\"XGBRF\"\n",
    "model_type = models[tag]\n",
    "model_name = model_type.__str__().split('(')[0]\n",
    "\n",
    "print(f\"{tag} training for {n_repeat} runs\")\n",
    "\n",
    "if model_name.__contains__(\"XGBClassifier\"):\n",
    "    model_name = \"XGBClassifier\"\n",
    "\n",
    "dirmaker(f'./model-logs/training/{folder_type}/{xdate}')\n",
    "file_name = open(\n",
    "    f\"./model-logs/training/{folder_type}/{xdate}/{model_name}_eval_{folder_type}_{n_repeat}_{xdate}_{rand_seed}.txt\", \"w+\")\n",
    "\n",
    "# Use this for getting validation metrics plotted alongside training metrics\n",
    "train_xgb_eval(model_type, des_df_hnum, nondes_df_hnum, \n",
    "file_name=file_name, folder_type=folder_type, num=n_repeat, rand_seed=rand_seed, features=features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"xtick.labelsize\": 14,\n",
    "    \"ytick.labelsize\": 14,\n",
    "    'font.size': 18,\n",
    "    'axes.labelweight': 'bold',\n",
    "    'figure.dpi': 350.0,\n",
    "})\n",
    "\n",
    "\n",
    "models = {\n",
    "    \"LR-old\": LogisticRegression(max_iter=100, penalty='l2', solver='newton-cg', tol=0.0001),\n",
    "    \"LR\": LogisticRegression(solver='newton-cg')\n",
    "}\n",
    "\n",
    "xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "rand_seed = 100\n",
    "n_repeat = 100\n",
    "folder_type='hnum'\n",
    "# cv = RepeatedKFold(n_splits=6, n_repeats=n_repeat, random_state=rand_seed)\n",
    "\n",
    "tag = \"LR\"\n",
    "model_type = models[tag]\n",
    "model_name = model_type.__str__().split('(')[0]\n",
    "print(f\"{tag} training for {n_repeat} runs\")\n",
    "\n",
    "dirmaker(f'./model-logs/training/{folder_type}/{xdate}')\n",
    "file_name = open(\n",
    "    f\"./model-logs/training/{folder_type}/{xdate}/{model_name}_{folder_type}_{n_repeat}_{xdate}_{rand_seed}.txt\", \"w+\")\n",
    "\n",
    "\n",
    "train_lr(model_type, des_df_hnum, nondes_df_hnum, \n",
    "file_name=file_name, folder_type=folder_type, num=n_repeat, rand_seed=rand_seed, features=features, model_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AB, DT, EF, GB, RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AB, DT, EF, GB, RF\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"xtick.labelsize\": 14,\n",
    "    \"ytick.labelsize\": 14,\n",
    "    'font.size': 18,\n",
    "    'axes.labelweight': 'bold',\n",
    "    'figure.dpi': 350.0,\n",
    "})\n",
    "\n",
    "models = {\n",
    "    \"RF\": RandomForestClassifier(max_depth=2, max_features='log2', min_samples_leaf=3,\n",
    "                       min_samples_split=4, n_estimators=40),\n",
    "    \"EF\": ExtraTreesClassifier(max_depth=4, max_features='log2', min_samples_leaf=2,\n",
    "                     n_estimators=40),\n",
    "    \"GB\": GradientBoostingClassifier(learning_rate=0.01, max_depth=2, max_features='sqrt',\n",
    "                           min_samples_leaf=3, n_estimators=10),\n",
    "    \"AB\": AdaBoostClassifier(learning_rate=0.01, n_estimators=100),\n",
    "    \"DT\": DecisionTreeClassifier(max_depth=10, max_features='sqrt', min_samples_leaf=3,\n",
    "                       min_samples_split=4)\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "rand_seed = 100\n",
    "n_repeat = 100\n",
    "folder_type='hnum'\n",
    "# cv = RepeatedKFold(n_splits=6, n_repeats=n_repeat, random_state=rand_seed)\n",
    "\n",
    "# tag = \"RF\"\n",
    "for x in models.keys():\n",
    "    tag = x\n",
    "    model_type = models[tag]\n",
    "    model_name = model_type.__str__().split('(')[0]\n",
    "\n",
    "    print(f\"{tag} training for {n_repeat} runs\")\n",
    "\n",
    "    if model_name.__contains__(\"XGBClassifier\"):\n",
    "        model_name = \"XGBClassifier\"\n",
    "\n",
    "    dirmaker(f'./model-logs/training/{folder_type}/{xdate}')\n",
    "    file_name = open(\n",
    "        f\"./model-logs/training/{folder_type}/{xdate}/{model_name}_{folder_type}_{n_repeat}_{xdate}_{rand_seed}.txt\", \"w+\")\n",
    "\n",
    "    train_ab_dt_ef_gb_rf(model_type, des_df_hnum, nondes_df_hnum, \n",
    "    file_name=file_name, folder_type=folder_type, num=n_repeat, rand_seed=rand_seed, features=features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"xtick.labelsize\": 14,\n",
    "    \"ytick.labelsize\": 14,\n",
    "    'font.size': 18,\n",
    "    'axes.labelweight': 'bold',\n",
    "    'figure.dpi': 350.0,\n",
    "})\n",
    "\n",
    "\n",
    "models = {\n",
    "    \"KNN-old\": KNeighborsClassifier(metric='manhattan', n_jobs=-1, n_neighbors=15,\n",
    "                     weights='distance'),\n",
    "    \"KNN\": KNeighborsClassifier(metric='manhattan', n_jobs=-1, n_neighbors=7,\n",
    "                     weights='distance')                 \n",
    "}\n",
    "\n",
    "xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "rand_seed = 100\n",
    "n_repeat = 100\n",
    "folder_type='hnum'\n",
    "\n",
    "tag = \"KNN\"\n",
    "model_type = models[tag]\n",
    "model_name = model_type.__str__().split('(')[0]\n",
    "print(model_name)\n",
    "print(f\"{tag} training for {n_repeat} runs\")\n",
    "\n",
    "dirmaker(f'./model-logs/training/{folder_type}/{xdate}')\n",
    "file_name = open(\n",
    "    f\"./model-logs/training/{folder_type}/{xdate}/{model_name}_{folder_type}_{n_repeat}_{xdate}_{rand_seed}.txt\", \"w+\")\n",
    "\n",
    "\n",
    "train_knn(model_type, des_df_hnum, nondes_df_hnum, \n",
    "file_name=file_name, folder_type=folder_type, num=n_repeat, rand_seed=rand_seed, features=features, model_name=model_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"xtick.labelsize\": 14,\n",
    "    \"ytick.labelsize\": 14,\n",
    "    'font.size': 18,\n",
    "    'axes.labelweight': 'bold',\n",
    "    'figure.dpi': 350.0,\n",
    "})\n",
    "\n",
    "\n",
    "models = {\n",
    "    \"SVC\": SVC(C=1, probability=True)\n",
    "}\n",
    "\n",
    "xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "rand_seed = 100\n",
    "n_repeat = 100\n",
    "folder_type='hnum'\n",
    "\n",
    "tag = \"SVC\"\n",
    "model_type = models[tag]\n",
    "model_name = model_type.__str__().split('(')[0]\n",
    "print(f'{model_name}')\n",
    "print(f\"{tag} training for {n_repeat} runs\")\n",
    "\n",
    "dirmaker(f'./model-logs/training/{folder_type}/{xdate}')\n",
    "file_name = open(\n",
    "    f\"./model-logs/training/{folder_type}/{xdate}/{model_name}_{folder_type}_{n_repeat}_{xdate}_{rand_seed}.txt\", \"w+\")\n",
    "\n",
    "\n",
    "train_svc(model_type, des_df_hnum, nondes_df_hnum, \n",
    "file_name=file_name, folder_type=folder_type, num=n_repeat, rand_seed=rand_seed, features=features, model_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost with Repeated KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "import multiprocessing\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold, RepeatedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"xtick.labelsize\": 14,\n",
    "    \"ytick.labelsize\": 14,\n",
    "    'font.size': 18,\n",
    "    'axes.labelweight': 'bold',\n",
    "    'figure.dpi': 150.0,\n",
    "})  # 'figure.figsize': [14.0, 10.0],\n",
    "\n",
    "\n",
    "print(\"Parallel Parameter optimization\")\n",
    "xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "xgb_roc_auc_repeatK = []\n",
    "coeff_xgb_repeatK = [0, 0, 0, 0, 0]\n",
    "# num = 10\n",
    "cv = RepeatedKFold(n_splits=5, n_repeats=10, random_state=100)\n",
    "\n",
    "dirmaker(f'./model-logs/hnum/{xdate}')\n",
    "file_hnum_xgb_repeatK = open(\n",
    "    f\"./model-logs/hnum/{xdate}/XGB_hnum_repeatKFold_{xdate}_100.txt\", \"w+\")\n",
    "\n",
    "xgb_class_hnumrepeatK = XGBClassifier(\n",
    "    tree_method='hist',\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='auc',\n",
    "    objective='binary:logistic',\n",
    "    n_jobs=multiprocessing.cpu_count() // 2)  # tree_method='gpu_hist', enable_categorical=True, predictor='gpu_predictor',\n",
    "\n",
    "p_repeatK = {'max_depth': [2, 4, 6, 8, 10],\n",
    "             'n_estimators': [10, 20, 30, 40, 50, 100],\n",
    "             'learning_rate': [0.01, 0.1],\n",
    "             # ,0.6,0.7,0.8,0.9,1.0\n",
    "             'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "             }\n",
    "\n",
    "\n",
    "X_train_hnum, y_train_hnum, X_test_hnum, y_test_hnum = data_generator(\n",
    "    des_df_hnum, nondes_df_hnum, test_sample_size=8, nondes_batch_size=38)\n",
    "\n",
    "xgb_clf = GridSearchCV(xgb_class_hnumrepeatK,\n",
    "                       param_grid=p_repeatK, verbose=1, scoring='roc_auc', cv=cv)\n",
    "\n",
    "xgb_class_hnum_repeatK = xgb_clf.fit(X_train_hnum, y_train_hnum, eval_set=[(X_train_hnum, y_train_hnum), (\n",
    "    X_test_hnum, y_test_hnum)], verbose=False, early_stopping_rounds=50)  # , early_stopping_rounds=50\n",
    "\n",
    "print('Best score', xgb_class_hnum_repeatK.best_score_, file=file_hnum_xgb_repeatK)\n",
    "print('Best params', xgb_class_hnum_repeatK.best_params_,\n",
    "      file=file_hnum_xgb_repeatK)\n",
    "y_pred_hnum_xgb = xgb_class_hnum_repeatK.best_estimator_.predict(X_test_hnum)\n",
    "target_names = ['non-DES', 'DES']  # non-DES is 0, DES is 1\n",
    "print(metrics.classification_report(y_test_hnum, y_pred_hnum_xgb,\n",
    "      target_names=target_names), file=file_hnum_xgb_repeatK)\n",
    "roc_auc_xgb = metrics.roc_auc_score(y_test_hnum, y_pred_hnum_xgb)\n",
    "print(f\"roc_auc_score: {roc_auc_xgb}\", file=file_hnum_xgb_repeatK)\n",
    "xgb_roc_auc_repeatK.append(roc_auc_xgb)\n",
    "print(xgb_class_hnum_repeatK.best_estimator_.feature_importances_,\n",
    "      file=file_hnum_xgb_repeatK)\n",
    "# print(f\"intercept: {xgb_class_hnum_repeatK.intercept_}\", file=file_hnum_xgb_repeatK)\n",
    "\n",
    "xgb_class_hnum_repeatK_feature_df = pd.DataFrame(\n",
    "    {'Importance': xgb_class_hnum_repeatK.best_estimator_.feature_importances_, 'features': features})\n",
    "max_coeff_index = list(xgb_class_hnum_repeatK.best_estimator_.feature_importances_).index(\n",
    "    xgb_class_hnum_repeatK.best_estimator_.feature_importances_.max())\n",
    "print(\n",
    "    f'max feature: {xgb_class_hnum_repeatK.best_estimator_.feature_importances_.max()} at index {max_coeff_index} [{features[max_coeff_index]}]', file=file_hnum_xgb_repeatK)\n",
    "coeff_xgb_repeatK[max_coeff_index] += 1\n",
    "print('\\n', file=file_hnum_xgb_repeatK)\n",
    "print(xgb_class_hnum_repeatK_feature_df, file=file_hnum_xgb_repeatK)\n",
    "print('\\n'*2, file=file_hnum_xgb_repeatK)\n",
    "\n",
    "# roc = [ z for z in range(1,num+1)]\n",
    "print(\n",
    "    f\"roc_auc scores on test set: {xgb_roc_auc_repeatK}\", file=file_hnum_xgb_repeatK)\n",
    "print(\n",
    "    f\"Average roc_auc scores on test set: {np.average(xgb_roc_auc_repeatK)}\", file=file_hnum_xgb_repeatK)\n",
    "print(\n",
    "    f\"std dev of roc_auc scores on test set: {np.std(xgb_roc_auc_repeatK)}\", file=file_hnum_xgb_repeatK)\n",
    "print(\n",
    "    f\"Best roc_auc score on test set: {max(xgb_roc_auc_repeatK)} at index {xgb_roc_auc_repeatK.index(max(xgb_roc_auc_repeatK)) + 1}\", file=file_hnum_xgb_repeatK)\n",
    "print(\n",
    "    f\"Best model's roc_auc score from early stopping: {xgb_class_hnum_repeatK.best_estimator_.best_score}\", file=file_hnum_xgb_repeatK)\n",
    "print(\n",
    "    f\"Best model's iteration from early stopping: {xgb_class_hnum_repeatK.best_estimator_.best_iteration}\", file=file_hnum_xgb_repeatK)\n",
    "# print(f\"model's eval_results: {xgb_class_hnum_repeatK.best_estimator_.evals_result()}\", file=file_hnum_xgb_repeatK)\n",
    "train_eval = list(xgb_class_hnum_repeatK.best_estimator_.evals_result()[\n",
    "                  'validation_0'].items())\n",
    "print(\n",
    "    f'Number of training auc scores: {len(train_eval[0][1])}', file=file_hnum_xgb_repeatK)\n",
    "print(\n",
    "    f'auc scores of training set: {train_eval[0][1]}', file=file_hnum_xgb_repeatK)\n",
    "print(f'Average and std-dev of auc scores of training set: {round(np.average(train_eval[0][1]),2)}, \\\n",
    "{round(np.std(train_eval[0][1]),2)} \\n', file=file_hnum_xgb_repeatK)\n",
    "\n",
    "val_eval = list(xgb_class_hnum_repeatK.best_estimator_.evals_result()[\n",
    "                'validation_1'].items())\n",
    "print(\n",
    "    f'Number of testing auc scores: {len(val_eval[0][1])}', file=file_hnum_xgb_repeatK)\n",
    "print(\n",
    "    f'auc scores of testing set: {val_eval[0][1]}', file=file_hnum_xgb_repeatK)\n",
    "print(f'Average and std-dev of auc scores of testing set: {round(np.average(val_eval[0][1]),2)}, \\\n",
    "{round(np.std(val_eval[0][1]),2)} \\n', file=file_hnum_xgb_repeatK)\n",
    "\n",
    "print('\\n', file=file_hnum_xgb_repeatK)\n",
    "coeff_df_xgb = pd.DataFrame(\n",
    "    {'Top features': coeff_xgb_repeatK, 'features': features})\n",
    "print(f\"Coefficients: {coeff_df_xgb} \\n\", file=file_hnum_xgb_repeatK)\n",
    "\n",
    "print(f'Best estimator: {xgb_class_hnum_repeatK.best_estimator_} \\n',\n",
    "      file=file_hnum_xgb_repeatK)\n",
    "print(f'Best params: {xgb_class_hnum_repeatK.best_params_} \\n',\n",
    "      file=file_hnum_xgb_repeatK)\n",
    "print(\n",
    "    f\"Best estimator's score from early stopping: {xgb_class_hnum_repeatK.best_estimator_.best_score} \\n\", file=file_hnum_xgb_repeatK)\n",
    "# plotting roc_auc score\n",
    "fig = plt.figure()\n",
    "fig_ax = fig.add_subplot(1, 1, 1)\n",
    "fig.set_size_inches(12, 8, forward=True)\n",
    "fig_ax.set_xlabel(\"Number of runs\")\n",
    "fig_ax.set_ylabel(\"ROC-AUC score\")\n",
    "fig_ax.set_ylim(0, 1.1)\n",
    "plt.title('XGBoost (Repeated KFold) hbond number', fontsize=12, weight='bold')\n",
    "\n",
    "fig_ax.plot(range(1, len(train_eval[0][1])+1), train_eval[0][1], '-o', linewidth=2, markersize=8.0, label=f\"avg training roc_auc: {round(np.average(train_eval[0][1]),2)}\\n \\\n",
    "std training roc_auc : {round(np.std(train_eval[0][1]),2)}\")\n",
    "\n",
    "fig_ax.plot(range(1, len(val_eval[0][1])+1), val_eval[0][1], '-o', linewidth=2, markersize=8.0, label=f\"avg testing roc_auc: {round(np.average(val_eval[0][1]),2)}\\n \\\n",
    "std testing roc_auc : {round(np.std(val_eval[0][1]),2)}\")\n",
    "\n",
    "plt.legend(loc='best')\n",
    "file_hnum_xgb_repeatK.close()\n",
    "dirmaker(f'./plots/roc-auc/hnum/{xdate}')\n",
    "fig.savefig(f'plots/roc-auc/hnum/{xdate}/XGB_hnum_repeatK-{xdate}_100.png',\n",
    "            dpi=500, facecolor='white', bbox_inches='tight')\n",
    "\n",
    "xgb.plot_importance(\n",
    "    xgb_class_hnum_repeatK.best_estimator_).set_yticklabels(features)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_hnum, y_train_hnum, X_test_hnum, y_test_hnum\n",
    "# len(y_test_hnum)\n",
    "list(xgb_class_hnum_repeatK.best_estimator_.evals_result()\n",
    "     ['validation_0'].items())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost with Repeated stratified KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "import multiprocessing\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold, RepeatedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"xtick.labelsize\": 16,\n",
    "    \"ytick.labelsize\": 16,\n",
    "    'font.size': 18,\n",
    "    'axes.labelweight': 'bold',\n",
    "    'figure.dpi': 150.0,\n",
    "})  # 'figure.figsize': [14.0, 10.0],\n",
    "\n",
    "\n",
    "print(\"Parallel Parameter optimization\")\n",
    "xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "xgb_roc_auc_stratK = []\n",
    "coeff_xgb_stratK = [0, 0, 0, 0, 0]\n",
    "# num = 10\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=1000)\n",
    "\n",
    "dirmaker(f'./model-logs/hnum/{xdate}')\n",
    "file_hnum_xgb_stratK = open(\n",
    "    f\"./model-logs/hnum/{xdate}/XGB_hnum_stratKFold_{xdate}.txt\", \"w+\")\n",
    "\n",
    "xgb_class_hnumstratK = XGBClassifier(\n",
    "    tree_method='hist',\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='auc',\n",
    "    objective='binary:logistic',\n",
    "    n_jobs=multiprocessing.cpu_count() // 2)  # tree_method='gpu_hist', enable_categorical=True, predictor='gpu_predictor',\n",
    "\n",
    "p_stratK = {'max_depth': [2, 4, 6, 8, 10],\n",
    "            'n_estimators': [10, 20, 30, 40, 50, 100],\n",
    "            'learning_rate': [0.01, 0.1],\n",
    "            # ,0.6,0.7,0.8,0.9,1.0\n",
    "            'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "            }\n",
    "\n",
    "\n",
    "X_train_hnum, y_train_hnum, X_test_hnum, y_test_hnum = data_generator(\n",
    "    des_df_hnum, nondes_df_hnum, test_sample_size=8, nondes_batch_size=38)\n",
    "\n",
    "xgb_clf = GridSearchCV(\n",
    "    xgb_class_hnumstratK, param_grid=p_stratK, verbose=1, scoring='roc_auc', cv=cv)\n",
    "\n",
    "xgb_class_hnum_stratK = xgb_clf.fit(X_train_hnum, y_train_hnum, eval_set=[(X_train_hnum, y_train_hnum), (\n",
    "    X_test_hnum, y_test_hnum)], verbose=False, early_stopping_rounds=50)  # , early_stopping_rounds=50\n",
    "\n",
    "print('Best score', xgb_class_hnum_stratK.best_score_, file=file_hnum_xgb_stratK)\n",
    "print('Best params', xgb_class_hnum_stratK.best_params_, file=file_hnum_xgb_stratK)\n",
    "y_pred_hnum_xgb = xgb_class_hnum_stratK.best_estimator_.predict(X_test_hnum)\n",
    "target_names = ['non-DES', 'DES']  # non-DES is 0, DES is 1\n",
    "print(metrics.classification_report(y_test_hnum, y_pred_hnum_xgb,\n",
    "      target_names=target_names), file=file_hnum_xgb_stratK)\n",
    "roc_auc_xgb = metrics.roc_auc_score(y_test_hnum, y_pred_hnum_xgb)\n",
    "print(f\"roc_auc_score: {roc_auc_xgb}\", file=file_hnum_xgb_stratK)\n",
    "xgb_roc_auc_stratK.append(roc_auc_xgb)\n",
    "print(xgb_class_hnum_stratK.best_estimator_.feature_importances_,\n",
    "      file=file_hnum_xgb_stratK)\n",
    "# print(f\"intercept: {xgb_class_hnum_stratK.intercept_}\", file=file_hnum_xgb_stratK)\n",
    "\n",
    "xgb_class_hnum_stratK_feature_df = pd.DataFrame(\n",
    "    {'Importance': xgb_class_hnum_stratK.best_estimator_.feature_importances_, 'features': features})\n",
    "max_coeff_index = list(xgb_class_hnum_stratK.best_estimator_.feature_importances_).index(\n",
    "    xgb_class_hnum_stratK.best_estimator_.feature_importances_.max())\n",
    "print(\n",
    "    f'max feature: {xgb_class_hnum_stratK.best_estimator_.feature_importances_.max()} at index {max_coeff_index} [{features[max_coeff_index]}]', file=file_hnum_xgb_stratK)\n",
    "coeff_xgb_stratK[max_coeff_index] += 1\n",
    "print('\\n', file=file_hnum_xgb_stratK)\n",
    "print(xgb_class_hnum_stratK_feature_df, file=file_hnum_xgb_stratK)\n",
    "print('\\n'*2, file=file_hnum_xgb_stratK)\n",
    "\n",
    "# roc = [ z for z in range(1,num+1)]\n",
    "print(\n",
    "    f\"roc_auc scores on test set: {xgb_roc_auc_stratK}\", file=file_hnum_xgb_stratK)\n",
    "print(\n",
    "    f\"Average roc_auc scores on test set: {np.average(xgb_roc_auc_stratK)}\", file=file_hnum_xgb_stratK)\n",
    "print(\n",
    "    f\"std dev of roc_auc scores on test set: {np.std(xgb_roc_auc_stratK)}\", file=file_hnum_xgb_stratK)\n",
    "print(\n",
    "    f\"Best roc_auc score on test set: {max(xgb_roc_auc_stratK)} at index {xgb_roc_auc_stratK.index(max(xgb_roc_auc_stratK)) + 1}\", file=file_hnum_xgb_stratK)\n",
    "print(\n",
    "    f\"Best model's roc_auc score from early stopping: {xgb_class_hnum_stratK.best_estimator_.best_score}\", file=file_hnum_xgb_stratK)\n",
    "print(\n",
    "    f\"Best model's iteration from early stopping: {xgb_class_hnum_stratK.best_estimator_.best_iteration}\", file=file_hnum_xgb_stratK)\n",
    "# print(f\"model's eval_results: {xgb_class_hnum_stratK.best_estimator_.evals_result()}\", file=file_hnum_xgb_stratK)\n",
    "train_eval = list(xgb_class_hnum_stratK.best_estimator_.evals_result()[\n",
    "                  'validation_0'].items())\n",
    "print(\n",
    "    f'Number of training auc scores: {len(train_eval[0][1])}', file=file_hnum_xgb_stratK)\n",
    "print(\n",
    "    f'auc scores of training set: {train_eval[0][1]}', file=file_hnum_xgb_stratK)\n",
    "print(f'Average and std-dev of auc scores of training set: {round(np.average(train_eval[0][1]),2)}, \\\n",
    "{round(np.std(train_eval[0][1]),2)} \\n', file=file_hnum_xgb_stratK)\n",
    "\n",
    "val_eval = list(xgb_class_hnum_stratK.best_estimator_.evals_result()[\n",
    "                'validation_1'].items())\n",
    "print(\n",
    "    f'Number of testing auc scores: {len(val_eval[0][1])}', file=file_hnum_xgb_stratK)\n",
    "print(\n",
    "    f'auc scores of testing set: {val_eval[0][1]}', file=file_hnum_xgb_stratK)\n",
    "print(f'Average and std-dev of auc scores of testing set: {round(np.average(val_eval[0][1]),2)}, \\\n",
    "{round(np.std(val_eval[0][1]),2)} \\n', file=file_hnum_xgb_stratK)\n",
    "\n",
    "print('\\n', file=file_hnum_xgb_stratK)\n",
    "coeff_df_xgb = pd.DataFrame(\n",
    "    {'Top features': coeff_xgb_stratK, 'features': features})\n",
    "print(f\"Coefficients: {coeff_df_xgb} \\n\", file=file_hnum_xgb_stratK)\n",
    "\n",
    "print(f'Best estimator: {xgb_class_hnum_stratK.best_estimator_} \\n',\n",
    "      file=file_hnum_xgb_stratK)\n",
    "print(f'Best params: {xgb_class_hnum_stratK.best_params_} \\n',\n",
    "      file=file_hnum_xgb_stratK)\n",
    "print(\n",
    "    f\"Best estimator's score from early stopping: {xgb_class_hnum_stratK.best_estimator_.best_score} \\n\", file=file_hnum_xgb_stratK)\n",
    "# plotting roc_auc score\n",
    "fig = plt.figure()\n",
    "fig_ax = fig.add_subplot(1, 1, 1)\n",
    "fig.set_size_inches(12, 8, forward=True)\n",
    "fig_ax.set_xlabel(\"Number of runs\")\n",
    "fig_ax.set_ylabel(\"ROC-AUC score\")\n",
    "fig_ax.set_ylim(0, 1.1)\n",
    "plt.title('XGBoost (Repeated stratified KFold) hbond number',\n",
    "          fontsize=12, weight='bold')\n",
    "\n",
    "fig_ax.plot(range(1, len(train_eval[0][1])+1), train_eval[0][1], '-o', linewidth=2, markersize=8.0, label=f\"avg training roc_auc: {round(np.average(train_eval[0][1]),2)}\\n \\\n",
    "std training roc_auc : {round(np.std(train_eval[0][1]),2)}\")\n",
    "\n",
    "fig_ax.plot(range(1, len(val_eval[0][1])+1), val_eval[0][1], '-o', linewidth=2, markersize=8.0, label=f\"avg testing roc_auc: {round(np.average(val_eval[0][1]),2)}\\n \\\n",
    "std testing roc_auc : {round(np.std(val_eval[0][1]),2)}\")\n",
    "\n",
    "plt.legend(loc='best')\n",
    "file_hnum_xgb_stratK.close()\n",
    "dirmaker(f'./plots/roc-auc/hnum/{xdate}')\n",
    "fig.savefig(f'plots/roc-auc/hnum/{xdate}/XGB_hnum_stratKsearch-{xdate}.png',\n",
    "            dpi=500, facecolor='white', bbox_inches='tight')\n",
    "\n",
    "xgb.plot_importance(\n",
    "    xgb_class_hnum_stratK.best_estimator_).set_yticklabels(features)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_class_hnum_stratK.best_estimator_.evals_result()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hbond number + lifetime\n",
    "Models are trained n merged hbond number and lifetime data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### des"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "des_df_hlife_edited = des_df_hlife.rename(columns={'A-A': 'A-A_l', 'B-B': 'B-B_l', 'A-B': 'A-B_l',\n",
    "                                          'A-A/B-B': 'A-A_l/B-B_l', 'A-B/(A-A + B-B)': 'A-B_l/(A-A_l + B-B_l)', 'output': 'output_l'})\n",
    "# des_df_hlife_edited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "des_df_hnum_edited = des_df_hnum.rename(columns={'A-A': 'A-A_n', 'B-B': 'B-B_n', 'A-B': 'A-B_n',\n",
    "                                        'A-A/B-B': 'A-A_n/B-B_n', 'A-B/(A-A + B-B)': 'A-B_n/(A-A_n + B-B_n)', 'output': 'output_n'})\n",
    "# des_df_hnum_edited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nondes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nondes_df_hlife_edited = nondes_df_hlife.rename(\n",
    "    columns={'A-A': 'A-A_l', 'B-B': 'B-B_l', 'A-B': 'A-B_l', 'A-A/B-B': 'A-A_l/B-B_l', 'A-B/(A-A + B-B)': 'A-B_l/(A-A_l + B-B_l)', 'output': 'output_l'})\n",
    "# nondes_df_hlife_edited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nondes_df_hnum_edited = nondes_df_hnum.rename(\n",
    "    columns={'A-A': 'A-A_n', 'B-B': 'B-B_n', 'A-B': 'A-B_n', 'A-A/B-B': 'A-A_n/B-B_n', 'A-B/(A-A + B-B)': 'A-B_n/(A-A_n + B-B_n)', 'output': 'output_n'})\n",
    "# nondes_df_hnum_edited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "des_df_merged_list = [des_df_hnum_edited, des_df_hlife_edited]\n",
    "des_df_merged = pd.concat(des_df_merged_list, axis=1)\n",
    "# des_df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nondes_df_merged_list = [nondes_df_hnum_edited, nondes_df_hlife_edited]\n",
    "nondes_df_merged = pd.concat(nondes_df_merged_list, axis=1)\n",
    "# nondes_df_merged"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparam opt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.rcParams.update({\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"xtick.labelsize\": 14,\n",
    "    \"ytick.labelsize\": 14,\n",
    "    'font.size': 18,\n",
    "    'axes.labelweight': 'bold',\n",
    "    'figure.dpi': 300.0,\n",
    "    'axes.linewidth':2.0,\n",
    "})\n",
    "\n",
    "models = {\n",
    "     \"XGB\": XGBClassifier(\n",
    "            tree_method='hist',\n",
    "            eval_metric='auc',\n",
    "            objective='binary:logistic',\n",
    "            n_jobs=multiprocessing.cpu_count(), early_stopping_rounds=50)  \n",
    "}\n",
    "\n",
    "params = { 'XGB':{'max_depth': [2, 4, 6, 8, 10],\n",
    "             'n_estimators': [10, 20, 30, 40, 50, 100],\n",
    "             'learning_rate': [0.01, 0.1],\n",
    "             'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "             }\n",
    "}\n",
    "\n",
    "print(\"Parallel Parameter optimization\")\n",
    "xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "rand_seed = 100\n",
    "n_repeat = 10\n",
    "cv = RepeatedKFold(n_splits=6, n_repeats=n_repeat, random_state=rand_seed)\n",
    "tag = \"XGB\"\n",
    "print(f\"{tag} Parallel Parameter optimization\")\n",
    "\n",
    "model_generic = models[tag]  \n",
    "p_repeatK = params[tag]\n",
    "model_name = model_generic.__str__().split('(')[0]\n",
    "folder_type = 'merged'\n",
    "\n",
    "dirmaker(f'./model-logs/gridsearch/{folder_type}/{xdate}')\n",
    "file_merged_xgb_repeatK = open(\n",
    "    f\"./model-logs/gridsearch/{folder_type}/{xdate}/{model_name}_{folder_type}_{n_repeat}_{xdate}_{rand_seed}.txt\", \"w+\")\n",
    "\n",
    "\n",
    "kingmaker_xgb(model_generic, p_repeatK, des_df_merged, nondes_df_merged, cv=cv,\n",
    "           file_name=file_merged_xgb_repeatK, folder_type=folder_type, n_repeat=n_repeat, rand_seed=rand_seed, features=features_merged)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBRF\n",
    "plt.rcParams.update({\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"xtick.labelsize\": 14,\n",
    "    \"ytick.labelsize\": 14,\n",
    "    'font.size': 18,\n",
    "    'axes.labelweight': 'bold',\n",
    "    'figure.dpi': 300.0,\n",
    "    'axes.linewidth':2.0,\n",
    "})\n",
    "\n",
    "models = {\n",
    "    \"XGBRF\": XGBRFClassifier(\n",
    "            tree_method='hist',\n",
    "            eval_metric='auc',\n",
    "            objective='binary:logistic',\n",
    "            n_jobs=multiprocessing.cpu_count())  \n",
    "}\n",
    "\n",
    "params = {\n",
    "           'XGBRF':{'max_depth': [2, 4, 6, 8, 10],\n",
    "             'n_estimators': [10, 20, 30, 40, 50, 100],\n",
    "             'learning_rate': [0.01, 0.1],\n",
    "             'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "             }\n",
    "}\n",
    "\n",
    "print(\"Parallel Parameter optimization\")\n",
    "xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "rand_seed = 100\n",
    "n_repeat = 10\n",
    "cv = RepeatedKFold(n_splits=6, n_repeats=n_repeat, random_state=rand_seed)\n",
    "tag = \"XGBRF\"\n",
    "print(f\"{tag} Parallel Parameter optimization\")\n",
    "\n",
    "model_generic = models[tag]  \n",
    "p_repeatK = params[tag]\n",
    "model_name = model_generic.__str__().split('(')[0]\n",
    "print(model_name)\n",
    "folder_type = 'merged'\n",
    "\n",
    "dirmaker(f'./model-logs/gridsearch/{folder_type}/{xdate}')\n",
    "file_merged_xgb_repeatK = open(\n",
    "    f\"./model-logs/gridsearch/{folder_type}/{xdate}/{model_name}_{folder_type}_{n_repeat}_{xdate}_{rand_seed}.txt\", \"w+\")\n",
    "\n",
    "\n",
    "kingmaker_xgbrf(model_generic, p_repeatK, des_df_merged, nondes_df_merged, cv=cv, features=features_merged,\n",
    "           file_name=file_merged_xgb_repeatK, folder_type=folder_type, n_repeat=n_repeat, rand_seed=rand_seed)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LR\n",
    "plt.rcParams.update({\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"xtick.labelsize\": 14,\n",
    "    \"ytick.labelsize\": 14,\n",
    "    'font.size': 18,\n",
    "    'axes.labelweight': 'bold',\n",
    "    'figure.dpi': 150.0,\n",
    "})\n",
    "\n",
    "models = {\n",
    "    \"LR\": LogisticRegression()\n",
    "}\n",
    "\n",
    "params = {\n",
    "    \"LR\": {'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "            'tol': [1e-4, 1e-6],\n",
    "             'max_iter': [100, 200, 300, 400, 500],\n",
    "             'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "             }\n",
    "}\n",
    "\n",
    "\n",
    "xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "rand_seed = 100\n",
    "n_repeat = 10\n",
    "cv = RepeatedKFold(n_splits=6, n_repeats=n_repeat, random_state=rand_seed)\n",
    "tag = \"LR\"\n",
    "print(f\"{tag} Parallel Parameter optimization\")\n",
    "\n",
    "model_generic = models[tag]  \n",
    "p_repeatK = params[tag]\n",
    "model_name = model_generic.__str__().strip('()')\n",
    "folder_type = 'merged'\n",
    "\n",
    "dirmaker(f'./model-logs/gridsearch/{folder_type}/{xdate}')\n",
    "file_name = open(\n",
    "    f\"./model-logs/gridsearch/{folder_type}/{xdate}/{model_name}_{folder_type}_{n_repeat}_{xdate}_{rand_seed}.txt\", \"w+\")\n",
    "\n",
    "kingmaker_lr(model_generic, p_repeatK, des_df_merged, nondes_df_merged, cv=cv,\n",
    "           file_name=file_name, folder_type=folder_type, n_repeat=n_repeat, rand_seed=rand_seed, features=features_merged)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.rcParams.update({\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"xtick.labelsize\": 14,\n",
    "    \"ytick.labelsize\": 14,\n",
    "    'font.size': 18,\n",
    "    'axes.labelweight': 'bold',\n",
    "    'figure.dpi': 150.0,\n",
    "})\n",
    "\n",
    "models = {\n",
    "    \"RF\": RandomForestClassifier(),\n",
    "    \"EF\": ExtraTreesClassifier(),\n",
    "    \"GB\": GradientBoostingClassifier(),\n",
    "    \"AB\": AdaBoostClassifier(),\n",
    "    \"DT\": DecisionTreeClassifier()\n",
    "}\n",
    "\n",
    "params = {\n",
    "    \"RF\": {'max_depth': [2, 4, 6, 8, 10],\n",
    "             'n_estimators': [10, 20, 30, 40, 50, 100],\n",
    "             'min_samples_leaf': [1, 2, 3],\n",
    "            'min_samples_split': [2,4,6],\n",
    "             'max_features': [\"auto\", \"sqrt\", \"log2\"],\n",
    "             },\n",
    "    \"EF\": {'max_depth': [2, 4, 6, 8, 10],\n",
    "             'n_estimators': [10, 20, 30, 40, 50, 100],\n",
    "             'min_samples_leaf': [1, 2, 3],\n",
    "            'min_samples_split': [2,4,6],\n",
    "             'max_features': [\"auto\", \"sqrt\", \"log2\"],\n",
    "             },\n",
    "    \"GB\": {'max_depth': [2, 4, 6, 8, 10],\n",
    "             'n_estimators': [10, 20, 30, 40, 50, 100],\n",
    "             'min_samples_leaf': [1, 2, 3],\n",
    "            'min_samples_split': [2,4,6],\n",
    "             'max_features': [\"auto\", \"sqrt\", \"log2\"],\n",
    "             'learning_rate': [0.01, 0.1],\n",
    "             },\n",
    "    \"AB\": {'n_estimators': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "             'learning_rate': [0.001, 0.01, 0.1, 1.0],\n",
    "             },\n",
    "    \"DT\": {'max_depth': [2, 4, 6, 8, 10],\n",
    "             'min_samples_leaf': [1, 2, 3],\n",
    "            'min_samples_split': [2,4,6],\n",
    "             'max_features': [\"auto\", \"sqrt\", \"log2\"],\n",
    "             }\n",
    "}\n",
    "\n",
    "\n",
    "xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "rand_seed = 100\n",
    "n_repeat = 10\n",
    "cv = RepeatedKFold(n_splits=6, n_repeats=n_repeat, random_state=rand_seed)\n",
    "\n",
    "for x in models.keys():\n",
    "    tag = x\n",
    "    print(f\"{tag} Parallel Parameter optimization\")\n",
    "\n",
    "    model_generic = models[tag]  \n",
    "    p_repeatK = params[tag]\n",
    "    model_name = model_generic.__str__().split('(')[0]\n",
    "\n",
    "    folder_type = 'merged'\n",
    "\n",
    "    dirmaker(f'./model-logs/gridsearch/{folder_type}/{xdate}')\n",
    "    file_name = open(\n",
    "        f\"./model-logs/gridsearch/{folder_type}/{xdate}/{model_name}_{folder_type}_{n_repeat}_{xdate}_{rand_seed}.txt\", \"w+\")\n",
    "\n",
    "    kingmaker_generic(model_generic, p_repeatK, des_df_merged, nondes_df_merged, cv=cv,\n",
    "           file_name=file_name, folder_type=folder_type, n_repeat=n_repeat, rand_seed=rand_seed, features=features_merged)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC\n",
    "plt.rcParams.update({\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"xtick.labelsize\": 14,\n",
    "    \"ytick.labelsize\": 14,\n",
    "    'font.size': 18,\n",
    "    'axes.labelweight': 'bold',\n",
    "    'figure.dpi': 150.0,\n",
    "})\n",
    "\n",
    "models = {\n",
    "    \"SVC\": SVC(probability=True),\n",
    "    \"SVC1\": SVC(probability=True)\n",
    "}\n",
    "\n",
    "# 'gamma': ['scale', 'auto'],\n",
    "# 'gamma': [0.001, 0.0001],\n",
    "# \"C\": [1, 10, 100, 1000]\n",
    "#             \n",
    "params = {\n",
    "    \"SVC\": { \n",
    "             'degree': [3, 5, 7],\n",
    "             'kernel' : ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "             'tol': [1e-3, 1e-4, 1e-5, 1e-6],\n",
    "             \"C\": [1, 10]\n",
    "             }\n",
    "}\n",
    "\n",
    "\n",
    "xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "rand_seed = 100\n",
    "n_repeat = 10\n",
    "cv = RepeatedKFold(n_splits=6, n_repeats=n_repeat, random_state=rand_seed)\n",
    "tag = \"SVC\"\n",
    "print(f\"{tag} Parallel Parameter optimization\")\n",
    "\n",
    "model_generic = models[tag]  \n",
    "p_repeatK = params[tag]\n",
    "model_name = model_generic.__str__().split('(')[0]\n",
    "folder_type = 'merged'\n",
    "\n",
    "dirmaker(f'./model-logs/gridsearch/{folder_type}/{xdate}')\n",
    "file_name = open(\n",
    "    f\"./model-logs/gridsearch/{folder_type}/{xdate}/{model_name}_{folder_type}_{n_repeat}_{xdate}_{rand_seed}.txt\", \"w+\")\n",
    "\n",
    "\n",
    "\n",
    "kingmaker_svc(model_generic, p_repeatK, des_df_merged, nondes_df_merged, cv=cv,\n",
    "           file_name=file_name, folder_type=folder_type, n_repeat=n_repeat, rand_seed=rand_seed, features=features_merged)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "plt.rcParams.update({\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"xtick.labelsize\": 14,\n",
    "    \"ytick.labelsize\": 14,\n",
    "    'font.size': 18,\n",
    "    'axes.labelweight': 'bold',\n",
    "    'figure.dpi': 150.0,\n",
    "})\n",
    "\n",
    "models = {\n",
    "    \"KNN\": KNeighborsClassifier(n_jobs=-1)\n",
    "}\n",
    "\n",
    "params = {\n",
    "    \"KNN\": {'n_neighbors' : [5,7,9,11,13,15],\n",
    "               'weights' : ['uniform','distance'],\n",
    "               'metric' : ['minkowski','euclidean','manhattan'],\n",
    "               'leaf_size' : [30, 40, 50, 60]\n",
    "               }\n",
    "}\n",
    "\n",
    "\n",
    "xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "rand_seed = 100\n",
    "n_repeat = 10\n",
    "cv = RepeatedKFold(n_splits=6, n_repeats=n_repeat, random_state=rand_seed)\n",
    "tag = \"KNN\"\n",
    "print(f\"{tag} Parallel Parameter optimization\")\n",
    "\n",
    "model_generic = models[tag]  \n",
    "p_repeatK = params[tag]\n",
    "model_name = model_generic.__str__().split('(')[0]\n",
    "folder_type = 'merged'\n",
    "\n",
    "dirmaker(f'./model-logs/gridsearch/{folder_type}/{xdate}')\n",
    "file_name = open(\n",
    "    f\"./model-logs/gridsearch/{folder_type}/{xdate}/{model_name}_{folder_type}_{n_repeat}_{xdate}_{rand_seed}.txt\", \"w+\")\n",
    "\n",
    "kingmaker_knn(model_generic, p_repeatK, des_df_merged, nondes_df_merged, cv=cv,\n",
    "           file_name=file_name, folder_type=folder_type, n_repeat=n_repeat, rand_seed=rand_seed, features=features_merged)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"xtick.labelsize\": 14,\n",
    "    \"ytick.labelsize\": 14,\n",
    "    'font.size': 18,\n",
    "    'axes.labelweight': 'bold',\n",
    "    'figure.dpi': 350.0,\n",
    "})\n",
    "\n",
    "\n",
    "models = {\n",
    "    \"LR\": LogisticRegression(penalty='l1', solver='saga'),\n",
    "    \"LR2\": LogisticRegression(max_iter=100, penalty='l2', solver='newton-cg', tol=0.0001)  # old hnum data with errors \n",
    "}\n",
    "\n",
    "xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "rand_seed = 100\n",
    "n_repeat = 100\n",
    "folder_type='merged'\n",
    "\n",
    "tag = \"LR\"\n",
    "model_type = models[tag]\n",
    "model_name = model_type.__str__().split('(')[0]\n",
    "print(f\"{tag} training for {n_repeat} runs\")\n",
    "\n",
    "dirmaker(f'./model-logs/training/{folder_type}/{xdate}')\n",
    "file_name = open(\n",
    "    f\"./model-logs/training/{folder_type}/{xdate}/{model_name}_{folder_type}_{n_repeat}_{xdate}_{rand_seed}.txt\", \"w+\")\n",
    "\n",
    "\n",
    "train_lr(model_type, des_df_merged, nondes_df_merged, \n",
    "file_name=file_name, folder_type=folder_type, num=n_repeat, rand_seed=rand_seed, features=features_merged, model_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AB, DT, EF, GB, RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AB, DT, EF, GB, RF\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"xtick.labelsize\": 14,\n",
    "    \"ytick.labelsize\": 14,\n",
    "    'font.size': 18,\n",
    "    'axes.labelweight': 'bold',\n",
    "    'figure.dpi': 350.0,\n",
    "})\n",
    "\n",
    "models = {\n",
    "    \"RF\": RandomForestClassifier(max_depth=2, max_features='auto', min_samples_leaf=3,\n",
    "                       min_samples_split=6, n_estimators=50),\n",
    "    \"EF\": ExtraTreesClassifier(max_depth=2, max_features='log2', min_samples_leaf=3,\n",
    "                     n_estimators=20),\n",
    "    \"GB\": GradientBoostingClassifier(learning_rate=0.01, max_depth=2, max_features='log2',\n",
    "                           min_samples_split=4, n_estimators=10),\n",
    "    \"AB\": AdaBoostClassifier(learning_rate=0.01, n_estimators=80),\n",
    "    \"DT\": DecisionTreeClassifier(max_depth=2, max_features='auto', min_samples_leaf=2)\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "rand_seed = 100\n",
    "n_repeat = 100\n",
    "folder_type='merged'\n",
    "\n",
    "for x in models.keys():\n",
    "    tag = x\n",
    "    model_type = models[tag]\n",
    "    model_name = model_type.__str__().split('(')[0]\n",
    "\n",
    "    print(f\"{tag} training for {n_repeat} runs\")\n",
    "\n",
    "    dirmaker(f'./model-logs/training/{folder_type}/{xdate}')\n",
    "    file_name = open(\n",
    "        f\"./model-logs/training/{folder_type}/{xdate}/{model_name}_{folder_type}_{n_repeat}_{xdate}_{rand_seed}.txt\", \"w+\")\n",
    "\n",
    "    train_ab_dt_ef_gb_rf(model_type, des_df_merged, nondes_df_merged, \n",
    "    file_name=file_name, folder_type=folder_type, num=n_repeat, rand_seed=rand_seed, features=features_merged)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"xtick.labelsize\": 14,\n",
    "    \"ytick.labelsize\": 14,\n",
    "    'font.size': 18,\n",
    "    'axes.labelweight': 'bold',\n",
    "    'figure.dpi': 350.0,\n",
    "})\n",
    "\n",
    "\n",
    "models = {\n",
    "    \"SVC\": SVC(C=1, probability=True)\n",
    "}\n",
    "\n",
    "xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "rand_seed = 100\n",
    "n_repeat = 100\n",
    "folder_type='merged'\n",
    "\n",
    "tag = \"SVC\"\n",
    "model_type = models[tag]\n",
    "model_name = model_type.__str__().split('(')[0]\n",
    "print(f\"{tag} training for {n_repeat} runs\")\n",
    "\n",
    "dirmaker(f'./model-logs/training/{folder_type}/{xdate}')\n",
    "file_name = open(\n",
    "    f\"./model-logs/training/{folder_type}/{xdate}/{model_name}_{folder_type}_{n_repeat}_{xdate}_{rand_seed}.txt\", \"w+\")\n",
    "\n",
    "\n",
    "train_svc(model_type, des_df_merged, nondes_df_merged, \n",
    "file_name=file_name, folder_type=folder_type, num=n_repeat, rand_seed=rand_seed, features=features_merged, model_name=model_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"xtick.labelsize\": 14,\n",
    "    \"ytick.labelsize\": 14,\n",
    "    'font.size': 18,\n",
    "    'axes.labelweight': 'bold',\n",
    "    'figure.dpi': 350.0,\n",
    "})\n",
    "\n",
    "\n",
    "models = {\n",
    "    \"KNN-old\": KNeighborsClassifier(metric='manhattan', n_jobs=-1, n_neighbors=13,\n",
    "                     weights='distance'),\n",
    "    \"KNN\": KNeighborsClassifier(n_jobs=-1, n_neighbors=9, weights='distance')                 \n",
    "}\n",
    "\n",
    "xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "rand_seed = 100\n",
    "n_repeat = 100\n",
    "folder_type='merged'\n",
    "\n",
    "tag = \"KNN\"\n",
    "model_type = models[tag]\n",
    "model_name = model_type.__str__().split('(')[0]\n",
    "print(model_name)\n",
    "print(f\"{tag} training for {n_repeat} runs\")\n",
    "\n",
    "dirmaker(f'./model-logs/training/{folder_type}/{xdate}')\n",
    "file_name = open(\n",
    "    f\"./model-logs/training/{folder_type}/{xdate}/{model_name}_{folder_type}_{n_repeat}_{xdate}_{rand_seed}.txt\", \"w+\")\n",
    "\n",
    "\n",
    "train_knn(model_type, des_df_merged, nondes_df_merged, \n",
    "file_name=file_name, folder_type=folder_type, num=n_repeat, rand_seed=rand_seed, features=features_merged, model_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# XGB training loop\n",
    "plt.rcParams.update({\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"xtick.labelsize\": 14,\n",
    "    \"ytick.labelsize\": 14,\n",
    "    'font.size': 18,\n",
    "    'axes.labelweight': 'bold',\n",
    "    'figure.dpi': 350.0,\n",
    "    'axes.linewidth':2.0,\n",
    "})\n",
    "\n",
    "models = {    \n",
    "    \"XGB-old\": XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=0.3,\n",
    "              enable_categorical=False, eval_metric='auc', gamma=0, gpu_id=-1,\n",
    "              importance_type=None, interaction_constraints='',\n",
    "              learning_rate=0.1, max_delta_step=0, max_depth=6,\n",
    "              min_child_weight=1, monotone_constraints='()',\n",
    "              n_estimators=40, n_jobs=12, num_parallel_tree=1, predictor='auto',\n",
    "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
    "              subsample=1, tree_method='hist', use_label_encoder=False,\n",
    "              validate_parameters=1, verbosity=None),\n",
    "    \"XGB\": XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
    "              colsample_bylevel=None, colsample_bynode=None,\n",
    "              colsample_bytree=0.5, \n",
    "              enable_categorical=False, eval_metric='auc', feature_types=None,\n",
    "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
    "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
    "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
    "              max_delta_step=None, max_depth=2, max_leaves=None,\n",
    "              min_child_weight=None, monotone_constraints=None,\n",
    "              n_estimators=20, n_jobs=12, num_parallel_tree=None,\n",
    "              predictor=None, random_state=None)           \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "rand_seed = 100\n",
    "n_repeat = 100\n",
    "folder_type='merged'\n",
    "\n",
    "tag = \"XGB\"\n",
    "model_type = models[tag]\n",
    "model_name = model_type.__str__().split('(')[0]\n",
    "\n",
    "print(f\"{tag} training for {n_repeat} runs\")\n",
    "\n",
    "if model_name.__contains__(\"XGBClassifier\"):\n",
    "    model_name = \"XGBClassifier\"\n",
    "\n",
    "dirmaker(f'./model-logs/training/{folder_type}/{xdate}')\n",
    "file_name = open(\n",
    "    f\"./model-logs/training/{folder_type}/{xdate}/{model_name}_{folder_type}_{n_repeat}_{xdate}_{rand_seed}.txt\", \"w+\")\n",
    "\n",
    "train_xgb(model_type, des_df_merged, nondes_df_merged, \n",
    "file_name=file_name, folder_type=folder_type, num=n_repeat, rand_seed=rand_seed, features=features_merged)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# XGBRF\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"xtick.labelsize\": 14,\n",
    "    \"ytick.labelsize\": 14,\n",
    "    'font.size': 18,\n",
    "    'axes.labelweight': 'bold',\n",
    "    'figure.dpi': 350.0,\n",
    "    'axes.linewidth':2.0,\n",
    "})\n",
    "\n",
    "models = {    \n",
    "    \"XGBRF-old\": XGBRFClassifier(base_score=None, booster=None, callbacks=None,\n",
    "                colsample_bylevel=None, colsample_bytree=0.5,\n",
    "                early_stopping_rounds=None, enable_categorical=False,\n",
    "                eval_metric='auc', feature_types=None, gamma=None, gpu_id=None,\n",
    "                grow_policy=None, importance_type=None,\n",
    "                interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
    "                max_cat_threshold=None, max_cat_to_onehot=None,\n",
    "                max_delta_step=None, max_depth=2, max_leaves=None,\n",
    "                min_child_weight=None, monotone_constraints=None,\n",
    "                n_estimators=100, n_jobs=12, num_parallel_tree=None,\n",
    "                objective='binary:logistic', predictor=None, random_state=None),\n",
    "    \"XGBRF\": XGBRFClassifier(base_score=None, booster=None, callbacks=None,\n",
    "                colsample_bylevel=None, colsample_bytree=0.5,\n",
    "                early_stopping_rounds=None, enable_categorical=False,\n",
    "                eval_metric='auc', feature_types=None, gamma=None, gpu_id=None,\n",
    "                grow_policy=None, importance_type=None,\n",
    "                interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
    "                max_cat_threshold=None, max_cat_to_onehot=None,\n",
    "                max_delta_step=None, max_depth=2, max_leaves=None,\n",
    "                min_child_weight=None, monotone_constraints=None,\n",
    "                n_estimators=30, n_jobs=12, num_parallel_tree=None,\n",
    "                objective='binary:logistic', predictor=None, random_state=None) \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "rand_seed = 100\n",
    "n_repeat = 100\n",
    "folder_type='merged'\n",
    "\n",
    "tag = \"XGBRF\"\n",
    "model_type = models[tag]\n",
    "model_name = model_type.__str__().split('(')[0]\n",
    "\n",
    "print(f\"{tag} training for {n_repeat} runs\")\n",
    "\n",
    "dirmaker(f'./model-logs/training/{folder_type}/{xdate}')\n",
    "file_name = open(\n",
    "    f\"./model-logs/training/{folder_type}/{xdate}/{model_name}_{folder_type}_{n_repeat}_{xdate}_{rand_seed}.txt\", \"w+\")\n",
    "\n",
    "train_xgb(model_type, des_df_merged, nondes_df_merged, \n",
    "file_name=file_name, folder_type=folder_type, num=n_repeat, rand_seed=rand_seed, features=features_merged)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGB and XGBRF eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBClassifier\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"xtick.labelsize\": 14,\n",
    "    \"ytick.labelsize\": 14,\n",
    "    'font.size': 18,\n",
    "    'axes.labelweight': 'bold',\n",
    "    'figure.dpi': 350.0,\n",
    "    'axes.linewidth':2.0,\n",
    "})\n",
    "\n",
    "models = {    \n",
    "    \"XGB\": XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
    "              colsample_bylevel=None, colsample_bynode=None,\n",
    "              colsample_bytree=0.5, \n",
    "              enable_categorical=False, eval_metric='auc', feature_types=None,\n",
    "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
    "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
    "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
    "              max_delta_step=None, max_depth=2, max_leaves=None,\n",
    "              min_child_weight=None, monotone_constraints=None,\n",
    "              n_estimators=20, n_jobs=12, num_parallel_tree=None,\n",
    "              predictor=None, random_state=None),\n",
    "     \"XGBRF\": XGBRFClassifier(base_score=None, booster=None, callbacks=None,\n",
    "                colsample_bylevel=None, colsample_bytree=0.5,\n",
    "                early_stopping_rounds=None, enable_categorical=False,\n",
    "                eval_metric='auc', feature_types=None, gamma=None, gpu_id=None,\n",
    "                grow_policy=None, importance_type=None,\n",
    "                interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
    "                max_cat_threshold=None, max_cat_to_onehot=None,\n",
    "                max_delta_step=None, max_depth=2, max_leaves=None,\n",
    "                min_child_weight=None, monotone_constraints=None,\n",
    "                n_estimators=30, n_jobs=12, num_parallel_tree=None,\n",
    "                objective='binary:logistic', predictor=None, random_state=None) \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "rand_seed = 100\n",
    "n_repeat = 100\n",
    "folder_type='merged'\n",
    "\n",
    "tag = \"XGBRF\"\n",
    "model_type = models[tag]\n",
    "model_name = model_type.__str__().split('(')[0]\n",
    "\n",
    "print(f\"{tag} training for {n_repeat} runs\")\n",
    "\n",
    "if model_name.__contains__(\"XGBClassifier\"):\n",
    "    model_name = \"XGBClassifier\"\n",
    "\n",
    "dirmaker(f'./model-logs/training/{folder_type}/{xdate}')\n",
    "file_name = open(\n",
    "    f\"./model-logs/training/{folder_type}/{xdate}/{model_name}_eval_{folder_type}_{n_repeat}_{xdate}_{rand_seed}.txt\", \"w+\")\n",
    "\n",
    "# Use this for getting validation metrics plotted alongside training metrics\n",
    "train_xgb_eval(model_type, des_df_merged, nondes_df_merged, \n",
    "file_name=file_name, folder_type=folder_type, num=n_repeat, rand_seed=rand_seed, features=features_merged)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost with GridSearchCV\n",
    "This uses a for-loop to get more repetitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "import multiprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"xtick.labelsize\": 14,\n",
    "    \"ytick.labelsize\": 14,\n",
    "    'font.size': 18,\n",
    "    'axes.labelweight': 'bold',\n",
    "    'figure.dpi': 150.0,\n",
    "})  # 'figure.figsize': [14.0, 10.0],\n",
    "\n",
    "\n",
    "print(\"Parallel Parameter optimization\")\n",
    "xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "xgb_roc_auc_grid = []\n",
    "coeff_xgb_grid = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "num = 10\n",
    "file_merged_xgb_grid = open(\n",
    "    f\"./model-logs/XGB_merged_gridsearch_{num}_{xdate}.txt\", \"w+\")\n",
    "\n",
    "xgb_class_mergedgrid = XGBClassifier(\n",
    "    tree_method='hist',\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='auc',\n",
    "    objective='binary:logistic',\n",
    "    n_jobs=multiprocessing.cpu_count() // 2)  # tree_method='gpu_hist', enable_categorical=True, predictor='gpu_predictor',\n",
    "\n",
    "p_grid = {'max_depth': [2, 4, 6, 8, 10],\n",
    "          'n_estimators': [10, 20, 30, 40, 50, 100],\n",
    "          'learning_rate': [0.01, 0.1],\n",
    "          'colsample_bytree': [0.1, 0.2, 0.3],\n",
    "          }\n",
    "\n",
    "for x in trange(num):\n",
    "    X_train_merged, y_train_merged, X_test_merged, y_test_merged = df_generator(\n",
    "        des_df_merged, nondes_df_merged, test_sample_size=8, nondes_batch_size=38)\n",
    "    # xgb_class_merged_grid = XGBClassifier(\n",
    "    #     tree_method='hist',\n",
    "    #     use_label_encoder=False,\n",
    "    #     eval_metric='auc',\n",
    "    #     objective='binary:logistic',\n",
    "    #     n_jobs=multiprocessing.cpu_count() // 2)\n",
    "    xgb_clf = GridSearchCV(xgb_class_mergedgrid,\n",
    "                           param_grid=p_grid, verbose=1, scoring='roc_auc')\n",
    "\n",
    "    xgb_class_merged_grid = xgb_clf.fit(X_train_merged, y_train_merged, eval_set=[(\n",
    "        X_test_merged, y_test_merged)], verbose=False, early_stopping_rounds=50)  # , early_stopping_rounds=50\n",
    "\n",
    "    print('Best score', xgb_class_merged_grid.best_score_,\n",
    "          file=file_merged_xgb_grid)\n",
    "    print('Best params', xgb_class_merged_grid.best_params_,\n",
    "          file=file_merged_xgb_grid)\n",
    "    y_pred_merged_xgb = xgb_class_merged_grid.best_estimator_.predict(\n",
    "        X_test_merged)\n",
    "    target_names = ['non-DES', 'DES']  # non-DES is 0, DES is 1\n",
    "    print(metrics.classification_report(y_test_merged, y_pred_merged_xgb,\n",
    "          target_names=target_names), file=file_merged_xgb_grid)\n",
    "    roc_auc_xgb = metrics.roc_auc_score(y_test_merged, y_pred_merged_xgb)\n",
    "    print(f\"roc_auc_score: {roc_auc_xgb}\", file=file_merged_xgb_grid)\n",
    "    xgb_roc_auc_grid.append(roc_auc_xgb)\n",
    "    print(xgb_class_merged_grid.best_estimator_.feature_importances_,\n",
    "          file=file_merged_xgb_grid)\n",
    "    # print(f\"intercept: {xgb_class_merged_grid.intercept_}\", file=file_merged_xgb_grid)\n",
    "\n",
    "    xgb_class_merged_grid_feature_df = pd.DataFrame(\n",
    "        {'Importance': xgb_class_merged_grid.best_estimator_.feature_importances_, 'Features_merged': features_merged})\n",
    "    max_coeff_index = list(xgb_class_merged_grid.best_estimator_.feature_importances_).index(\n",
    "        xgb_class_merged_grid.best_estimator_.feature_importances_.max())\n",
    "    print(\n",
    "        f'max feature: {xgb_class_merged_grid.best_estimator_.feature_importances_.max()} at index {max_coeff_index} [{features_merged[max_coeff_index]}]', file=file_merged_xgb_grid)\n",
    "    coeff_xgb_grid[max_coeff_index] += 1\n",
    "    print('\\n', file=file_merged_xgb_grid)\n",
    "    print(xgb_class_merged_grid_feature_df, file=file_merged_xgb_grid)\n",
    "    print('\\n'*2, file=file_merged_xgb_grid)\n",
    "\n",
    "\n",
    "# plotting roc_auc score\n",
    "fig = plt.figure()\n",
    "fig_ax = fig.add_subplot(1, 1, 1)\n",
    "fig.set_size_inches(12, 8, forward=True)\n",
    "fig_ax.set_xlabel(\"Number of runs\")  # , fontsize=14, weight='bold')\n",
    "fig_ax.set_ylabel(\"ROC-AUC score\")  # , fontsize=14, weight='bold')\n",
    "fig_ax.set_ylim(0, 1.0)\n",
    "fig_ax.set_xlim(0, num+2)\n",
    "plt.title('XGBoost hbond number + lifetime', fontsize=12, weight='bold')\n",
    "\n",
    "roc = [z for z in range(1, num+1)]\n",
    "print(\n",
    "    f\"roc_auc scores on test set: {xgb_roc_auc_grid}\", file=file_merged_xgb_grid)\n",
    "print(\n",
    "    f\"Average roc_auc scores on test set: {np.average(xgb_roc_auc_grid)}\", file=file_merged_xgb_grid)\n",
    "print(\n",
    "    f\"std dev of roc_auc scores on test set: {np.std(xgb_roc_auc_grid)}\", file=file_merged_xgb_grid)\n",
    "print(\n",
    "    f\"Best roc_auc score on test set: {max(xgb_roc_auc_grid)} at index {xgb_roc_auc_grid.index(max(xgb_roc_auc_grid)) + 1}\", file=file_merged_xgb_grid)\n",
    "print(\n",
    "    f\"Best model's roc_auc score: {xgb_class_merged_grid.best_estimator_.best_score}\", file=file_merged_xgb_grid)\n",
    "print(\n",
    "    f\"Best model's iteration: {xgb_class_merged_grid.best_estimator_.best_iteration}\", file=file_merged_xgb_grid)\n",
    "print(\n",
    "    f\"model's eval_results: {xgb_class_merged_grid.best_estimator_.evals_result()}\", file=file_merged_xgb_grid)\n",
    "print('\\n', file=file_merged_xgb_grid)\n",
    "coeff_df_xgb = pd.DataFrame(\n",
    "    {'Top Features_merged': coeff_xgb_grid, 'Features_merged': features_merged})\n",
    "print(f\"Coefficients: {coeff_df_xgb}\", file=file_merged_xgb_grid)\n",
    "fig_ax.plot(roc, xgb_roc_auc_grid, '-o', linewidth=2, markersize=8.0, label=f\"avg roc_auc: {round(np.average(xgb_roc_auc_grid),2)} \\n \\\n",
    "std roc_auc : {round(np.std(xgb_roc_auc_grid),2)}\")\n",
    "plt.legend(loc='upper left')\n",
    "file_merged_xgb_grid.close()\n",
    "dirmaker(f'./plots/roc-auc/merged/{xdate}')\n",
    "# fig.savefig(f'plots/roc-auc/merged/XGB_merged_gridsearch_{num}-{xdate}.png', dpi=500,facecolor='white', bbox_inches='tight')\n",
    "xgb.plot_importance(\n",
    "    xgb_class_merged_grid.best_estimator_).set_yticklabels(features_merged)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBClassifier().get_params().keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_class_merged_grid.best_params_\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost GridSearchCV with RepeatedKFold\n",
    "This obviates the need for using for-loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "import multiprocessing\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold, RepeatedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"xtick.labelsize\": 14,\n",
    "    \"ytick.labelsize\": 14,\n",
    "    'font.size': 18,\n",
    "    'axes.labelweight': 'bold',\n",
    "    'figure.dpi': 150.0,\n",
    "})  # 'figure.figsize': [14.0, 10.0],\n",
    "\n",
    "\n",
    "print(\"Parallel Parameter optimization\")\n",
    "xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "xgb_roc_auc_repeatK = []\n",
    "coeff_xgb_repeatK = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "# num = 10\n",
    "cv = RepeatedKFold(n_splits=5, n_repeats=10, random_state=1000)\n",
    "\n",
    "dirmaker(f'./model-logs/merged/{xdate}')\n",
    "file_merged_xgb_repeatK = open(\n",
    "    f\"./model-logs/merged/{xdate}/XGB_merged_repeatKFold_{xdate}.txt\", \"w+\")\n",
    "\n",
    "xgb_class_mergedrepeatK = XGBClassifier(\n",
    "    tree_method='hist',\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='auc',\n",
    "    objective='binary:logistic',\n",
    "    n_jobs=multiprocessing.cpu_count() // 2)  # tree_method='gpu_hist', enable_categorical=True, predictor='gpu_predictor',\n",
    "\n",
    "p_repeatK = {'max_depth': [2, 4, 6, 8, 10],\n",
    "             'n_estimators': [10, 20, 30, 40, 50, 100],\n",
    "             'learning_rate': [0.01, 0.1],\n",
    "             # ,0.6,0.7,0.8,0.9,1.0\n",
    "             'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "             }\n",
    "\n",
    "\n",
    "X_train_merged, y_train_merged, X_test_merged, y_test_merged = df_generator(\n",
    "    des_df_merged, nondes_df_merged, test_sample_size=8, nondes_batch_size=38)\n",
    "\n",
    "xgb_clf = GridSearchCV(xgb_class_mergedrepeatK,\n",
    "                       param_grid=p_repeatK, verbose=1, scoring='roc_auc', cv=cv)\n",
    "\n",
    "xgb_class_merged_repeatK = xgb_clf.fit(X_train_merged, y_train_merged, eval_set=[(X_train_merged, y_train_merged), (\n",
    "    X_test_merged, y_test_merged)], verbose=False, early_stopping_rounds=50)  # , early_stopping_rounds=50\n",
    "\n",
    "print('Best score', xgb_class_merged_repeatK.best_score_,\n",
    "      file=file_merged_xgb_repeatK)\n",
    "print('Best params', xgb_class_merged_repeatK.best_params_,\n",
    "      file=file_merged_xgb_repeatK)\n",
    "y_pred_merged_xgb = xgb_class_merged_repeatK.best_estimator_.predict(\n",
    "    X_test_merged)\n",
    "target_names = ['non-DES', 'DES']  # non-DES is 0, DES is 1\n",
    "print(metrics.classification_report(y_test_merged, y_pred_merged_xgb,\n",
    "      target_names=target_names), file=file_merged_xgb_repeatK)\n",
    "roc_auc_xgb = metrics.roc_auc_score(y_test_merged, y_pred_merged_xgb)\n",
    "print(f\"roc_auc_score: {roc_auc_xgb}\", file=file_merged_xgb_repeatK)\n",
    "xgb_roc_auc_repeatK.append(roc_auc_xgb)\n",
    "print(xgb_class_merged_repeatK.best_estimator_.feature_importances_,\n",
    "      file=file_merged_xgb_repeatK)\n",
    "# print(f\"intercept: {xgb_class_merged_repeatK.intercept_}\", file=file_merged_xgb_repeatK)\n",
    "\n",
    "xgb_class_merged_repeatK_feature_df = pd.DataFrame(\n",
    "    {'Importance': xgb_class_merged_repeatK.best_estimator_.feature_importances_, 'Features_merged': features_merged})\n",
    "max_coeff_index = list(xgb_class_merged_repeatK.best_estimator_.feature_importances_).index(\n",
    "    xgb_class_merged_repeatK.best_estimator_.feature_importances_.max())\n",
    "print(\n",
    "    f'max feature: {xgb_class_merged_repeatK.best_estimator_.feature_importances_.max()} at index {max_coeff_index} [{features_merged[max_coeff_index]}]', file=file_merged_xgb_repeatK)\n",
    "coeff_xgb_repeatK[max_coeff_index] += 1\n",
    "print('\\n', file=file_merged_xgb_repeatK)\n",
    "print(xgb_class_merged_repeatK_feature_df, file=file_merged_xgb_repeatK)\n",
    "print('\\n'*2, file=file_merged_xgb_repeatK)\n",
    "\n",
    "# roc = [ z for z in range(1,num+1)]\n",
    "print(\n",
    "    f\"roc_auc scores on test set: {xgb_roc_auc_repeatK}\", file=file_merged_xgb_repeatK)\n",
    "print(\n",
    "    f\"Average roc_auc scores on test set: {np.average(xgb_roc_auc_repeatK)}\", file=file_merged_xgb_repeatK)\n",
    "print(\n",
    "    f\"std dev of roc_auc scores on test set: {np.std(xgb_roc_auc_repeatK)}\", file=file_merged_xgb_repeatK)\n",
    "print(\n",
    "    f\"Best roc_auc score on test set: {max(xgb_roc_auc_repeatK)} at index {xgb_roc_auc_repeatK.index(max(xgb_roc_auc_repeatK)) + 1}\", file=file_merged_xgb_repeatK)\n",
    "print(\n",
    "    f\"Best model's roc_auc score from early stopping: {xgb_class_merged_repeatK.best_estimator_.best_score}\", file=file_merged_xgb_repeatK)\n",
    "print(\n",
    "    f\"Best model's iteration from early stopping: {xgb_class_merged_repeatK.best_estimator_.best_iteration}\", file=file_merged_xgb_repeatK)\n",
    "# print(f\"model's eval_results: {xgb_class_merged_repeatK.best_estimator_.evals_result()}\", file=file_merged_xgb_repeatK)\n",
    "train_eval = list(xgb_class_merged_repeatK.best_estimator_.evals_result()[\n",
    "                  'validation_0'].items())\n",
    "print(\n",
    "    f'Number of training auc scores: {len(train_eval[0][1])}', file=file_merged_xgb_repeatK)\n",
    "print(\n",
    "    f'auc scores of training set: {train_eval[0][1]}', file=file_merged_xgb_repeatK)\n",
    "print(f'Average and std-dev of auc scores of training set: {round(np.average(train_eval[0][1]),2)}, \\\n",
    "{round(np.std(train_eval[0][1]),2)} \\n', file=file_merged_xgb_repeatK)\n",
    "\n",
    "val_eval = list(xgb_class_merged_repeatK.best_estimator_.evals_result()[\n",
    "                'validation_1'].items())\n",
    "print(\n",
    "    f'Number of testing auc scores: {len(val_eval[0][1])}', file=file_merged_xgb_repeatK)\n",
    "print(\n",
    "    f'auc scores of testing set: {val_eval[0][1]}', file=file_merged_xgb_repeatK)\n",
    "print(f'Average and std-dev of auc scores of testing set: {round(np.average(val_eval[0][1]),2)}, \\\n",
    "{round(np.std(val_eval[0][1]),2)} \\n', file=file_merged_xgb_repeatK)\n",
    "\n",
    "print('\\n', file=file_merged_xgb_repeatK)\n",
    "coeff_df_xgb = pd.DataFrame(\n",
    "    {'Top Features_merged': coeff_xgb_repeatK, 'Features_merged': features_merged})\n",
    "print(f\"Coefficients: {coeff_df_xgb} \\n\", file=file_merged_xgb_repeatK)\n",
    "\n",
    "print(f'Best estimator: {xgb_class_merged_repeatK.best_estimator_} \\n',\n",
    "      file=file_merged_xgb_repeatK)\n",
    "print(f'Best params: {xgb_class_merged_repeatK.best_params_} \\n',\n",
    "      file=file_merged_xgb_repeatK)\n",
    "print(\n",
    "    f\"Best estimator's score from early stopping: {xgb_class_merged_repeatK.best_estimator_.best_score} \\n\", file=file_merged_xgb_repeatK)\n",
    "# plotting roc_auc score\n",
    "fig = plt.figure()\n",
    "fig_ax = fig.add_subplot(1, 1, 1)\n",
    "fig.set_size_inches(12, 8, forward=True)\n",
    "fig_ax.set_xlabel(\"Number of runs\")\n",
    "fig_ax.set_ylabel(\"ROC-AUC score\")\n",
    "fig_ax.set_ylim(0, 1.1)\n",
    "plt.title('XGBoost (Repeated KFold) hbond number + lifetime',\n",
    "          fontsize=12, weight='bold')\n",
    "\n",
    "fig_ax.plot(range(1, len(train_eval[0][1])+1), train_eval[0][1], '-o', linewidth=2, markersize=8.0, label=f\"avg training roc_auc: {round(np.average(train_eval[0][1]),2)}\\n \\\n",
    "std training roc_auc : {round(np.std(train_eval[0][1]),2)}\")\n",
    "\n",
    "fig_ax.plot(range(1, len(val_eval[0][1])+1), val_eval[0][1], '-o', linewidth=2, markersize=8.0, label=f\"avg testing roc_auc: {round(np.average(val_eval[0][1]),2)}\\n \\\n",
    "std testing roc_auc : {round(np.std(val_eval[0][1]),2)}\")\n",
    "\n",
    "plt.legend(loc='best')\n",
    "file_merged_xgb_repeatK.close()\n",
    "dirmaker(f'./plots/roc-auc/merged/{xdate}')\n",
    "fig.savefig(f'plots/roc-auc/merged/{xdate}/XGB_merged_repeatKsearch-{xdate}.png',\n",
    "            dpi=500, facecolor='white', bbox_inches='tight')\n",
    "\n",
    "xgb.plot_importance(\n",
    "    xgb_class_merged_repeatK.best_estimator_).set_yticklabels(features_merged)\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost GridSearchCV with Stratified RepeatedKFold\n",
    "This obviates the need for using for-loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "import multiprocessing\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold, RepeatedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"xtick.labelsize\": 14,\n",
    "    \"ytick.labelsize\": 14,\n",
    "    'font.size': 18,\n",
    "    'axes.labelweight': 'bold',\n",
    "    'figure.dpi': 150.0,\n",
    "})  # 'figure.figsize': [14.0, 10.0],\n",
    "\n",
    "\n",
    "print(\"Parallel Parameter optimization\")\n",
    "xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "xgb_roc_auc_stratK = []\n",
    "coeff_xgb_stratK = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "# num = 10\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=1000)\n",
    "\n",
    "dirmaker(f'./model-logs/merged/{xdate}')\n",
    "file_merged_xgb_stratK = open(\n",
    "    f\"./model-logs/merged/{xdate}/XGB_merged_stratKFold_{xdate}.txt\", \"w+\")\n",
    "\n",
    "xgb_class_mergedstratK = XGBClassifier(\n",
    "    tree_method='hist',\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='auc',\n",
    "    objective='binary:logistic',\n",
    "    n_jobs=multiprocessing.cpu_count() // 2)  # tree_method='gpu_hist', enable_categorical=True, predictor='gpu_predictor',\n",
    "\n",
    "p_stratK = {'max_depth': [2, 4, 6, 8, 10],\n",
    "            'n_estimators': [10, 20, 30, 40, 50, 100],\n",
    "            'learning_rate': [0.01, 0.1],\n",
    "            # ,0.6,0.7,0.8,0.9,1.0\n",
    "            'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "            }\n",
    "\n",
    "\n",
    "X_train_merged, y_train_merged, X_test_merged, y_test_merged = df_generator(\n",
    "    des_df_merged, nondes_df_merged, test_sample_size=8, nondes_batch_size=38)\n",
    "\n",
    "xgb_clf = GridSearchCV(xgb_class_mergedstratK,\n",
    "                       param_grid=p_stratK, verbose=1, scoring='roc_auc', cv=cv)\n",
    "\n",
    "xgb_class_merged_stratK = xgb_clf.fit(X_train_merged, y_train_merged, eval_set=[(X_train_merged, y_train_merged), (\n",
    "    X_test_merged, y_test_merged)], verbose=False, early_stopping_rounds=50)  # , early_stopping_rounds=50\n",
    "\n",
    "print('Best score', xgb_class_merged_stratK.best_score_,\n",
    "      file=file_merged_xgb_stratK)\n",
    "print('Best params', xgb_class_merged_stratK.best_params_,\n",
    "      file=file_merged_xgb_stratK)\n",
    "y_pred_merged_xgb = xgb_class_merged_stratK.best_estimator_.predict(\n",
    "    X_test_merged)\n",
    "target_names = ['non-DES', 'DES']  # non-DES is 0, DES is 1\n",
    "print(metrics.classification_report(y_test_merged, y_pred_merged_xgb,\n",
    "      target_names=target_names), file=file_merged_xgb_stratK)\n",
    "roc_auc_xgb = metrics.roc_auc_score(y_test_merged, y_pred_merged_xgb)\n",
    "print(f\"roc_auc_score: {roc_auc_xgb}\", file=file_merged_xgb_stratK)\n",
    "xgb_roc_auc_stratK.append(roc_auc_xgb)\n",
    "print(xgb_class_merged_stratK.best_estimator_.feature_importances_,\n",
    "      file=file_merged_xgb_stratK)\n",
    "# print(f\"intercept: {xgb_class_merged_stratK.intercept_}\", file=file_merged_xgb_stratK)\n",
    "\n",
    "xgb_class_merged_stratK_feature_df = pd.DataFrame(\n",
    "    {'Importance': xgb_class_merged_stratK.best_estimator_.feature_importances_, 'Features_merged': features_merged})\n",
    "max_coeff_index = list(xgb_class_merged_stratK.best_estimator_.feature_importances_).index(\n",
    "    xgb_class_merged_stratK.best_estimator_.feature_importances_.max())\n",
    "print(\n",
    "    f'max feature: {xgb_class_merged_stratK.best_estimator_.feature_importances_.max()} at index {max_coeff_index} [{features_merged[max_coeff_index]}]', file=file_merged_xgb_stratK)\n",
    "coeff_xgb_stratK[max_coeff_index] += 1\n",
    "print('\\n', file=file_merged_xgb_stratK)\n",
    "print(xgb_class_merged_stratK_feature_df, file=file_merged_xgb_stratK)\n",
    "print('\\n'*2, file=file_merged_xgb_stratK)\n",
    "\n",
    "# roc = [ z for z in range(1,num+1)]\n",
    "print(\n",
    "    f\"roc_auc scores on test set: {xgb_roc_auc_stratK}\", file=file_merged_xgb_stratK)\n",
    "print(\n",
    "    f\"Average roc_auc scores on test set: {np.average(xgb_roc_auc_stratK)}\", file=file_merged_xgb_stratK)\n",
    "print(\n",
    "    f\"std dev of roc_auc scores on test set: {np.std(xgb_roc_auc_stratK)}\", file=file_merged_xgb_stratK)\n",
    "print(\n",
    "    f\"Best roc_auc score on test set: {max(xgb_roc_auc_stratK)} at index {xgb_roc_auc_stratK.index(max(xgb_roc_auc_stratK)) + 1}\", file=file_merged_xgb_stratK)\n",
    "print(\n",
    "    f\"Best model's roc_auc score from early stopping: {xgb_class_merged_stratK.best_estimator_.best_score}\", file=file_merged_xgb_stratK)\n",
    "print(\n",
    "    f\"Best model's iteration from early stopping: {xgb_class_merged_stratK.best_estimator_.best_iteration} \\n\", file=file_merged_xgb_stratK)\n",
    "# print(f\"model's eval_results: {xgb_class_merged_stratK.best_estimator_.evals_result()}\", file=file_merged_xgb_stratK)\n",
    "train_eval = list(xgb_class_merged_stratK.best_estimator_.evals_result()[\n",
    "                  'validation_0'].items())\n",
    "print(\n",
    "    f'Number of training auc scores: {len(train_eval[0][1])}', file=file_merged_xgb_stratK)\n",
    "print(\n",
    "    f'auc scores of training set: {train_eval[0][1]}', file=file_merged_xgb_stratK)\n",
    "print(f'Average and std-dev of auc scores of training set: {round(np.average(train_eval[0][1]),2)}, \\\n",
    "{round(np.std(train_eval[0][1]),2)} \\n', file=file_merged_xgb_stratK)\n",
    "\n",
    "val_eval = list(xgb_class_merged_stratK.best_estimator_.evals_result()[\n",
    "                'validation_1'].items())\n",
    "print(\n",
    "    f'Number of testing auc scores: {len(val_eval[0][1])}', file=file_merged_xgb_stratK)\n",
    "print(\n",
    "    f'auc scores of testing set: {val_eval[0][1]}', file=file_merged_xgb_stratK)\n",
    "print(f'Average and std-dev of auc scores of testing set: {round(np.average(val_eval[0][1]),2)}, \\\n",
    "{round(np.std(val_eval[0][1]),2)} \\n', file=file_merged_xgb_stratK)\n",
    "\n",
    "print('\\n', file=file_merged_xgb_stratK)\n",
    "coeff_df_xgb = pd.DataFrame(\n",
    "    {'Top Features_merged': coeff_xgb_stratK, 'Features_merged': features_merged})\n",
    "print(f\"Coefficients: {coeff_df_xgb}\", file=file_merged_xgb_stratK)\n",
    "\n",
    "print(f'Best estimator: {xgb_class_merged_stratK.best_estimator_} \\n',\n",
    "      file=file_merged_xgb_stratK)\n",
    "print(f'Best params: {xgb_class_merged_stratK.best_params_} \\n',\n",
    "      file=file_merged_xgb_stratK)\n",
    "print(\n",
    "    f\"Best estimator's score from early stopping: {xgb_class_merged_stratK.best_estimator_.best_score} \\n\", file=file_merged_xgb_stratK)\n",
    "\n",
    "# plotting roc_auc score\n",
    "fig = plt.figure()\n",
    "fig_ax = fig.add_subplot(1, 1, 1)\n",
    "fig.set_size_inches(12, 8, forward=True)\n",
    "fig_ax.set_xlabel(\"Number of runs\")  # , fontsize=14, weight='bold')\n",
    "fig_ax.set_ylabel(\"ROC-AUC score\")  # , fontsize=14, weight='bold')\n",
    "fig_ax.set_ylim(0, 1.1)\n",
    "# fig_ax.set_xlim(0, num+2)\n",
    "plt.title('XGBoost hbond number + lifetime', fontsize=12, weight='bold')\n",
    "fig_ax.plot(range(1, len(train_eval[0][1])+1), train_eval[0][1], '-o', linewidth=2, markersize=8.0, label=f\"avg training roc_auc: {round(np.average(train_eval[0][1]),2)}\\n \\\n",
    "std training roc_auc : {round(np.std(train_eval[0][1]),2)}\")\n",
    "\n",
    "fig_ax.plot(range(1, len(val_eval[0][1])+1), val_eval[0][1], '-o', linewidth=2, markersize=8.0, label=f\"avg testing roc_auc: {round(np.average(val_eval[0][1]),2)}\\n \\\n",
    "std testing roc_auc : {round(np.std(val_eval[0][1]),2)}\")\n",
    "\n",
    "plt.legend(loc='best')\n",
    "file_merged_xgb_stratK.close()\n",
    "dirmaker(f'./plots/roc-auc/merged/{xdate}')\n",
    "fig.savefig(f'plots/roc-auc/merged/{xdate}/XGB_merged_stratKsearch-{xdate}.png',\n",
    "            dpi=500, facecolor='white', bbox_inches='tight')\n",
    "\n",
    "xgb.plot_importance(\n",
    "    xgb_class_merged_stratK.best_estimator_).set_yticklabels(features_merged)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "des_hlife_sum = des_df_hlife.describe()\n",
    "des_hnum_sum = des_df_hnum.describe()\n",
    "nondes_hlife_sum = nondes_df_hlife.describe()\n",
    "nondes_hnum_sum = nondes_df_hnum.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "des_hlife_sum\n",
    "# des_hnum_sum\n",
    "# nondes_hlife_sum\n",
    "# nondes_hnum_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # All tags\n",
    "# taggsss = list(nondes_df_hnum.columns)\n",
    "# taggsss.remove('output')\n",
    "# taggsss\n",
    "\n",
    "# # Excluding the ratios\n",
    "# taggsss = list(nondes_df_hnum.columns)\n",
    "# taggsss.remove('output')\n",
    "# taggsss.remove('A-A/B-B')\n",
    "# taggsss.remove('A-B/(A-A + B-B)')\n",
    "# taggsss\n",
    "\n",
    "# Excluding all but the ratios\n",
    "taggsss = list(nondes_df_hnum.columns)\n",
    "taggsss.remove('output')\n",
    "taggsss.remove('A-A')\n",
    "taggsss.remove('B-B')\n",
    "taggsss.remove('A-B')\n",
    "# taggsss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_boxplot(df, list_of_tags):\n",
    "    taggss = list_of_tags\n",
    "    list_baba = []\n",
    "\n",
    "    for i in range(len(taggss)):\n",
    "        boxplot_dict = {\n",
    "            'label' : taggss[i],  # hbond features\n",
    "            'whislo': df[taggss[i]].loc['min'],    # Bottom whisker position\n",
    "            'q1'    : df[taggss[i]].loc['25%'],    # First quartile (25th percentile)\n",
    "            'med'   : df[taggss[i]].loc['50%'],    # Median         (50th percentile)\n",
    "            'q3'    : df[taggss[i]].loc['75%'],    # Third quartile (75th percentile)\n",
    "            'whishi': df[taggss[i]].loc['max'],    # Top whisker position\n",
    "            'fliers': []        # Outliers\n",
    "        }\n",
    "\n",
    "        list_baba.append(boxplot_dict)\n",
    "    \n",
    "    return list_baba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deshnum_list = df_boxplot(des_hnum_sum, taggsss)\n",
    "nondeshnum_list = df_boxplot(nondes_hnum_sum, taggsss)\n",
    "deshlife_list = df_boxplot(des_hlife_sum, taggsss)\n",
    "nondeshlife_list = df_boxplot(nondes_hlife_sum, taggsss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def boxplotter(df_list, title_tag, fig_title, data_type='hnum'):\n",
    "    xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "\n",
    "    fig_1, ax_1 = plt.subplots(1,1)\n",
    "    fig_1.set_size_inches(12,10, forward=True)  \n",
    "\n",
    "    ax_1.bxp(df_list, showfliers=False, boxprops=dict(linestyle='-', linewidth=3.5),\n",
    "    flierprops=dict(linestyle='-', linewidth=5.5),\n",
    "                medianprops=dict(linestyle='-', linewidth=3.5),\n",
    "                whiskerprops=dict(linestyle='-', linewidth=3.5),\n",
    "                capprops=dict(linestyle='-', linewidth=3.5))\n",
    "    \n",
    "    if data_type=='hnum':\n",
    "        upper=105\n",
    "    elif data_type=='hlife':\n",
    "        upper=10\n",
    "    else:\n",
    "        upper=105\n",
    "        \n",
    "                        \n",
    "    ax_1.set_ylim(bottom=0, top=upper)\n",
    "    title = title_tag\n",
    "    # ax_1.set_title(f'{title_tag}', weight='bold')\n",
    "    dirmaker(f'./plots/boxplots/{xdate}')\n",
    "    # plt.savefig(f\"./plots/boxplots/{xdate}/{fig_title}_ratios_{xdate}.tiff\", facecolor=\"white\", bbox_inches=\"tight\", dpi=350)\n",
    "    plt.savefig(f\"./plots/boxplots/{xdate}/{fig_title}_{xdate}.tiff\", facecolor=\"white\", bbox_inches=\"tight\", dpi=350)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def boxplotter_ratios(df_list, title_tag, fig_title, data_type='hnum'):\n",
    "    xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "\n",
    "    fig_1, ax_1 = plt.subplots(1,1)\n",
    "    fig_1.set_size_inches(12,10, forward=True)  \n",
    "\n",
    "    ax_1.bxp(df_list, showfliers=False, boxprops=dict(linestyle='-', linewidth=3.5),\n",
    "    flierprops=dict(linestyle='-', linewidth=5.5),\n",
    "                medianprops=dict(linestyle='-', linewidth=3.5),\n",
    "                whiskerprops=dict(linestyle='-', linewidth=3.5),\n",
    "                capprops=dict(linestyle='-', linewidth=3.5))\n",
    "    \n",
    "    if data_type=='hnum':\n",
    "        upper=60\n",
    "    elif data_type=='hlife':\n",
    "        upper=31\n",
    "    else:\n",
    "        upper=105\n",
    "        \n",
    "                        \n",
    "    ax_1.set_ylim(bottom=0, top=upper)\n",
    "    title = title_tag\n",
    "    # ax_1.set_title(f'{title_tag}', weight='bold')\n",
    "    dirmaker(f'./plots/boxplots/{xdate}')\n",
    "    plt.savefig(f\"./plots/boxplots/{xdate}/{fig_title}_ratios_{xdate}.tiff\", facecolor=\"white\", bbox_inches=\"tight\", dpi=350)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"xtick.labelsize\": 30,\n",
    "    \"ytick.labelsize\": 30,\n",
    "    'font.size': 34,\n",
    "    'axes.labelweight': 'bold',\n",
    "    'figure.dpi': 350.0,\n",
    "    'axes.linewidth':2.0,\n",
    "})\n",
    "\n",
    "titles = {\n",
    "        'des_hnum':'DES hydrogen bond numbers per molecule',\n",
    "        'nondes_hnum':'non-DES hydrogen bond numbers per molecule',\n",
    "        'des_hlife':'DES hydrogen bond lifetimes per molecule',\n",
    "        'nondes_hlife':'non-DES hydrogen bond lifetimes per molecule',\n",
    "    }\n",
    "\n",
    "df_lists = {\n",
    "        'des_hnum':deshnum_list,\n",
    "        'nondes_hnum':nondeshnum_list,\n",
    "        'des_hlife':deshlife_list,\n",
    "        'nondes_hlife':nondeshlife_list,\n",
    "    }\n",
    "\n",
    "for key in df_lists.keys():\n",
    "    titletag = key\n",
    "    dtype = titletag.split('_')[1]\n",
    "    # boxplotter(df_lists[titletag], titles[titletag], titletag, data_type=dtype)\n",
    "    boxplotter_ratios(df_lists[titletag], titles[titletag], titletag, data_type=dtype)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "des_df_hlife_scatter = des_df_hlife.drop(['A-A', 'B-B', 'A-B', 'output'], axis=1)\n",
    "nondes_df_hlife_scatter = nondes_df_hlife.drop(['A-A', 'B-B', 'A-B', 'output'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nondes_df_hlife_scatter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hlife"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratio of inter-component hlife to intra-component hlife vs ratio of intra-component hlife\n",
    "plt.rcParams.update({\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"xtick.labelsize\": 30,\n",
    "    \"ytick.labelsize\": 30,\n",
    "    'font.size': 34,\n",
    "    'axes.labelweight': 'bold',\n",
    "    'figure.dpi': 150.0,\n",
    "    'axes.linewidth':2.0,\n",
    "})\n",
    "\n",
    "xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "\n",
    "fig_2, ax_2 = plt.subplots(1,1)\n",
    "fig_2.set_size_inches(12,10, forward=True)  \n",
    "\n",
    "ax_2.scatter(des_df_hlife_scatter['A-A/B-B'], des_df_hlife_scatter['A-B/(A-A + B-B)'], s=200, label='DES', edgecolors='black')\n",
    "ax_2.scatter(nondes_df_hlife_scatter['A-A/B-B'], nondes_df_hlife_scatter['A-B/(A-A + B-B)'], s=200, label='non-DES', alpha=0.5, edgecolors='black')\n",
    "ax_2.set_xlabel('\\n A-A/B-B')\n",
    "ax_2.set_ylabel('A-B/(A-A + B-B) \\n')\n",
    "ax_2.set_ylim(top=2.6, bottom=0)\n",
    "ax_2.set_xlim(right=61)\n",
    "ax_2.legend(loc='upper right')\n",
    "dirmaker(f'./plots/scatterplots/{xdate}')\n",
    "plt.savefig(f\"./plots/scatterplots/{xdate}/hlife_ratios_inter_vs_intra_{xdate}_alpha5.tiff\", facecolor=\"white\", bbox_inches=\"tight\", dpi=350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratio of intra-component hlife vs ratio of inter-component hlife to intra-component hlife\n",
    "plt.rcParams.update({\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"xtick.labelsize\": 30,\n",
    "    \"ytick.labelsize\": 30,\n",
    "    'font.size': 34,\n",
    "    'axes.labelweight': 'bold',\n",
    "    'figure.dpi': 150.0,\n",
    "    'axes.linewidth':2.0,\n",
    "})\n",
    "\n",
    "xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "\n",
    "fig_2, ax_2 = plt.subplots(1,1)\n",
    "fig_2.set_size_inches(12,10, forward=True)  \n",
    "\n",
    "ax_2.scatter(des_df_hlife_scatter['A-B/(A-A + B-B)'], des_df_hlife_scatter['A-A/B-B'], s=200, label='DES', edgecolors='black')  # c='blue', \n",
    "ax_2.scatter(nondes_df_hlife_scatter['A-B/(A-A + B-B)'], nondes_df_hlife_scatter['A-A/B-B'], s=200, label='non-DES', alpha=0.5, edgecolors='black')  # c='red', \n",
    "ax_2.set_ylabel('A-A/B-B \\n')\n",
    "ax_2.set_xlabel('\\n A-B/(A-A + B-B) ')\n",
    "ax_2.legend(loc='upper right')\n",
    "\n",
    "ax_2.set_xlim(right=2.6)\n",
    "ax_2.set_ylim(top=61)\n",
    "dirmaker(f'./plots/scatterplots/{xdate}')\n",
    "plt.savefig(f\"./plots/scatterplots/{xdate}/hlife_ratios_intra_vs_inter_{xdate}_alpha5.tiff\", facecolor=\"white\", bbox_inches=\"tight\", dpi=350)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "des_df_hnum_scatter = des_df_hnum.drop(['A-A', 'B-B', 'A-B', 'output'], axis=1)\n",
    "nondes_df_hnum_scatter = nondes_df_hnum.drop(['A-A', 'B-B', 'A-B', 'output'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratio of inter-component hnum to intra-component hnum vs ratio of intra-component hnum\n",
    "plt.rcParams.update({\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"xtick.labelsize\": 30,\n",
    "    \"ytick.labelsize\": 30,\n",
    "    'font.size': 34,\n",
    "    'axes.labelweight': 'bold',\n",
    "    'figure.dpi': 150.0,\n",
    "    'axes.linewidth':2.0,\n",
    "})\n",
    "\n",
    "xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "\n",
    "fig_2, ax_2 = plt.subplots(1,1)\n",
    "fig_2.set_size_inches(12,10, forward=True)  \n",
    "\n",
    "ax_2.scatter(des_df_hnum_scatter['A-A/B-B'], des_df_hnum_scatter['A-B/(A-A + B-B)'], s=200, label='DES', edgecolors='black')\n",
    "ax_2.scatter(nondes_df_hnum_scatter['A-A/B-B'], nondes_df_hnum_scatter['A-B/(A-A + B-B)'], s=200, label='non-DES', alpha=0.5, edgecolors='black')\n",
    "ax_2.set_xlabel('\\n A-A/B-B')\n",
    "ax_2.set_ylabel('A-B/(A-A + B-B) \\n')\n",
    "ax_2.legend(loc='upper right')\n",
    "ax_2.set_ylim(top=2.6, bottom=0)\n",
    "ax_2.set_xlim(right=61)\n",
    "\n",
    "dirmaker(f'./plots/scatterplots/{xdate}')\n",
    "plt.savefig(f\"./plots/scatterplots/{xdate}/hnum_ratios_inter_vs_intra_{xdate}_alpha5.tiff\", facecolor=\"white\", bbox_inches=\"tight\", dpi=350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratio of intra-component hnum vs ratio of inter-component hnum to intra-component hnum\n",
    "plt.rcParams.update({\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"xtick.labelsize\": 30,\n",
    "    \"ytick.labelsize\": 30,\n",
    "    'font.size': 34,\n",
    "    'axes.labelweight': 'bold',\n",
    "    'figure.dpi': 150.0,\n",
    "    'axes.linewidth':2.0,\n",
    "})\n",
    "\n",
    "xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "\n",
    "fig_2, ax_2 = plt.subplots(1,1)\n",
    "fig_2.set_size_inches(12,10, forward=True)  \n",
    "\n",
    "ax_2.scatter(des_df_hnum_scatter['A-B/(A-A + B-B)'], des_df_hnum_scatter['A-A/B-B'], s=200, label='DES', edgecolors='black') # c='blue', \n",
    "ax_2.scatter(nondes_df_hnum_scatter['A-B/(A-A + B-B)'], nondes_df_hnum_scatter['A-A/B-B'], s=200, label='non-DES', alpha=0.5, edgecolors='black') # c='red', \n",
    "ax_2.set_ylabel('A-A/B-B \\n')\n",
    "ax_2.set_xlabel('\\n A-B/(A-A + B-B)')\n",
    "ax_2.legend(loc='upper right')\n",
    "ax_2.set_ylim(top=61)\n",
    "ax_2.set_xlim(right=2.6)\n",
    "\n",
    "dirmaker(f'./plots/scatterplots/{xdate}')\n",
    "plt.savefig(f\"./plots/scatterplots/{xdate}/hnum_ratios_intra_vs_inter_{xdate}_alpha5.tiff\", facecolor=\"white\", bbox_inches=\"tight\", dpi=350)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hnum histogram\n",
    "plt.rcParams.update({\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"xtick.labelsize\": 30,\n",
    "    \"ytick.labelsize\": 30,\n",
    "    'font.size': 28,\n",
    "    'axes.labelweight': 'bold',\n",
    "    'figure.dpi': 150.0,\n",
    "    'axes.linewidth':2.0,\n",
    "})\n",
    "\n",
    "xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "\n",
    "fig_2, ax_2 = plt.subplots(1,1)\n",
    "fig_2.set_size_inches(12,10, forward=True)  \n",
    "\n",
    "ax_2.hist([des_df_hnum_scatter['A-A/B-B'], nondes_df_hnum_scatter['A-A/B-B'], \n",
    "        des_df_hnum_scatter['A-B/(A-A + B-B)'], nondes_df_hnum_scatter['A-B/(A-A + B-B)']], bins=5,\n",
    "         label=['A-A/B-B des', 'A-A/B-B non-des', 'A-B/(A-A + B-B) des', 'A-B/(A-A + B-B) non-des'])\n",
    "\n",
    "ax_2.legend(loc='upper right', prop={'weight':'bold'})\n",
    "# ax_2.hist(nondes_df_hnum_scatter, bins=10)\n",
    "ax_2.set_xlabel('\\n Average hydrogen bond numbers')\n",
    "ax_2.set_xlim(right=61)\n",
    "ax_2.set_ylabel('Number of systems \\n')\n",
    "dirmaker(f'./plots/hist/{xdate}')\n",
    "plt.savefig(f\"./plots/hist/{xdate}/hnum_hist_{xdate}.tiff\", facecolor=\"white\", bbox_inches=\"tight\", dpi=350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hlife histogram \n",
    "plt.rcParams.update({\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"xtick.labelsize\": 30,\n",
    "    \"ytick.labelsize\": 30,\n",
    "    'font.size': 28,\n",
    "    'axes.labelweight': 'bold',\n",
    "    'figure.dpi': 150.0,\n",
    "    'axes.linewidth':2.0,\n",
    "})\n",
    "\n",
    "xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "\n",
    "fig_2, ax_2 = plt.subplots(1,1)\n",
    "fig_2.set_size_inches(12,10, forward=True)  \n",
    "\n",
    "ax_2.hist([des_df_hlife_scatter['A-A/B-B'], nondes_df_hlife_scatter['A-A/B-B'], \n",
    "        des_df_hlife_scatter['A-B/(A-A + B-B)'], nondes_df_hlife_scatter['A-B/(A-A + B-B)']], bins=5,\n",
    "         label=['A-A/B-B des', 'A-A/B-B non-des', 'A-B/(A-A + B-B) des', 'A-B/(A-A + B-B) non-des'], rwidth=20.9) #, histtype='stepfilled')\n",
    "\n",
    "ax_2.legend(loc='upper right', prop={'weight':'bold'})\n",
    "\n",
    "ax_2.set_xlabel('Average hydrogen bond lifetimes')\n",
    "ax_2.set_ylabel('Number of systems')\n",
    "ax_2.set_xlim(right=61)\n",
    "dirmaker(f'./plots/hist/{xdate}')\n",
    "plt.savefig(f\"./plots/hist/{xdate}/hlife_hist_{xdate}.tiff\", facecolor=\"white\", bbox_inches=\"tight\", dpi=350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-DES alone\n",
    "fig,ax = plt.subplots(1,1, sharey=True)\n",
    "fig.set_size_inches(14,8)\n",
    "# ax1.set_ylabel(\"Density\", weight=\"bold\")\n",
    "nondes_df_hlife_scatter.plot.kde(ax=ax, title='non-DES KDE')\n",
    "des_df_hlife_scatter.plot.kde(ax=ax, title='DES KDE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-overlapping histo NON-DES\n",
    "xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "non_des_fig_scatter = plt.figure()\n",
    "non_des_fig_scatter.set_size_inches(12, 8, forward=True)\n",
    "non_des_ax_scatter = non_des_fig_scatter.add_subplot(1,1,1)\n",
    "non_des_ax_scatter.set_xlabel(\"Hydrogen bond number\", fontsize=24, weight='bold')\n",
    "non_des_ax_scatter.set_ylabel(\"Number of systems\", fontsize=24, weight='bold')\n",
    "ytick = np.arange(0,40, 2)\n",
    "xtick = np.arange(0,90, 10)\n",
    "plt.yticks(ytick,fontsize=22, weight='bold')\n",
    "plt.xticks(xtick,fontsize=22, weight='bold')\n",
    "plt.title('Non-DES', fontsize=22, weight='bold')\n",
    "plt.ylim([0,12])\n",
    "# non_des_hist = non_des[['AA', 'BB', 'AB']]\n",
    "# non_des_hist.plot.hist(bins=20, alpha=0.5, ylim=[0,22], ax =non_des_ax_scatter) # ylim=[0,22], \n",
    "plt.hist([nondes_hnum_scatter['A-A'], nondes_hnum_scatter['B-B'], nondes_hnum_scatter['A-B']], bins=10, label=['A-A', 'B-B', 'A-B'])\n",
    "plt.legend(loc='upper right', prop={'weight':'bold'})\n",
    "non_des_fig_scatter.savefig(f'nondes_hnum_scatter_nonoverlap_{xdate}.png', dpi=350,facecolor='white', bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hnum or hlife\n",
    "single plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"xtick.labelsize\": 34,\n",
    "    \"ytick.labelsize\": 40,\n",
    "    'font.size': 44,\n",
    "    'axes.labelweight': 'bold',\n",
    "    'axes.labelsize': 48,\n",
    "    'figure.dpi': 350.0,\n",
    "    'axes.linewidth':2.0,\n",
    "})\n",
    "\n",
    "pathway = Path()\n",
    "\n",
    "for file in pathway.glob('./model-logs/training/hnum/01-23-2023/*.txt'):\n",
    "    if str(file).__contains__('KNeighbors'):\n",
    "        continue\n",
    "\n",
    "\n",
    "    model_tags = {\n",
    "        'A-A' : [],\n",
    "        'B-B' : [],\n",
    "        'A-B' : [],\n",
    "        'A-A/B-B' : [],\n",
    "        'A-B/(A-A + B-B)' : []\n",
    "    }\n",
    "\n",
    "    index = []\n",
    "    with open(file, 'r+') as r:        \n",
    "        # index = 0\n",
    "        for l_no, line in enumerate(r):\n",
    "            # search string\n",
    "            if 'Top ' in line:\n",
    "                # index.join(str(l_no))\n",
    "                index.append(l_no)\n",
    "                # print(f'string found in {file} on line number {l_no}')\n",
    "                break\n",
    "\n",
    "        # print(index)\n",
    "\n",
    "    with open(file, 'r+') as r:\n",
    "        lines = r.readlines()\n",
    "\n",
    "        for line in lines[index[-1] + 1:]:\n",
    "            # print(line)\n",
    "            splitted = line.strip().split()\n",
    "            # print(splitted)\n",
    "\n",
    "            if splitted[0] == '4':\n",
    "                model_tags['A-B/(A-A + B-B)'].append(int(splitted[1]))\n",
    "            else:\n",
    "                model_tags[splitted[2]].append(int(splitted[1]))\n",
    "\n",
    "    print(model_tags)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    fig.set_size_inches(24, 12, forward=True)\n",
    "    test = fig.add_subplot(1,1,1)        \n",
    "    test.set_ylim([0, 100])\n",
    "    # test.set_xlim([0, 8.0])\n",
    "    bar_width=0.5\n",
    "    prop_cycle = plt.rcParams['axes.prop_cycle']\n",
    "    colors = prop_cycle.by_key()['color']\n",
    "    \n",
    "    names = list(model_tags.keys())\n",
    "    values = list(model_tags.values())\n",
    "    values = list(np.concatenate(values).flat)\n",
    "    test.bar(range(len(model_tags)), values, tick_label=names, color=colors, width=bar_width)\n",
    "    test.set_xlabel(\"\\nHydrogen bond types\")\n",
    "    test.set_ylabel('Frequency\\n')\n",
    "    figname = str(file.stem).split('_')[0]\n",
    "    figtype = str(file.stem).split('_')[1]\n",
    "    fig.savefig(f'./plots/top-coeffs/{figtype}/{figname}_{figtype}_{xdate}.tiff', dpi=350, facecolor='white', bbox_inches='tight')\n",
    "    # fig.savefig(f'{folder}/{figname}.pdf', dpi=fig.dpi, facecolor='white', bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_merged_ = ['{A-A_n}', 'B-B_n', 'A-B_n', r'$\\frac{A-A_n}{B-B_n}', r'$\\frac{A-B_n}{A-A_n + B-B_n}',\n",
    "                   'A-A_l', 'B-B_l', 'A-B_l', r'$\\frac{A-A_l}{B-B_l}',\n",
    "                   r'$\\frac{A-B_l}{A-A_l + B-B_l}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged\n",
    "\n",
    "import matplotlib as mpl\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"xtick.labelsize\": 34,\n",
    "    \"ytick.labelsize\": 40,\n",
    "    'font.size': 44,\n",
    "    'axes.labelweight': 'bold',\n",
    "    'axes.labelsize': 48,\n",
    "    'figure.dpi': 350.0,\n",
    "    'axes.linewidth':2.0,\n",
    "})\n",
    "\n",
    "pathway = Path()\n",
    "\n",
    "for file in pathway.glob('./model-logs/training/merged/01-23-2023/*.txt'):\n",
    "    print(file)\n",
    "    if str(file).__contains__('KNeighbors'):\n",
    "        continue\n",
    "\n",
    "\n",
    "    model_tags_merged = {\n",
    "        'A-A_n' : [],\n",
    "        'B-B_n' : [],\n",
    "        'A-B_n' : [],\n",
    "        'A-A_n/B-B_n' : [],\n",
    "        'A-B_n/(A-A_n + B-B_n)' : [],\n",
    "        'A-A_l' : [],\n",
    "        'B-B_l' : [],\n",
    "        'A-B_l' : [],\n",
    "        'A-A_l/B-B_l' : [],\n",
    "        'A-B_l/(A-A_l + B-B_l)' : []\n",
    "    }\n",
    "\n",
    "    index = []\n",
    "    with open(file, 'r+') as r:        \n",
    "        # index = 0\n",
    "        for l_no, line in enumerate(r):\n",
    "            # search string\n",
    "            if 'Top ' in line:\n",
    "                # index.join(str(l_no))\n",
    "                index.append(l_no)\n",
    "                # print(f'string found in {file} on line number {l_no}')\n",
    "                break\n",
    "\n",
    "        # print(index)\n",
    "\n",
    "    with open(file, 'r+') as r:\n",
    "        lines = r.readlines()\n",
    "\n",
    "        for line in lines[index[-1] + 1:]:\n",
    "            # print(line)\n",
    "            splitted = line.strip().split()\n",
    "            # print(splitted)\n",
    "\n",
    "            if splitted[0] == '4':\n",
    "                model_tags_merged['A-B_n/(A-A_n + B-B_n)'].append(int(splitted[1]))\n",
    "            elif splitted[0] == '9':\n",
    "                model_tags_merged['A-B_l/(A-A_l + B-B_l)'].append(int(splitted[1]))\n",
    "            else:\n",
    "                model_tags_merged[splitted[2]].append(int(splitted[1]))\n",
    "\n",
    "    print(model_tags_merged)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    fig.set_size_inches(30, 20, forward=True)\n",
    "    test = fig.add_subplot(1,1,1)        \n",
    "    test.set_ylim([0, 100])\n",
    "    # test.set_xlim([0, 8.0])\n",
    "    bar_width=0.5\n",
    "    prop_cycle = plt.rcParams['axes.prop_cycle']\n",
    "    colors = prop_cycle.by_key()['color']\n",
    "    \n",
    "    # names = list(model_tags_merged.keys())\n",
    "    names = ['A-A_n', 'B-B_n', 'A-B_n', r'$\\frac{A-A_n}{B-B_n}$', r'$\\frac{A-B_n}{A-A_n + B-B_n}$',\n",
    "                   'A-A_l', 'B-B_l', 'A-B_l', r'$\\frac{A-A_l}{B-B_l}$',\n",
    "                   r'$\\frac{A-B_l}{A-A_l + B-B_l}$']\n",
    "    values = list(model_tags_merged.values())\n",
    "    values = list(np.concatenate(values).flat)\n",
    "    test.bar(range(len(model_tags_merged)), values, tick_label=names, color=colors, width=bar_width)\n",
    "    test.set_xlabel(\"\\nHydrogen bond types\")\n",
    "    test.set_ylabel('Frequency\\n')\n",
    "    figname = str(file.stem).split('_')[0]\n",
    "    figtype = str(file.stem).split('_')[1]\n",
    "    fig.savefig(f'./plots/top-coeffs/{figtype}/{figname}_{figtype}_{xdate}.tiff', dpi=350, facecolor='white', bbox_inches='tight')\n",
    "    # fig.savefig(f'{folder}/{figname}.pdf', dpi=fig.dpi, facecolor='white', bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "       "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hnum or hlife\n",
    "combined plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"xtick.labelsize\": 34,\n",
    "    \"ytick.labelsize\": 40,\n",
    "    'font.size': 44,\n",
    "    'axes.labelweight': 'bold',\n",
    "    'axes.labelsize': 48,\n",
    "    'figure.dpi': 350.0,\n",
    "    'axes.linewidth':2.0,\n",
    "})\n",
    "\n",
    "pathway = Path()\n",
    "model_tags = {\n",
    "        'A-A' : [],\n",
    "        'B-B' : [],\n",
    "        'A-B' : [],\n",
    "        'A-A/B-B' : [],\n",
    "        'A-B/(A-A + B-B)' : []\n",
    "    }\n",
    "\n",
    "for file in pathway.glob('./model-logs/training/hlife/01-23-2023/*.txt'):\n",
    "    if str(file).__contains__('KNeighbors'):\n",
    "        continue\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    index = []\n",
    "    with open(file, 'r+') as r:        \n",
    "        # index = 0\n",
    "        for l_no, line in enumerate(r):\n",
    "            # search string\n",
    "            if 'Top ' in line:\n",
    "                # index.join(str(l_no))\n",
    "                index.append(l_no)\n",
    "                # print(f'string found in {file} on line number {l_no}')\n",
    "                break\n",
    "\n",
    "        # print(index)\n",
    "\n",
    "    with open(file, 'r+') as r:\n",
    "        lines = r.readlines()\n",
    "\n",
    "        for line in lines[index[-1] + 1:]:\n",
    "            # print(line)\n",
    "            splitted = line.strip().split()\n",
    "            # print(splitted)\n",
    "\n",
    "            if splitted[0] == '4':\n",
    "                model_tags['A-B/(A-A + B-B)'].append(int(splitted[1]))\n",
    "            else:\n",
    "                model_tags[splitted[2]].append(int(splitted[1]))\n",
    "\n",
    "print(list(model_tags.values()))\n",
    "total_values = list(model_tags.values())\n",
    "total = []\n",
    "for x in total_values:\n",
    "    total.append(sum(x))\n",
    "\n",
    "print(total)\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(24, 12, forward=True)\n",
    "test = fig.add_subplot(1,1,1)        \n",
    "test.set_ylim([0, 600])\n",
    "# test.set_xlim([0, 8.0])\n",
    "bar_width=0.5\n",
    "prop_cycle = plt.rcParams['axes.prop_cycle']\n",
    "colors = prop_cycle.by_key()['color']\n",
    "\n",
    "names = list(model_tags.keys())\n",
    "total_values = list(model_tags.values())\n",
    "total = []\n",
    "for x in total_values:\n",
    "    total.append(sum(x))\n",
    "\n",
    "print(total)\n",
    "\n",
    "test.bar(range(len(model_tags)), total, tick_label=names, color=colors, width=bar_width)\n",
    "test.set_xlabel(\"\\nHydrogen bond types\")\n",
    "test.set_ylabel('Frequency\\n')\n",
    "figname = 'combined_plots'\n",
    "figtype = str(file.stem).split('_')[1]\n",
    "# fig.savefig(f'./plots/top-coeffs/{figtype}/{figname}_{figtype}_{xdate}.tiff', dpi=350, facecolor='white', bbox_inches='tight')\n",
    "# fig.savefig(f'{folder}/{figname}.pdf', dpi=fig.dpi, facecolor='white', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged\n",
    "import matplotlib as mpl\n",
    "\n",
    "xdate = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "plt.rcParams.update({\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"xtick.labelsize\": 40,\n",
    "    \"ytick.labelsize\": 48,\n",
    "    'font.size': 54,\n",
    "    'axes.labelweight': 'bold',\n",
    "    'axes.labelsize': 48,\n",
    "    'figure.dpi': 350.0,\n",
    "    'axes.linewidth':2.0,\n",
    "    'mathtext.default': 'regular',\n",
    "    #'mathtext.bf' : 'regular:bold'\n",
    "})\n",
    "\n",
    "pathway = Path()\n",
    "model_tags_merged = {\n",
    "        'A-A_n' : [],\n",
    "        'B-B_n' : [],\n",
    "        'A-B_n' : [],\n",
    "        'A-A_n/B-B_n' : [],\n",
    "        'A-B_n/(A-A_n + B-B_n)' : [],\n",
    "        'A-A_l' : [],\n",
    "        'B-B_l' : [],\n",
    "        'A-B_l' : [],\n",
    "        'A-A_l/B-B_l' : [],\n",
    "        'A-B_l/(A-A_l + B-B_l)' : []\n",
    "    }\n",
    "\n",
    "for file in pathway.glob('./model-logs/training/merged/01-23-2023/*.txt'):\n",
    "    if str(file).__contains__('KNeighbors'):\n",
    "        continue\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    index = []\n",
    "    with open(file, 'r+') as r:        \n",
    "        # index = 0\n",
    "        for l_no, line in enumerate(r):\n",
    "            # search string\n",
    "            if 'Top ' in line:\n",
    "                # index.join(str(l_no))\n",
    "                index.append(l_no)\n",
    "                # print(f'string found in {file} on line number {l_no}')\n",
    "                break\n",
    "\n",
    "        # print(index)\n",
    "\n",
    "    with open(file, 'r+') as r:\n",
    "        lines = r.readlines()\n",
    "\n",
    "        for line in lines[index[-1] + 1:]:\n",
    "            # print(line)\n",
    "            splitted = line.strip().split()\n",
    "            # print(splitted)\n",
    "\n",
    "            if splitted[0] == '4':\n",
    "                model_tags_merged['A-B_n/(A-A_n + B-B_n)'].append(int(splitted[1]))\n",
    "            elif splitted[0] == '9':\n",
    "                model_tags_merged['A-B_l/(A-A_l + B-B_l)'].append(int(splitted[1]))\n",
    "            else:\n",
    "                model_tags_merged[splitted[2]].append(int(splitted[1]))\n",
    "                \n",
    "\n",
    "print(list(model_tags_merged.values()))\n",
    "total_values = list(model_tags_merged.values())\n",
    "total = []\n",
    "for x in total_values:\n",
    "    total.append(sum(x))\n",
    "\n",
    "print(total)\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(40, 20, forward=True)\n",
    "test = fig.add_subplot(1,1,1)        \n",
    "test.set_ylim([0, 600])\n",
    "# test.set_xlim([0, 8.0])\n",
    "bar_width=0.5\n",
    "prop_cycle = plt.rcParams['axes.prop_cycle']\n",
    "colors = prop_cycle.by_key()['color']\n",
    "\n",
    "names = [r'A-A$_{\\_n}$', r'B-B$_{\\_n}$', r'A-B$_{\\_n}$', r\"$\\frac{A-A_{\\_n}}{B-B_{\\_n}}$\", r\"$\\frac{A-B_{\\_n}}{A-A_{\\_n} + B-B_{\\_n}}$\",\n",
    "                   r'A-A$_{\\_l}$', r'B-B$_{\\_l}$', r'A-B$_{\\_l}$', r'$\\frac{A-A_{\\_l}}{B-B_{\\_l}}$',\n",
    "                   r'$\\frac{A-B_{\\_l}}{A-A_{\\_l} + B-B_{\\_l}}$']\n",
    "\n",
    "total_values = list(model_tags_merged.values())\n",
    "total = []\n",
    "for x in total_values:\n",
    "    total.append(sum(x))\n",
    "\n",
    "print(total)\n",
    "\n",
    "test.bar(range(len(model_tags_merged)), total, tick_label=names, color=colors, width=bar_width)\n",
    "test.set_xlabel(\"\\nHydrogen bond types\")\n",
    "test.set_ylabel('Frequency\\n')\n",
    "figname = 'combined_plots'\n",
    "figtype = str(file.stem).split('_')[1]\n",
    "fig.savefig(f'./plots/top-coeffs/{figtype}/{figname}_{figtype}_{xdate}.tiff', dpi=350, facecolor='white', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "       "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrices visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### hnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "font = {'family': 'normal',\n",
    "        'weight': 'bold',\n",
    "        'size': 22}\n",
    "plt.rc('font', **font)\n",
    "\n",
    "models = {\n",
    "    'KNN': knn_class_hnum,\n",
    "    'SVC': sv_class_hnum,\n",
    "    'LR': reg_log_hnum,\n",
    "    'DT': dt_class_hnum,\n",
    "    'RF': rf_class_hnum,\n",
    "    'XG': xg_boost_hnum,\n",
    "}\n",
    "\n",
    "class_names = target_names\n",
    "\n",
    "for name, model in models.items():\n",
    "    titles_options = [\n",
    "        (f\"{name} confusion matrix (not normalized)_hnum\", None),\n",
    "        (f\"{name} confusion matrix (normalized)_hnum\", \"true\"), ]\n",
    "\n",
    "    for title, normalize in titles_options:\n",
    "        disp = ConfusionMatrixDisplay.from_estimator(\n",
    "            model,\n",
    "            X_test_hnum,\n",
    "            y_test_hnum,\n",
    "            display_labels=class_names,\n",
    "            cmap=plt.cm.Blues,\n",
    "            normalize=normalize,\n",
    "        )\n",
    "\n",
    "        disp.figure_.set_size_inches(14, 10)\n",
    "        disp.ax_.set_title(title, fontsize=30, weight='bold')\n",
    "        disp.ax_.set_xlabel(\"Predicted label\", fontsize=24, weight='bold')\n",
    "        disp.ax_.set_ylabel(\"True label\", fontsize=24, weight='bold')\n",
    "\n",
    "        print(title)\n",
    "        print(disp.confusion_matrix)\n",
    "        plt.savefig(\n",
    "            f\"./plots/classifiers/{title}.png\", dpi=400, facecolor='white')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "font = {'family': 'normal',\n",
    "        'weight': 'bold',\n",
    "        'size': 22}\n",
    "plt.rc('font', **font)\n",
    "\n",
    "models = {\n",
    "    'KNN': knn_class_hlife,\n",
    "    'SVC': sv_class_hlife,\n",
    "    'LR': reg_log_hlife,\n",
    "    'DT': dt_class_hlife,\n",
    "    'RF': rf_class_hlife,\n",
    "    'XG': xg_boost_hlife,\n",
    "}\n",
    "\n",
    "class_names = target_names\n",
    "\n",
    "for name, model in models.items():\n",
    "    titles_options = [\n",
    "        (f\"{name} confusion matrix (not normalized)_hlife\", None),\n",
    "        (f\"{name} confusion matrix (normalized)_hlife\", \"true\"), ]\n",
    "\n",
    "    for title, normalize in titles_options:\n",
    "        disp = ConfusionMatrixDisplay.from_estimator(\n",
    "            model,\n",
    "            X_test_hlife,\n",
    "            y_test_hlife,\n",
    "            display_labels=class_names,\n",
    "            cmap=plt.cm.Blues,\n",
    "            normalize=normalize,\n",
    "        )\n",
    "\n",
    "        disp.figure_.set_size_inches(14, 10)\n",
    "        disp.ax_.set_title(title, fontsize=30, weight='bold')\n",
    "        disp.ax_.set_xlabel(\"Predicted label\", fontsize=24, weight='bold')\n",
    "        disp.ax_.set_ylabel(\"True label\", fontsize=24, weight='bold')\n",
    "\n",
    "        print(title)\n",
    "        print(disp.confusion_matrix)\n",
    "        plt.savefig(\n",
    "            f\"./plots/classifiers/{title}.png\", dpi=400, facecolor='white')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'KNN': knn_class_hnum,\n",
    "    'SVC': sv_class_hnum,\n",
    "    'LR': reg_log_hnum,\n",
    "    'DT': dt_class_hnum,\n",
    "    'RF': rf_class_hnum,\n",
    "    'XG': xg_boost_hnum,\n",
    "}\n",
    "for name, model in models.items():\n",
    "    print(name, model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "271d7943521ff1a2a5055f183d9d47f24192a8d2b24fa5873713a4485f04fe48"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
